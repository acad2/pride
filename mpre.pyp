ccopy_reg
_reconstructor
p1
(cmpre.package
Package
p2
c__builtin__
object
p3
NtRp4
(dp5
S'files'
p6
(dp7
Vtests
p8
(lp9
VC:\u005cusers\u005c_\u005cpythonbs\u005cmpre\u005ctests\u005cbytecodedis.py
p10
aVC:\u005cusers\u005c_\u005cpythonbs\u005cmpre\u005ctests\u005cbytecodemap.py
p11
aVC:\u005cusers\u005c_\u005cpythonbs\u005cmpre\u005ctests\u005chashdicttest.py
p12
aVC:\u005cusers\u005c_\u005cpythonbs\u005cmpre\u005ctests\u005cinstalltest.py
p13
aVC:\u005cusers\u005c_\u005cpythonbs\u005cmpre\u005ctests\u005clru_test.py
p14
aVC:\u005cusers\u005c_\u005cpythonbs\u005cmpre\u005ctests\u005cnetwork2.py
p15
asVmpre
p16
(lp17
(Vbase.py
S'#   mpre.base - Instructions and root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport cPickle as pickle\n\nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward. Alerts\n              also include options for callback methods and instructions\n              \n            - The method known as parallel_method. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass#._metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes an instance will initialize with.\n    # storing them here and using the set_attributes method\n    # makes them modifiable at runtime and eliminates the need\n    # to type out the usual self.attribute = value statements\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n                       \n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n      #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__\n        self.objects = {}\n        \n        attributes = self.defaults.copy()\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))\n                \n        self.set_attributes(**attributes)\n        \n        self.environment.add(self)\n              \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        self.environment.modify("Parents", (instance, self.instance_name))        \n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        self.environment.delete(self)\n\n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To"""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__]"""   \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, [])\n        if instance not in siblings:\n            siblings.append(instance)\n            objects[instance_class] = siblings\n        else:\n       #     self.alert("Ignoring add of " + str(instance), level=0)\n            raise type("AddException", (BaseException, ), \n                       {"message" : "attempted to add an object that has already been added"})\n        if hasattr(instance, "instance_name"):\n            instance_name = instance.instance_name\n            references_to = self.environment.References_To.get(instance_name, set())\n            references_to.add(self.instance_name)\n            self.environment.References_To[instance_name] = references_to\n            \n    def alert(self, message="Unspecified alert message",\n                    format_args=tuple(),\n                    level=0,\n                    callback=None):\n        """usage: base.alert(message, format_args=tuple(), level=0, callback=None)\n\n        Create an alert. Depending on the level given, the alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n        -callback is an optional tuple of (function, args, kwargs) to be called when\n         the alert is triggered\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower number indicates a less verbose notification, while 0 indicates\n        an important message that should not be suppressed."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n\n            return self.parallel_method("Alert_Handler", "alert",\n                                        message,\n                                        level, callback)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for an explicit reference to that object."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__\n        \n    def __setstate__(self, state):\n        self.set_attributes(**state)\n        self.environment.add(self)\n        return self\n        \n    def update(self):\n        """usage: base.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. \n           The environment is updated with the new component information. Further\n           references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the new, updated object.\n           \n           This is the bleeding edge. not solid in terms of object deletion yet."""\n           \n        """found_metaclasses = set()       \n        for cls in reversed(type(self).__mro__): # will get weird with wrappers\n        \n            # reload the module of the metaclass of the class\n            metaclass = getattr(cls, "__metaclass__", None)\n            if metaclass and metaclass not in found_metaclasses:\n                found_metaclasses.add(metaclass)\n                utilities.reload_module(metaclass.__module__)\n                \n            class_module = cls.__module__\n            if class_module != "__main__":\n                utilities.reload_module(class_module)\n                \n        stats = self.__dict__.copy()\n        new_self = getattr(sys.modules[self.__module__], self.__class__.__name__)()\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**stats)"""\n        self.alert("Updating", level=0)\n        stats = self.__dict__.copy()\n        module = sys.modules[self.__module__]\n        reload(module)\n        new_self = getattr(module, self.__class__.__name__)()\n        new_self.alert("new instance created, replacing old instance", level=0)\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**stats)\n        return new_self\n        \n        \nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and may not be completely\n        final in it\'s api and/or implementation.\n        TODO: add transparent remote reaction support!"""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n    \n    def __getstate__(self):\n        attributes = self.__dict__.copy()\n        attributes["_respond_with"] = [method.function.func_name for method in\n                                       attributes["_respond_with"]]\n        \n        return attributes\n        \n    def __setstate__(self, state):\n        state["_respond_with"] = [getattr(self, name) for name in\n                                  state["_respond_with"]]\n        self.__dict__.update(state)\n        \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (self._respond_with.pop(0) if self._respond_with else\n                  getattr(self, command))\n                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. """\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n      #  print self, "getting attribute", attribute\n        return getattr(super(Wrapper, self).__getattribute__("wrapped_object"),\n                       attribute)\n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. This facilitates simple integration \n       with \'regular\' python objects, providing them with monkey patches and\n       the reaction/parallel_method/alert interfaces for very little effort.\n       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy wrapper instead."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)'
tp18
a(Vcompiler.py
S'import os\nimport sys\n\nfrom math import sqrt\nimport multiprocessing as mp\n\nimport _compile\n\nclass Compiler(object):\n    \n    def __init__(self, shared_file_type="pyd" if "win" in sys.platform else "so",\n                       directory=os.getcwd(),\n                       subfolders=tuple(),\n                       main_file=\'\',\n                       ignore_files=tuple(),\n                       max_processes=10):\n        self.shared_file_type = shared_file_type\n        self.directory = directory\n        self.subfolders = subfolders\n        self.main_file = main_file\n        self.ignore_files = ignore_files\n        self.max_processes = max_processes\n                     \n    def cleanup_compiled_files(self, file_types=("pyx", "c")):  \n        directory = self.directory\n        _, _, file_list = next(os.walk(directory))\n        file_list = [(\'\', file_list)]\n        \n        for subfolder in self.subfolders:\n            folder_path = os.path.join(directory, subfolder)\n            file_list.append((folder_path,\n                              next(os.walk(folder_path))[2]))\n         \n        for filetype in file_types:\n            for folder, _files in file_list:\n                for _file in _files:\n                    if os.path.splitext(_file)[-1] == \'.\' + filetype:\n                        os.remove(os.path.join(folder, _file))\n                     \n    def get_py_files(self, directory):\n        _, _, file_list = next(os.walk(directory))\n        return [os.path.join(directory, _file) for _file in file_list if \n                ".py" == os.path.splitext(_file)[-1] and _file not in\n                self.ignore_files]\n                  \n    def compile(self):    \n        directory = self.directory\n        files = []\n        files.extend(self.get_py_files(directory))\n        \n        for subfolder in self.subfolders:\n            files.extend(self.get_py_files(os.path.join(directory, subfolder)))\n                     \n        if self.main_file:\n            main_file = os.path.join(directory, self.main_file)\n            files.remove(main_file)\n        else:\n            main_file = \'\' # just making shared objects, no executable\n        \n        file_count = len(files)    \n        process_count = min(self.max_processes, int(sqrt(file_count)))\n        files_per_process = len(files) / process_count \n        \n        # maps consecutive ints (0, 1, 2...) to slices like [0:files_per_process]\n        slices = dict((index, \n                       slice(index * files_per_process,\n                            (index + 1) * files_per_process))\n                       for index in range(files_per_process))\n        \n        processes = []\n        for file_count in range(files_per_process):\n            processes.append(mp.Process(target=_compile.py_to_compiled, \n                                        args=[files[slices[file_count]],\n                                        self.shared_file_type]))\n        print "beginning compilation..."\n        for process in processes:\n            process.start()\n                        \n        print "waiting for shared resources to finish compiling..."        \n        for process in processes:            \n            process.join()\n            \n        if main_file:\n            print "compiling executable..."\n            executable = _compile.py_to_compiled([main_file], \'exe\')\n            print "...done"\n            \nif __name__ == "__main__":\n    compiler = Compiler(subfolders=("audio", "gui", "misc", "programs"),\n                        main_file="metapython.py",\n                        ignore_files=["compiler.py", "_compile.py"])\n    compiler.compile()\n    compiler.cleanup_compiled_files(file_types=("pyx", "pyd", \'c\'))'
tp19
a(Vdefaults.py
S'#   mpf.defaults - config file - contains attributes:values for new instances\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\nimport struct\nimport socket\nfrom traceback import format_exc\nfrom multiprocessing import cpu_count\nfrom StringIO import StringIO\n\nNO_ARGS = tuple()\nNO_KWARGS = dict()\nPROCESSOR_COUNT = 1#cpu_count()\n\n# Base\nMANUALLY_REQUEST_MEMORY = 0\nDEFAULT_MEMORY_SIZE = 4096\n\n# anonymous memory passes -1  as the file descriptor to pythons mmap.mmap.\n# persistent memory opens the file instance.instance_name and opens an\n# mmap.mmap with that files file descriptor\nANONYMOUS = -1\nPERSISTENT = 0\nBase = {"memory_size" : DEFAULT_MEMORY_SIZE,\n"memory_mode" : ANONYMOUS,\n"verbosity" : \'\',\n"deleted" : False,\n"update_flag" : False}\n\nReactor = Base.copy()\n\nProcess = Base.copy()\nProcess.update({"auto_start" : True,\n"priority" : .04})\n\n# vmlibrary\n\nProcessor = Process.copy()\nProcessor.update({"running" : True,\n"auto_start" : False})\n\nUser_Input = Process.copy()\n\n# network\n\nSocket = Base.copy()\nSocket.update({"blocking" : 0,\n"timeout" : 0,\n"add_on_init" : True,\n"network_packet_size" : 32768,\n"memory_size" : 0,\n"network_buffer" : \'\',\n"interface" : "0.0.0.0",\n"port" : 0,\n"bind_on_init" : False,\n"added_to_network" : False})\n\nTcp_Socket = Socket.copy()\nTcp_Socket.update({"socket_family" : socket.AF_INET,\n"socket_type" : socket.SOCK_STREAM})\n\nServer = Tcp_Socket.copy()\nServer.update({"port" : 80,\n"backlog" : 50,\n"name" : "",\n"reuse_port" : 0,\n"Tcp_Socket_type" : "network.Tcp_Socket",\n"share_methods" : ("on_connect", "client_socket_recv", "client_socket_send")})\n\nTcp_Client = Tcp_Socket.copy()\nTcp_Client.update({"ip" : "",\n"port" : 80,\n"target" : tuple(),\n"as_port" : 0,\n"connect_attempts" : 10,\n"timeout_notify" : True,\n"add_on_init" : False,\n"bad_target_verbosity" : 0}) # alert verbosity when trying to connect to bad address\ndel Tcp_Client["interface"]\n\nUdp_Socket = Socket.copy()\nUdp_Socket.update({"bind_on_init" : True})\n\n# only addresses in the range of 224.0.0.0 to 230.255.255.255 are valid for IP multicast\nMulticast_Beacon = Udp_Socket.copy()\nMulticast_Beacon.update({"packet_ttl" : struct.pack("b", 127),\n"multicast_group" : "224.0.0.0",\n"multicast_port" : 1929})\n\nMulticast_Receiver = Udp_Socket.copy()\nMulticast_Receiver.update({"address" : "224.0.0.0"})\n\nConnection_Manager = Process.copy()\nConnection_Manager.update({"auto_start" : False})\n\nNetwork = Process.copy()\nNetwork.update({"handle_resends" : False,\n"number_of_sockets" : 0,\n"priority" : .01,\n"update_priority" : 5,\n"auto_start" : False})\n\n# network2\nNetwork_Service = Udp_Socket.copy()\n\nAuthenticated_Service = Base.copy()\nAuthenticated_Service.update({"database_filename" : ":memory:",\n"login_message" : \'login success\',\n"hash_rounds" : 100000})\n\nAuthenticated_Client = Base.copy()\nAuthenticated_Client.update({"email" : \'\',\n"username" : "",\n"password" : \'\',\n"target" : "Authenticated_Service"})\n\nFile_Service = Base.copy()\nFile_Service.update({"network_packet_size" : 16384,\n"mmap_threshold" : 16384,\n"timeout_after" : 15})\n\nDownload = Base.copy()\nDownload.update({"filesize" : 0,\n"filename" :\'\',\n"filename_prefix" : "Download",\n"download_in_progress" : False,\n"network_packet_size" : 16384,\n"timeout_after" : 15})\n\n # Metapython\nJYTHON = "java -jar jython.jar"\nPYPY = "pypy"\nCPYTHON = "python"\nDEFAULT_IMPLEMENTATION = CPYTHON\n\nShell = Authenticated_Client.copy()\nShell.update({"email" : \'\',\n"username" : "root",\n"password" : "password",\n"prompt" : ">>> ",\n"startup_definitions" : \'\',\n"target" : "Interpreter_Service"})\n\nInterpreter_Service = Authenticated_Service.copy()\nInterpreter_Service.update({"copyright" : \'Type "help", "copyright", "credits" or "license" for more information.\'})\n\nAlert_Handler = Reactor.copy()\nAlert_Handler.update({"log_level" : 0,\n                      "print_level" : 0,\n                      "log_name" : "Alerts.log"})\n                      \nMetapython = Reactor.copy()\nMetapython.update({"command" : "shell_launcher.py",\n"implementation" : DEFAULT_IMPLEMENTATION,\n"environment_setup" : ["PYSDL2_DLL_PATH = C:\\\\Python27\\\\DLLs"],\n"interface" : "0.0.0.0",\n"port" : 40022,\n"prompt" : ">>> ",\n"_suspended_file_name" : "suspended_interpreter.bin",\n"copyright" : \'Type "help", "copyright", "credits" or "license" for more information.\',\n"priority" : .04,\n"interpreter_enabled" : True,\n"startup_definitions" : \\\n"""Instruction(\'Metapython\', \'create\', \'userinput.User_Input\').execute()\nInstruction("Metapython", "create", "network.Network").execute()"""})\n#"help" : "Execute a python script or launch a live metapython session"})\n'
tp20
a(Vfileio.py
S'import mmap\nimport os\nfrom contextlib import closing\n\nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n            _file.close()\n            \n            \nclass Cached(object):\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """usage: file_object = File([filename], [mode], [file])\n    \n       Creates a File object. File objects are pickleable and\n       support the reactor interface for reading/writing to the\n       underlying wrapped file."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"storage_mode" : "dont_copy"})\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, **kwargs):           \n        kwargs.setdefault("wrapped_object", (file if file else \n                                             open(filename, mode)))\n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        \n    def handle_write(self, sender, packet):\n        self.wrapped_object.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.wrapped_object.seek(seek)\n        return "handle_write " + self.file.read(byte_count)\n        \n    def __getstate__(self):\n        if self.storage_mode == "copy":\n            self.seek(0)\n            data = self.read()\n        else:\n            data = \'\'\n        return self.filename, self.mode, data\n        \n    def __setstate__(self, state):\n        self.__init__(*state[:2]) # (filename, smode)\n        if state[2] and self.storage_mode == "copy": # data\n            self.handle_write(None, state[2])\n        return self\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached, and the size of the cache may be altered.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename\n            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n        \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""'
tp21
a(Vmetaclass.py
S'import sys\nimport argparse\nimport types\nimport functools\nimport ast\nimport inspect\nimport utilities\nfrom copy import copy\n\nclass Docstring(object):\n    """ A descriptor object used by the Documented metaclass. Augments\n        instance docstrings with introspected information"""\n    def __init__(self):\n        super(Docstring, self).__init__()\n\n    def __get__(self, instance, _class):\n        _object = instance if instance else _class\n        return utilities.documentation(_object)\n        \n        \nclass Documented(type):\n    """ A metaclass that uses the Docstring object to supply\n        abundant documentation for classes"""\n    def __new__(cls, name, bases, attributes):\n        Documented.make_docstring(attributes)\n        return super(Documented, cls).__new__(cls, name, bases, attributes)\n        \n    @staticmethod\n    def make_docstring(attributes):\n        attributes["__doc"] = attributes.get("__doc__", "No docstring found")\n        attributes["__doc__"] = Docstring()\n        \n\nclass Method_Hook(type):\n    """ Provides a hook on all methods for the new class. This metaclass\n        uses this hook to wrap each method in a Runtime_Decorator."""\n        \n    def __new__(cls, name, bases, attributes):        \n        new_class = super(Method_Hook, cls).__new__(cls, name, bases, attributes)\n        Method_Hook.decorate(new_class)\n        return new_class\n        \n    @staticmethod\n    def decorate(new_class):\n        for key, value in new_class.__dict__.items():\n            if key[0] != "_" and callable(value):\n                bound_method = types.MethodType(Runtime_Decorator(value), \n                                                None, \n                                                new_class)\n                setattr(new_class, key, bound_method)\n        return new_class        \n        \n        \nclass Runtime_Decorator(object):\n    """ Provides the ability to call a method with a decorator, decorators,\n        or monkey patch specified via keyword argument. This decorator\n        inherits from object and utilizes the Documented metaclass.\n\n        usage: wrapped_method(my_argument, decorator="decorators.Tracer")"""\n    __metaclass__ = Documented\n    \n    def __init__(self, function):\n        self.function = function\n        functools.update_wrapper(self, function)\n        self.handler_map = {"monkey_patch" : self._handle_monkey_patch,\n                            "decorator" : self._handle_decorator,\n                            "decorators" : self._handle_decorators}\n            \n    def __call__(self, *args, **kwargs):\n        check_for = kwargs.pop\n        modifiers = ("monkey_patch", "decorator", "decorators")\n        \n        for modifier in modifiers:\n            found = check_for(modifier, None)\n            if found:\n                call = self.handler_map[modifier](found)\n                break\n        else:\n            call = self.function\n        return call(*args, **kwargs)  \n            \n    def _handle_context_manager(self, context_manager):\n        raise NotImplementedError\n        if isinstance(context_manager, str):\n            context_manager = utilities.resolve_string(context_manager)\n        return context_manager   \n\n        with context_manager():\n            result = self.function(*args, **kwargs)\n        return result\n\n    def _handle_monkey_patch(self, monkey_patch):\n        if isinstance(monkey_patch, str):\n            monkey_patch = utilities.resolve_string(monkey_patch)\n        try:\n            monkey_patch = functools.partial(monkey_patch, self.function.im_self)\n        finally: # function has no attribute im_self (not a method)\n            return monkey_patch\n\n    def _handle_decorator(self, decorator_type):\n        if isinstance(decorator_type, str):\n            decorator_type = utilities.resolve_string(decorator_type)\n        return decorator_type(self.function)\n\n    def _handle_decorators(self, decorator_info):\n        decorators = []\n        for decorator in decorator_info:\n            if isinstance(decorator, str):\n                decorator = utilities.resolve_string(decorator)\n\n            decorators.append(decorator)\n\n        wrapped_function = self.function\n        for item in reversed(decorators):\n            wrapped_function = item(wrapped_function)\n        return wrapped_function\n\n\nclass Parser_Metaclass(type):\n    """ Provides a command line parser for a class based upon \n        the class.defaults dictionary"""\n\n    parser = argparse.ArgumentParser()\n    command_parser = parser.add_subparsers(help="filename")\n    run_parser = command_parser.add_parser("run", help="execute the specified script")\n    profile_parser = command_parser.add_parser("profile", help="profile the specified script")\n    \n    def __new__(cls, name, bases, attributes):\n        new_class = super(Parser_Metaclass, cls).__new__(cls, name, bases, attributes)\n        exit_on_help = attributes.get("exit_on_help", True)\n\n        base_class = bases[0]\n        modifiers = getattr(base_class, "parser_modifiers", {}).copy()\n\n        parser_ignore = set()\n        new_parser_ignore = attributes.get("parser_ignore", tuple())\n        old_parser_ignore = getattr(base_class, "parser_ignore", tuple())\n        for ignore in new_parser_ignore + old_parser_ignore:\n            parser_ignore.add(ignore)\n        new_class.parser_ignore = tuple(parser_ignore)\n        for attribute in parser_ignore:\n            modifiers[attribute] = "ignore"\n\n        new_modifiers = attributes.get("parser_modifiers", {})\n        modifiers.update(new_modifiers)\n        \n        new_class = Parser_Metaclass.make_parser(new_class, name, \n                                                 modifiers, exit_on_help)\n        return new_class\n        \n    @staticmethod\n    def make_parser(new_class, name, modifiers, exit_on_help):\n        parser = Parser_Metaclass.command_parser.add_parser(name)\n        new_class.parser = Parser(parser, modifiers, exit_on_help, name)\n        return new_class\n    \nclass Parser(object):\n    """ Faciltates automatically generated command line parsers. Parser\n        instances are class attributes assigned by the Parser_Metaclass"""\n    sys_argv_backup = copy(sys.argv)\n    __metaclass__ = Documented\n    \n    def __init__(self, parser, modifiers, exit_on_help, name):\n        super(Parser, self).__init__()\n        self.parser = parser\n        self.modifiers = modifiers\n        self.exit_on_help = exit_on_help\n        self.name = name\n\n    def get_arguments(self, argument_info):\n        arguments = {}\n        argument_names = argument_info.keys()\n        switch = {"short" : "-",\n                  "long" : "--",\n                  "positional" : ""}\n\n        default_modifiers = {"types" : ("long", )}\n        self_modifiers = self.modifiers\n        for name in argument_names:\n            modifiers = self_modifiers.get(name, default_modifiers)\n            if modifiers == "ignore":\n                continue\n            info = {}\n            for keyword_argument, value in modifiers.items():\n                info[keyword_argument] = value\n\n            temporary = {}\n            for arg_type in info.pop("types"):\n                if arg_type != "positional":\n                    temporary["dest"] = name\n\n                default_value = argument_info[name]\n                temporary["default"] = default_value\n                value_type = type(default_value)\n                if value_type == bool:\n                    value_type = ast.literal_eval\n                temporary["type"] = value_type\n\n                for key, value in temporary.items():\n                    info.setdefault(key, value)\n\n                arg_name = switch[arg_type] + name\n                arguments[arg_name] = info\n\n        parser = self.parser\n        exit_on_help = self.exit_on_help\n\n        for argument_name, options in arguments.items():\n            parser.add_argument(argument_name, **options)\n\n        new_argv = copy(Parser.sys_argv_backup)\n        sys.argv = new_argv\n\n        try:\n            arguments, unused = parser.parse_known_args()\n        except SystemExit:\n            if exit_on_help:\n                raise\n            try:\n                new_argv.pop(new_argv.index("-h"))\n            except ValueError:\n                new_argv.pop(new_argv.index("--help"))\n            arguments, unused = parser.parse_known_args()\n\n        if unused:\n          #  new_argv = copy(Parser.sys_argv_backup)\n            for unused_name in unused:\n                index = new_argv.index(unused_name)\n                new_argv.pop(index)\n\n                if "-" in unused_name: # pop whatever the value for the positional arg was too\n                    try:\n                        word = new_argv.pop(index)\n                    except IndexError: # no argument supplied to positional arg\n                        pass\n                    else:\n                        try:\n                            unused.remove(word)\n                        except ValueError:\n                            pass\n\n            arguments, unused = parser.parse_known_args()\n            sys.argv = copy(Parser.sys_argv_backup)\n        return arguments\n\n    def get_options(self, argument_info):\n        namespace = self.get_arguments(argument_info)\n        options = dict((key, getattr(namespace, key)) for key in namespace.__dict__.keys())\n        return options\n\n       \nclass Instance_Tracker(type):\n    """ Provides instance tracking and counting attributes.\n    \n        Note as of 3/3/2015: the class must implement these attributes,\n        it is not performed by this metaclass"""\n        \n    def __new__(cls, name, bases, attributes):\n        if "instance_tracker" not in attributes:\n            attributes["instance_tracker"] = {}\n        if "instance_count" not in attributes:\n            attributes["instance_count"] = 0\n\n        return super(Instance_Tracker, cls).__new__(cls, name, bases, attributes)\n\n       \nclass Metaclass(Documented, Instance_Tracker, Parser_Metaclass, Method_Hook):\n    """ A metaclass that applies other metaclasses. Each metaclass\n        in the list Metaclass.metaclasses will be chained into a \n        new single inheritance metaclass that utilizes each entry. \n        The methods insert_metaclass and remove_metaclass may be used\n        to alter the contents of this list.\n        \n        Implementation currently under examination due to compiling with\n        cython being broken"""\n        \n    #metaclasses = [Documented, Instance_Tracker, Parser_Metaclass, Method_Hook]\n   # _metaclass = type("Metaclass",\n     #                 tuple(metaclasses),\n      #                {})\n                      \n    def __new__(cls, name, bases, attributes):\n        # create a new metaclass that uses Metaclass.metaclasses as it\'s bases.\n        #new_metaclass = cls._metaclass\n        return super(Metaclass, cls).__new__(cls, name, bases, attributes)\n       # return new_class\n    \n    @classmethod\n    def update_metaclass(cls):\n        cls._metaclass = type(cls.__name__,\n                              tuple(cls.metaclasses),\n                              {})\n               \n    @classmethod\n    def insert_metaclass(cls, metaclass, index=-1):\n        cls.metaclasses.insert(index, metaclass)\n        cls.update_metaclass()\n        \n    @classmethod\n    def remove_metaclass(cls, metaclass):\n        cls.metaclasses.remove(metaclass)\n        cls.update_metaclass()\n        \n        \nif __name__ == "__main__":\n    import unittest\n    import mpre.base\n    import mpre.defaults      \n    \n    class Test_Metaclass(unittest.TestCase):\n        \n        def testdocumentation(self):\n            print mpre.base.Base.__doc__[:256] + "..."\n            print "End documentation test"\n            \n        def testdecoration(self):\n            test_base = mpre.base.Base()\n            \n            def test_decorator1(function):\n                def wrapped_function(*args, **kwargs):\n                    print "inside local decorator1"\n                    return function(*args, **kwargs)\n                return wrapped_function\n               \n            def test_decorator2(function):\n                def wrapped_function(*args, **kwargs):\n                    print "inside local decorator2"\n                    return function(*args, **kwargs)\n                return wrapped_function\n                \n            sock = test_base.create("socket.socket", decorator=test_decorator1)\n            \n            other_base = test_base.create("mpre.base.Base", decorators=(test_decorator1, test_decorator2))\n            \n            def monkey_patch(*args, **kwargs):\n                print "inside monkey patch"\n                \n            another_sock = test_base.create("socket.socket", \n                                            monkey_patch=monkey_patch)\n            self.failIf(another_sock) # monkey_patch returns False\n            \n        def testparser(self):\n            import sys\n\n            \n            backup = sys.argv\n            arguments = ("--test_string", "test_value", "--test_int", \'8\',\n                         "--test_bool", "False", "--test_float", 3.14)\n            sys.argv = list(arguments)\n            print len(sys.argv)\n\n            class TestBase(mpre.base.Base):\n                defaults = mpre.defaults.Base.copy()\n                \n                arg_index = 1\n                for item in arguments[::2]:\n                    defaults[item] = arguments[arg_index]\n                    arg_index += 2\n                    \n            test_base = TestBase(parse_args=True, testattr=1, \n                                 test_string="ishouldn\'tbehere")\n            \n            print "Ensuring parser attribute assignment works"\n            \n            print "Testing keyword arg assignment..."\n            self.failUnless(test_base.testattr == 1)\n            \n            \n            # as above, iteratively for the pairs in sys.argv\n            arg_index = 1\n            for index, item in enumerate(arguments[::2]):\n                value = arguments[arg_index]\n                arg_index += 2\n                print "Testing {}: {} == {}".format(item, getattr(test_base, item), value)\n                self.failUnless(getattr(test_base, item) == value)            \n            \n            sys.argv = backup\n    unittest.main()'
tp22
a(Vmetapython.py
S'#!/usr/bin/env python\nfrom __future__ import unicode_literals\n\nimport sys\nimport codeop\nimport os\nimport traceback\nimport time\nimport cStringIO as StringIO\nimport importlib\nimport copy\nimport pickle\n\nimport mpre\nimport mpre.base as base\nimport mpre.vmlibrary as vmlibrary\nimport mpre.network2 as network2\nimport mpre.utilities as utilities\nimport mpre.fileio as fileio\nimport mpre.defaults as defaults\n\nInstruction = mpre.Instruction            \n            \nclass Shell(network2.Authenticated_Client):\n    \n    defaults = defaults.Shell\n                     \n    def __init__(self, **kwargs):\n        super(Shell, self).__init__(**kwargs)\n        self.lines = \'\'\n        self.user_is_entering_definition = False            \n        self.reaction("User_Input", "add_listener " + self.instance_name)\n        \n    def login_result(self, sender, packet):\n        response = super(Shell, self).login_result(sender, packet)\n        if self.logged_in:\n            sys.stdout.write(">>> ")\n            if self.startup_definitions:\n                self.handle_startup_definitions()                \n        return response\n     \n    def handle_startup_definitions(self):\n        try:\n            compile(self.startup_definitions, "Shell", \'exec\')\n        except:\n            self.alert("Startup defintions failed to compile:\\n{}",\n                    [traceback.format_exc()],\n                    level=0)\n        else:\n            self.execute_source(self.startup_definitions) \n                    \n    def handle_keystrokes(self, sender, keyboard_input):\n        if not self.logged_in:\n            return\n        \n        self.lines += keyboard_input\n        lines = self.lines\n                \n        if lines != "\\n":            \n            try:\n                code = codeop.compile_command(lines, "<stdin>", "exec")\n            except (SyntaxError, OverflowError, ValueError) as error:\n                sys.stdout.write(traceback.format_exc())\n                self.prompt = ">>> "\n                self.lines = \'\'\n            else:\n                if code:\n                    if self.user_is_entering_definition:\n                        if lines[-2:] == "\\n\\n":\n                            self.prompt = ">>> "\n                            self.lines = \'\'\n                            self.execute_source(lines)\n                            self.user_is_entering_definition = False              \n                    else:\n                        self.lines = \'\'\n                        self.execute_source(lines)\n                else:\n                    self.user_is_entering_definition = True\n                    self.prompt = "... "\n        else:\n            self.lines = \'\'\n        \n        sys.stdout.write(self.prompt)\n        \n    def execute_source(self, source):\n        self.reaction(self.target, self.exec_code_request(self.target, source))\n        \n    def exec_code_request(self, sender, source):\n        if not self.logged_in:\n            response = self.login(sender, source)\n        else:\n            self.respond_with(self.result)\n            response = "exec_code " + source\n        return response     \n        \n    def result(self, sender, packet):\n        if packet:\n            sys.stdout.write("\\b"*4 + "   " + "\\b"*4 + packet)\n\n    def __setstate__(self, state):\n        super(Shell, self).__setstate__(state)\n        Instruction(self.instance_name, "handle_startup_definitions").execute()\n        \n        \nclass Interpreter_Service(network2.Authenticated_Service):\n    \n    defaults = defaults.Interpreter_Service\n    \n    def __init__(self, **kwargs):\n        self.user_namespaces = {}\n        super(Interpreter_Service, self).__init__(**kwargs)\n        self.log_file = open("Metapython.log", \'a\')\n        \n    def login(self, sender, packet):\n        response = super(Interpreter_Service, self).login(sender, packet)\n        if "success" in response.lower():\n            username = self.logged_in[sender]\n            #self.user_namespaces[username] = {"__builtins__": __builtins__,\n             #                                 "__name__" : "__main__",\n              #                                "__doc__" : \'\',\n               #                               "Instruction" : Instruction}\n                       \n            string_info = (username, sender,\n                           sys.version, sys.platform, self.copyright)\n        \n            greeting = ("Welcome {} from {}\\nPython {} on {}\\n{}\\n".\\\n                        format(*string_info))\n            response = "login_result success " + greeting\n\n        return response\n        \n    @network2.Authenticated\n    def exec_code(self, sender, packet):\n        log = self.log_file\n        \n        username = self.logged_in[sender]\n        log.write("{} {} from {}:\\n".format(time.asctime(), username, sender) + \n                  packet)\n        result = \'\'        \n        try:\n            code = compile(packet, "<stdin>", \'exec\')\n        except (SyntaxError, OverflowError, ValueError):\n            result = traceback.format_exc()\n           \n        else:                \n            backup = sys.stdout            \n            sys.stdout = StringIO.StringIO()\n            \n            try:\n                exec code in globals() #self.user_namespaces[username]\n            except BaseException as error:\n                if type(error) == SystemExit:\n                    raise\n                else:\n                    result = traceback.format_exc()\n            finally:\n                sys.stdout.seek(0)\n                result += sys.stdout.read()\n                \n                sys.stdout.close()\n                sys.stdout = backup\n                \n                log.write("{}\\n".format(result))\n        log.flush()\n        \n        return "result " + result\n    \n    \nclass Alert_Handler(base.Reactor):\n    \n    level_map = {0 : "",\n                \'v\' : "notification ",\n                \'vv\' : "verbose notification ",\n                \'vvv\' : "very verbose notification ",\n                \'vvvv\' : "extremely verbose notification "}\n                \n    defaults = defaults.Alert_Handler\n             \n    def __init__(self, **kwargs):\n        kwargs["parse_args"] = True\n        super(Alert_Handler, self).__init__(**kwargs)\n        self.log = fileio.File(self.log_name, \'a\')\n        \n    def alert(self, message, level, callback):      \n        if not self.print_level or level <= self.print_level:\n            sys.stdout.write(message + "\\n")\n        if level <= self.log_level:\n            severity = self.level_map.get(level, str(level))\n            self.log.write(severity + message + "\\n")\n\n        if callback:\n            function, args, kwargs = callback\n            return function(*args, **kwargs)\n\n            \nclass Metapython(base.Reactor):\n\n    defaults = defaults.Metapython\n        \n    parser_ignore = ("environment_setup", "prompt", "copyright", \n                     "traceback", "memory_size", "network_packet_size", \n                     "interface", "port")\n                     \n    parser_modifiers = {"command" : {"types" : ("positional", ),\n                                     "nargs" : \'?\'},\n                        "help" : {"types" : ("short", "long"),\n                                  "nargs" : \'?\'}\n                        }\n    exit_on_help = False\n\n    def __init__(self, **kwargs):\n        super(Metapython, self).__init__(**kwargs)\n        self.setup_os_environ()\n        self.processor = self.create("vmlibrary.Processor")        \n        self.alert_handler = self.create(Alert_Handler)\n\n        if self.startup_definitions:\n            Instruction(self.instance_name, "exec_command", \n                        self.startup_definitions).execute() \n                        \n        if self.interpreter_enabled:\n            Instruction(self.instance_name, "start_service").execute()\n                       \n    def exec_command(self, source):\n        code = compile(source, \'Metapython\', \'exec\')\n        \n        exec code in globals(), globals()\n\n    def setup_os_environ(self):\n        modes = {"=" : "equals",\n                 "+=" : "__add__", # append strings or add ints\n                 "-=" : "__sub__", # integer values only\n                 "*=" : "__mul__",\n                 "/=" : "__div__"}\n\n        for command in self.environment_setup:\n            variable, mode, value = command.split()\n            if modes[mode] == "equals":\n                result = value\n            else:\n                environment_value = os.environ[variable]\n                method = modes[mode]\n                result = getattr(environment_value, method)(value)\n            os.environ[variable] = result\n            \n    def start_machine(self):\n        with open(self.command, \'r\') as user_module:\n            source = user_module.read()\n                       \n        Instruction(self.instance_name, "exec_command", source).execute()\n                   \n        self.processor.run()       \n    \n    def start_service(self):\n        server_options = {"name" : self.instance_name,\n                          "interface" : self.interface,\n                          "port" : self.port}  \n        \n        self.server = self.create(Interpreter_Service, **server_options)      \n        \n    def exit(self, exit_code=0):\n        Instruction("Processor", "set_attributes", running=False).execute()\n        # cleanup/finalizers go here?\n\n    def save_state(self):\n        """ usage: metapython.save_state()\n        \n            Stores a snapshot of the current runtime environment. \n            This file is saved as metapython._suspended_file_name, which\n            defaults to "suspended_interpreter.bin"."""            \n        with open(self._suspended_file_name, \'wb\') as pickle_file:\n            pickle.dump(self.environment, pickle_file)            \n            pickle_file.flush()\n            pickle_file.close()\n                    \n    @staticmethod\n    def load_state(pickle_filename):\n        """ usage: from metapython import *\n                    Metapython.load_state(pickle_filename) => interpreter\n                    \n            Load an environment that was saved by Metapython.save_state.\n            The package global mpre.environment is updated with the\n            contents of the restored environment, and the component at\n            environment.Component_Resolve["Metapython"] is returned by this\n            method.\n            \n            """\n        import mpre\n        \n        with open(pickle_filename, \'rb\') as pickle_file:\n            mpre.environment.update(pickle.load(pickle_file))\n            pickle_file.close()\n\n        interpreter = mpre.environment.Component_Resolve["Metapython"]\n        interpreter.setup_os_environ()\n        return interpreter\n        \n \nclass Restored_Interpreter(Metapython):\n    """ usage: Restored_Intepreter(filename="suspended_interpreter.bin") => interpreter\n    \n        Restores an interpreter environment that has been suspended via\n        metapython.Metapython.save_state. This is a convenience class\n        over Metapython.load_state; instances produced by instantiating\n        Restored_Interpreter will be of the type of instance returned by\n        Metapython.load_state and not Restored_Interpreter"""\n        \n    defaults = defaults.Metapython.copy()\n    defaults.update({"filename" : \'suspended_interpreter.bin\'})\n    \n    def __new__(cls, *args, **kwargs):\n        instance = super(Restored_Interpreter, cls).__new__(cls, *args, **kwargs)\n        attributes = cls.defaults.copy()\n        if kwargs.get("parse_args"):\n            attributes.update(instance.parser.get_options(cls.defaults))       \n        \n        return Metapython.load_state(attributes["filename"])\n        \nif __name__ == "__main__":\n    metapython = Metapython(verbosity=\'vvv\', parse_args=True)\n    metapython.start_machine()\n    metapython.alert("{} shutting down", [metapython.instance_name], level=\'v\')'
tp23
a(Vnetwork.py
S'#   mpf.network_library - Asynchronous socket operations\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\nimport socket\nimport select\nimport struct\nimport errno\nimport traceback\n\nimport mpre\nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nfrom utilities import Latency, Average\nInstruction = mpre.Instruction\n\nERROR_CODES = {}\ntry:\n    CALL_WOULD_BLOCK = errno.WSAEWOULDBLOCK\n    BAD_TARGET = errno.WSAEINVAL\n    CONNECTION_IN_PROGRESS = errno.WSAEWOULDBLOCK\n    CONNECTION_IS_CONNECTED = errno.WSAEISCONN\n    CONNECTION_WAS_ABORTED = errno.WSAECONNABORTED\n    CONNECTION_RESET = errno.WSAECONNRESET\n    \n    ERROR_CODES[BAD_TARGET] = "BAD_TARGET"\n    \nexcept:\n    CALL_WOULD_BLOCK = errno.EWOULDBLOCK\n    CONNECTION_IN_PROGRESS = errno.EINPROGRESS\n    CONNECTION_IS_CONNECTED = errno.EISCONN\n    CONNECTION_WAS_ABORTED = errno.ECONNABORTED\n    CONNECTION_RESET = errno.ECONNRESET\n \nERROR_CODES.update({CALL_WOULD_BLOCK : "CALL_WOULD_BLOCK",\n                    CONNECTION_IN_PROGRESS : "CONNECTION_IN_PROGRESS",\n                    CONNECTION_IS_CONNECTED : "CONNECTION_IS_CONNECTED",\n                    CONNECTION_WAS_ABORTED : "CONNECTION_WAS_ABORTED",\n                    CONNECTION_RESET  : "CONNECTION_RESET"})\n               \nHOST = socket.gethostbyname(socket.gethostname())\n\nclass Error_Handler(object):\n            \n    def connection_reset(self, sock, error):\n        sock.handle_connection_reset()\n        \n    def connection_was_aborted(self, sock, error):\n        sock.close()\n        sock.delete()\n        \n    def eagain(self, sock, error):\n        sock.alert("{}", [error], level=0)\n        \n    def unhandled(self, sock, error):\n        sock.alert("Unhandled error:\\n{}", [error], level=0)\n        \n        \nclass Socket(base.Wrapper):\n\n    defaults = defaults.Socket\n\n    def _get_recv_method(self):\n        return self.recvfrom\n    _network_recv = property(_get_recv_method)\n    \n    def __init__(self, family=socket.AF_INET, type=socket.SOCK_STREAM,\n                       proto=0, **kwargs):\n        kwargs.setdefault("wrapped_object", socket.socket(family, type, proto))\n        super(Socket, self).__init__(**kwargs)\n        self.socket = self.wrapped_object\n        self.setblocking(self.blocking)\n        self.settimeout(self.timeout)\n        self.error_handler = Error_Handler()\n        if self.add_on_init:\n            self.added_to_network = True\n            self.parallel_method("Network", "add", self)\n         \n    def send(self, data):\n        return self.parallel_method("Network", "send", self, data)\n                             \n    def sendto(self, data, host_info):\n        return self.parallel_method("Network", "sendto", \n                                    self, data, host_info)\n    def recv(self, buffer_size=0):\n        buffer_size = (self.network_packet_size if not buffer_size else\n                       buffer_size)\n        return self.wrapped_object.recv(buffer_size)\n        \n    def recvfrom(self, buffer_size=0):\n        buffer_size = (self.network_packet_size if not buffer_size else\n                       buffer_size)\n        return self.wrapped_object.recvfrom(buffer_size)\n        \n    def delete(self):\n        self.close()        \n        super(Socket, self).delete()\n    \n    def close(self):\n        if self.added_to_network:\n            self.parallel_method("Network", "remove", self)\n        self.wrapped_object.close()\n        \n       \nclass Tcp_Socket(Socket):\n\n    defaults = defaults.Tcp_Socket\n    \n    def _get_recv_method(self):\n        return self.recv\n    _network_recv = property(_get_recv_method)\n    \n    def __init__(self, **kwargs):\n        kwargs.setdefault("wrapped_object", socket.socket(socket.AF_INET,\n                                                          socket.SOCK_STREAM))\n        super(Tcp_Socket, self).__init__(**kwargs)\n\n        \nclass Server(Tcp_Socket):\n\n    defaults = defaults.Server\n\n    def __init__(self, **kwargs):       \n        super(Server, self).__init__(**kwargs)\n        self.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, self.reuse_port)\n\n        bind_success = True\n        try:\n            self.bind((self.interface, self.port))\n        except socket.error:\n            self.alert("socket.error when binding to {0}", (self.port, ), 0)\n            bind_success = self.handle_bind_error()\n        if bind_success:\n            self.listen(self.backlog)\n\n    def recv(self):\n        _socket, address = self.accept()\n        \n        connection = self.create(self.Tcp_Socket_type,\n                                 wrapped_object=_socket)\n        \n        self.alert("{} accepted connection {} from {}", \n                  (self.name, connection.instance_name, address),\n                  level="v")\n        \n        self.on_connect(connection)\n\n    def handle_bind_error(self):\n        if self.allow_port_zero:\n            self.bind((self.interface, 0))\n            return True\n        else:\n            self.alert("{0}\\nAddress already in use. Deleting {1}\\n",\n                       (traceback.format_exc(), self.instance_name), 0)\n            instruction = Instruction(self.instance_name, "delete")\n            instruction.execute()\n \n    def on_connect(self, connection):\n        raise NotImplementedError \n        \n        \nclass Tcp_Client(Tcp_Socket):\n\n    defaults = defaults.Tcp_Client\n\n    def __init__(self, **kwargs):\n        super(Tcp_Client, self).__init__(**kwargs)\n        \n        if not self.target:\n            if not self.ip:\n                self.alert("Attempted to create Tcp_Client with no host ip or target", tuple(), 0)\n            self.target = (self.ip, self.port)\n        \n        self.parallel_method("Connection_Manager", "add", self)\n                \n    def unhandled_error(self):\n        print "unhandled exception for", self.instance_name\n        self.delete()\n\n    def attempt_connection(self):\n        self.stop_connecting = True\n        if not self.connect_attempts:\n            self.alert("{0} to {1} timed out after {2} frames", (self.instance_name, self.target, self.timeout), 0)\n            self.delete()\n\n        else:\n            self.connect_attempts -= 1\n            try: # non blocking connect\n                self.connect(self.target)\n            except socket.error as socket_error:\n                error = socket_error.errno\n                \n                if error == CONNECTION_IS_CONNECTED: # complete\n                    self.parallel_method("Network", "add", self)\n                    self.added_to_network = True\n                    self.on_connect()                    \n                                        \n                elif error in (CALL_WOULD_BLOCK, CONNECTION_IN_PROGRESS): # waiting\n                    self.alert("waiting for connection to {}", (self.target, ), level="vv")\n                    self.stop_connecting = False\n\n                elif error == BAD_TARGET: #10022: # WSAEINVALID bad target\n                    self.alert("WSAEINVALID bad target", [self.instance_name], level=self.bad_target_verbosity)\n                    self.delete()\n                    \n                else:\n                    print "unhandled exception for", self.instance_name\n                    print traceback.format_exc()\n                    self.delete()\n            else:\n                self.added_to_network = True\n                self.on_connect()                \n                \n        return self.stop_connecting\n        \n    def on_connect(self):\n        raise NotImplementedError\n        \n        \nclass Udp_Socket(Socket):\n\n    defaults = defaults.Udp_Socket\n\n    def __init__(self, **kwargs):\n        kwargs.setdefault("wrapped_object", socket.socket(socket.AF_INET, socket.SOCK_DGRAM))\n        super(Udp_Socket, self).__init__(**kwargs)        \n               \n        if self.bind_on_init:\n            self.bind((self.interface, self.port))\n            \n        if not self.port:\n            self.port = self.getsockname()[1]\n                   \n        \nclass Multicast_Beacon(Udp_Socket):\n\n    defaults = defaults.Multicast_Beacon\n\n    def __init__(self, **kwargs):\n        super(Multicast_Beacon, self).__init__(**kwargs)\n        self.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, self.packet_ttl)\n\n\nclass Multicast_Receiver(Udp_Socket):\n\n    defaults = defaults.Multicast_Receiver\n\n    def __init__(self, **kwargs):\n        super(Multicast_Receiver, self).__init__(**kwargs)\n\n        # thanks to http://pymotw.com/2/socket/multicast.html for the below\n        group_option = socket.inet_aton(self.address)\n        multicast_configuration = struct.pack("4sL", group_option, socket.INADDR_ANY)\n        self.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, multicast_configuration)\n\n\nclass Connection_Manager(vmlibrary.Process):\n\n    defaults = defaults.Connection_Manager\n        \n    def __init__(self, **kwargs):        \n        super(Connection_Manager, self).__init__(**kwargs)\n        self.buffer = []\n        self.running = False\n        \n    def add(self, sock):\n        self.running = True\n        self.buffer.append(sock)\n        self.parallel_method("Network", "_run")\n        \n    def run(self):\n        running = False\n        buffer = self.buffer\n        new_buffer = self.buffer = []\n        while buffer:\n            \n            connection = buffer.pop()     \n            if not connection.deleted and not connection.attempt_connection():\n                running = True\n                new_buffer.append(connection)          \n        \n        self.running = running\n           \n\nclass Network(vmlibrary.Process):\n\n    defaults = defaults.Network\n   \n    def __init__(self, **kwargs):\n        # minor optimization; pre allocated slices and ranges for\n        # sliding through the socket list to sidestep the 500 \n        # file descriptor limit that select has. Produces slice objects\n        # for ranges 0-500, 500-1000, 1000-1500, etc, up to 5000.\n        self._slice_mapping = dict((x, slice(x * 500, (500 + x * 500))) for \n                                    x in xrange(10))\n        self._socket_range_size = range(1)\n        \n        self.send_buffer = {}\n        self.sendto_buffer = {}\n        self.writable = set()\n        super(Network, self).__init__(**kwargs)\n        self.sockets = self.objects["Socket_Objects"] = []\n        self.late_sends = self.delayed_sendtos = self.delayed_sends = self.running = False\n                        \n        self.connection_manager = self.create(Connection_Manager)\n        self.sockets.remove(self.connection_manager)\n        \n        instruction = self.update_instruction = Instruction("Network", "_update_range_size")        \n        instruction.execute(self.update_priority)\n  \n    def add(self, sock):\n        super(Network, self).add(sock)\n        self.sockets.append(sock)\n        self._run()\n    \n    def remove(self, sock):\n        super(Network, self).remove(sock)\n        self.sockets.remove(sock)\n        \n    def _run(self):\n        if not self.running:\n            self.run_instruction.execute(priority=self.priority)\n            self.running = True\n                   \n    def _update_range_size(self):\n        self._socket_range_size = range((len(self.sockets) / 500) + 1)\n        self.update_instruction.execute(self.update_priority)\n\n    def run(self):\n        if self.connection_manager.running:\n            self.connection_manager.run()\n        \n        sockets = self.sockets\n        \n        if sockets:\n            for chunk in self._socket_range_size:\n                # select has a max # of file descriptors it can handle, which\n                # is about 500 (at least on windows). We can avoid this limitation\n                # by sliding through the socket list in slices of 500 at a time\n                socket_list = sockets[self._slice_mapping[chunk]]\n\n                readable, writable, errors = select.select(socket_list, socket_list, [], 0.0)\n                \n                self.writable = writable\n                \n                if readable:\n                    self.handle_reads(readable)                \n\n            if self.late_sends:\n                self.handle_delayed_sends(writable)\n                                        \n            self.run_instruction.execute(priority=self.priority)\n        else:\n            self.running = False\n       \n    def handle_delayed_sends(self, writable):\n        self.late_sends = False\n        if self.delayed_sends:\n            self.delayed_sends = False\n            resends = ((sock, self.send_buffer.pop(sock)) for sock, messages in\n                        self.send_buffer.items() if sock in writable)\n            self.alert("sending delayed tcp sends", level=0)\n            \n            for sender, messages in resends:\n                for data in messages:\n                    self.alert("Sending {} on {}",\n                               [data[:128], sender],\n                               level=0)\n                    self.send(sender, data)\n        \n        if self.delayed_sendtos:\n            self.delayed_sendtos = False\n            resends = ((sock, self.sendto_buffer.pop(sock)) for sock, message in\n                        self.sendto_buffer.items() if sock in writable)\n            self.alert("sending delayed udp sendto\'s", level=0)\n            \n            for sender, messages in resends:\n                for data, host_info in messages:\n                    self.sendto(sender, data, host_info)\n                    \n    def handle_reads(self, readable_sockets):\n        for sock in readable_sockets:\n            try:\n                sock._network_recv()\n            except socket.error as error:       \n                handler = getattr(sock.error_handler, \n                                  ERROR_CODES[error.errno].lower(),\n                                  sock.error_handler.unhandled)\n                    \n    def send(self, sock, data):   \n        if sock in self.writable:\n            byte_count = sock.wrapped_object.send(data)          \n        else:\n            self.alert("{} not writable; delaying send of {} bytes",\n                       (sock.instance_name, len(data)),\n                       level=0)\n                       \n            self.late_sends = self.delayed_sends = True\n            byte_count = 0\n            try:\n                self.send_buffer[sock].append(data)\n            except KeyError:\n                self.send_buffer[sock] = [data]\n        return byte_count\n        \n    def sendto(self, sock, data, host_info):\n        if sock in self.writable:\n            byte_count = sock.wrapped_object.sendto(data, host_info)\n        else:\n            self.alert("{} not writable; delaying send of {} bytes",\n                       (sock.instance_name, len(data)),\n                       level=0)\n                       \n            self.late_sends = self.delayed_sendtos = True\n            delayed_sendto = (data, host_info)\n            byte_count = 0\n            try:\n                self.sendto_buffer[sock].append(delayed_sendto)\n            except KeyError:\n                self.sendto_buffer[sock] = [delayed_sendto]\n        return byte_count'
tp24
a(Vnetwork2.py
S'import os\nimport collections\nimport hmac\nimport getpass\nimport hashlib\nimport sqlite3\nimport binascii\nimport functools\n\nimport mpre\nimport mpre.base as base\nimport mpre.defaults as defaults\nimport mpre.network as network\nimport mpre.fileio as fileio\nfrom mpre.utilities import Latency, timer_function\nInstruction = mpre.Instruction\n           \ndef Authenticated(function):\n    def call(instance, sender, packet):\n        if sender in instance.logged_in:\n            response = function(instance, sender, packet)\n        else:\n            response = "login_result 0"\n        return response\n    return call\n    \n    \nclass Network_Service(network.Udp_Socket):\n    \n    defaults = defaults.Network_Service\n    \n    end_request_errors = {"0" : "Invalid Request"}\n    \n    def __init__(self, **kwargs):\n        super(Network_Service, self).__init__(**kwargs)\n        self.expecting_response = collections.deque(maxlen=20)\n        self.received = collections.deque(maxlen=20)\n        self.packet_cache = collections.deque(maxlen=20)\n        self._return_to = {}\n        self.sent_at = {}\n        self.resent = set()\n\n    def socket_recv(self):\n        packet, sender = self.recvfrom(self.network_packet_size)\n\n        # (hopefully) reliable udp mechanisms\n        id, response_to, data = packet.split(" ", 2)     \n        self.received.append(response_to)\n        request = (sender, response_to)\n        \n        self.alert("Checking to see if {} is expected",\n                   [request],\n                   level=\'vv\')    \n        try:                   \n            self.expecting_response.remove(request)\n        except ValueError:\n            if response_to == "None":\n                self.alert("Received a new connection {}",\n                           [id],\n                           \'vv\')\n            else:\n                self.alert("Received duplicate packet {}",\n                           [id],\n                           level=\'vv\')\n                if request in self.resent:\n                    self.resent.remove(request)  \n                else:\n                    return\n        \n        # packet parsing\n        end_of_request = False\n        if response_to in self._return_to:\n            command = self._return_to[response_to]\n            value = data\n            if value[:11] == "end_request":\n                value = value[11:]\n                end_of_request = True\n        else:\n            if data[:11] == "end_request":\n                data = data[12:]\n                end_of_request = True\n            try:\n                command, value = data.split(" ", 1)\n            except ValueError:\n                if not end_of_request: # malformed request\n                    response = self.invalid_request(sender, packet)\n                    self.send_data(response, sender, response_to, False)  \n                    return\n\n        if end_of_request:\n            self.alert("Request finished {}",\n                       [request],\n                       \'vv\')\n            return\n            \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        #print "reaction: ", self.instance_name, command, value[:45]\n        response = getattr(self, command)(sender, value)\n        response = response if response else "end_request"\n        expect_response = response[:11] != "end_request"\n        \n        self.alert("Sending response: {} in response to {}",\n                   [response, id],\n                   level=\'vvv\')\n        self.send_data(response, sender, response_to, expect_response)\n        \n        #self._handle_resends()\n        \n    def send_data(self, data, to=None, \n                  response_to=\'None\', expect_response=True):\n        reaction = \'\'\n        lowercase_data = data.lower()\n        \n        if lowercase_data[:6] == "return":\n            flag, reaction, data = data.split(" ", 2)\n        \n        id, packet = self._make_packet(response_to, data)\n        \n        if reaction:\n            self._return_to[id] = reaction\n            \n        if to[0] == "localhost":\n            to = ("127.0.0.1", to[1])                            \n        \n        self.sendto(packet, to)\n        \n        if expect_response:\n            self.expecting_response.append((to, id))\n            \n        self.packet_cache.append((id, packet))\n        self.sent_at[id] = timer_function()\n        self.alert("sent packet {} {} to {} in response to {}",\n                   [id, data[:32], to, response_to],\n                   level=\'vv\')                               \n        \n    def _handle_resends(self):\n        packet_cache = dict((id, packet) for id, packet in self.packet_cache)\n        sent_at = self.sent_at\n        resend_after = .2\n        \n        for target, id in self.expecting_response:\n            if timer_function() - sent_at[id] > resend_after:\n                packet = packet_cache[id]\n                \n                self.alert("Resending {}",\n                           [id],\n                           level=0)\n                        \n                self.parallel_method("Network", "send", \n                                self,\n                                packet,\n                                target)\n                self.resent.add((target, id))               \n               \n    def invalid_request(self, sender, packet):\n        self.alert("Invalid reaction request\\nFrom:{}\\nPacket:{}",\n                   [sender, packet],\n                   level=0)\n                                    \n        return "end_request invalid_request " + packet\n    \n    def _make_packet(self, response_to, data):\n        message = response_to + " " + data\n        id = str(hash(message))\n        return id, id + " " + message\n        \n    def demo_reaction(self, sender, packet):\n        print "im a demo reaction for", sender, packet\n        counter = int(packet)\n        if counter >= 1000:\n            print "1000 reactions happened between {} and {}".format(self, sender)\n            response = \'\'\n        else:\n            response = "demo_reaction " + str(counter + 1)\n        return response\n        \n        \nclass Authenticated_Service(base.Reactor):\n    \n    defaults = defaults.Authenticated_Service\n                \n    def __init__(self, **kwargs):\n        super(Authenticated_Service, self).__init__(**kwargs)\n        self.invalid_attempts = {}\n        self.logged_in = {}\n        \n        db = self.database = sqlite3.connect(self.database_filename)\n        db.text_factory = str\n                    \n        cursor = db.cursor()\n        \n        cursor.execute("CREATE TABLE IF NOT EXISTS Credentials(" + \n                       "email TEXT, username TEXT, password TEXT" +\n                       ", address TEXT)")\n                       \n        self._add_user = \'\'\'INSERT INTO Credentials VALUES(?, ?, ?, ?)\'\'\'\n        self._remove_user = "DELETE FROM Credentials WHERE username=:username"\n        self._select_user = """SELECT username, password FROM Credentials WHERE username = ?"""\n            \n    def _sql_encrypt(self, password, salt=None):\n        salt = os.urandom(64) if not salt else salt\n        iterations = self.hash_rounds\n        digest = salt + password\n        hash_functions = dict((name, getattr(hashlib, name)) for name in \n                               hashlib.algorithms if name != "pbkdf2_hmac")         \n        while iterations > 0:\n            for hash_function in hashlib.algorithms:\n                digest = hash_functions[hash_function](digest).digest()\n                iterations -= 1\n        return salt + digest\n        \n    def __reduce__(self):\n        state = self.__dict__.copy()\n        del state["database"]\n        del state["log_file"]\n        return (self.__class__, tuple(), state, None, None)\n        \n    def login(self, sender, packet):\n        username, password = packet.split(" ", 1)\n        \n        if username in self.logged_in.values():\n            return \'login_result failed 1\'\n            \n        database = self.database#sqlite3.connect(self.database_filename)\n        cursor = database.cursor()\n        \n        self.alert("{} attempting to login from {}",\n                   [username, sender],\n                   level=\'v\')                   \n        \n        cursor.execute(self._select_user, [username])       \n        database.commit()            \n        try:\n            username, correct_password = cursor.fetchone()\n        except TypeError as error:\n            response = "register "\n            message = ("Please register username before logging in\\n" +\n                       "Registration requires:" + "\\n\\temail: {}" + \n                       "\\n\\tusername: {}" + "\\n\\tpassword: {}")\n            response += message\n            database.rollback()            \n        else:\n            hashed = self._sql_encrypt(password, correct_password[:64])\n            if (hmac.compare_digest(hashed, correct_password) if \n                hasattr(hmac, "compare_digest") else \n                hashed == correct_password):\n                     \n                self.logged_in[sender] = username\n                response = "success " + self.login_message\n            else:\n                invalid_attempts = self.invalid_attempts\n                \n                attempts = invalid_attempts.get(sender, 0)\n                invalid_attempts.setdefault(sender, attempts + 1)\n                response = "failed 0"            \n                \n        return "login_result " + response\n        \n    def register(self, sender, packet):\n        database = self.database#sqlite3.connect(self.database_filename)\n        cursor = database.cursor()\n        \n        email, username, password = packet.split(" ", 2)\n\n        self.alert("Registering new user {} {} {}",\n                   [email, username, sender],\n                   level=\'v\')\n       \n        try:\n            cursor.execute(self._add_user, (email, username,\n                                            self._sql_encrypt(password), str(sender)))\n            \n        except sqlite3.Error as error:            \n            self.alert("Database error: {}",\n                       [error],\n                       0)\n            database.rollback()\n            response = \'failed\'\n        else:\n            database.commit()\n            response = "success"\n            \n            self.alert("{} {} {} registered successfully",\n                       [username, email, sender],\n                       level=\'vv\')\n        return "register_results " + response\n\n    def logout(self, sender, packet):\n        if sender in self.logged_in:            \n            del self.logged_in[sender]\n    \n    @Authenticated\n    def modify_user(self, sender, packet):\n        mode, user = packet.split(" ", 1)\n        database = sqlite3.connect(self.database_filename)\n        cursor = database.cursor()\n        \n        if mode == "remove":\n            cursor.execute(self._remove_user, \n                          {"Username" : self.logged_in[sender]})\n            database.commit()\n            del self.logged_in[user]\n\n      \nclass Authenticated_Client(base.Reactor):\n            \n    defaults = defaults.Authenticated_Client\n    \n    login_errors = {"0" : "Invalid username or password",\n                    "1" : "Already logged in"}\n                    \n    def __init__(self, **kwargs):\n        super(Authenticated_Client, self).__init__(**kwargs)        \n        self.logged_in = False\n        self.reaction(self.target, self.login())        \n        \n    def login(self, sender=None, packet=None):\n        self.alert("Attempting to login", level=0)#\'v\')\n        \n        username = (self.username if self.username else \n                    raw_input("Please provide username for {}: ".format(\n                               self.instance_name)))\n                    \n        password = self.password if self.password else getpass.getpass()\n        return "login {} {}".format(username, password)\n                \n    def register(self, sender, packet):        \n        self.alert(packet, \n                  (self.email, self.username, "*" * len(self.password)),\n                   level=0)\n        \n        email = (self.email if self.email else \n                 raw_input("Please register an email address: "))\n        while \' \' in email:\n            self.alert("Invalid email address. Cannot contain spaces",\n                       level=0)\n            email = (self.email if self.email else \n                     raw_input("Please register an email address: "))\n                 \n        username = (self.username if self.username else \n                    raw_input("Please register a username: "))\n                    \n        password = self.password if self.password else getpass.getpass()        \n        \n        return "register {} {} {}".format(email, username, password)\n    \n    def register_results(self, sender, packet):\n        if "success" in packet:\n            return self.login(sender, packet)\n        else:\n            self.alert("Error encountered when attempting to register with {}\\n{}",\n                       [sender, packet])\n        \n    def login_result(self, sender, packet):\n        if "success" in packet:\n            self.alert(packet, level=0)\n            self.logged_in = True\n        elif "register" in packet:\n            flag, message = packet.split(" ", 1)\n            return self.register(sender, message)\n        else:\n            failed, code = packet.split(" ", 1)\n            error = self.login_errors[code]\n            self.alert("Login failed; {}", [error], level=0)\n        \n        \nclass Service_Listing(Network_Service):\n    defaults = defaults.Network_Service.copy()\n    \n    def __init__(self, **kwargs):\n        self.services = {}\n        super(Service_Listing, self).__init__(**kwargs)\n        \n    def set_service(self, sender, packet):\n        service_name, address = packet.split(" ", 1)                \n        self.services[address] = service_name\n        return "set success"\n        \n    def remove_service(self, sender, packet):\n        service_name, address = packet.split(" ", 1)\n        del self.services[address]\n        \n    def send_listing(self, sender, packet):\n        return "\\n".join("Address: {: >20} Service: {: > 5}".format\\\n                        (address, service_info) for  address, service_info\\\n                        in self.services.items())\n            \n           \nclass File_Service(base.Reactor):\n    defaults = defaults.File_Service\n    \n    def __init__(self, **kwargs):\n        super(File_Service, self).__init__(**kwargs)\n                \n    def slice_request(self, sender, slice_info):\n        filename, file_position, request_size = slice_info.split()\n        seek_index = int(file_position)\n        request_size = int(request_size)\n        \n        if request_size >= self.mmap_threshold:\n            _file, offset = fileio.Mmap(filename, seek_index)\n            data = _file[offset:offset + request_size]            \n        \n        else:\n            _file = open(filename, \'rb\')\n            _file.seek(seek_index)\n            data = _file.read(request_size)\n            _file.close()\n            \n        self.alert("retrieved {}/{} bytes of data/requested", \n                   [len(data), request_size],\n                   level=\'vv\')\n        return "record_data " + file_position + " " + data        \n        \n    def get_filesize(self, sender, filename):\n        try:\n            response = str(os.path.getsize(filename))\n        except WindowsError:\n            response = "0"\n        return "set_filesize " + response\n                  \n  \nclass Download(base.Reactor):\n    \n    defaults = defaults.Download\n    \n    def __init__(self, **kwargs):\n        super(Download, self).__init__(**kwargs)\n        self.data_remaining = 0\n        \n        filename = self.filename\n        self.file = open("{}_{}".format(self.filename_prefix, filename), \'wb\')    \n                \n        self.reaction(self.target, "get_filesize " + filename)                  \n                \n    def make_request(self):\n        if self.bytes_remaining > 0:\n            file_position = self.file.tell()\n            request_size = min(self.bytes_remaining, self.network_packet_size)\n            request = "{} {} {} {}".format("slice_request",\n                                            self.filename, \n                                            file_position, \n                                            request_size)\n        else:\n            request = ""\n            self.alert("finished downloading, sending close request" + "*"*40, level=0)\n            self.file.close()\n        return request\n                \n    def set_filesize(self, sender, value):\n        filesize = int(value)\n        if filesize:\n            self.bytes_remaining = filesize\n            return self.make_request()            \n        else:\n            self.alert("File {} was not available for download from {}",\n                       [self.filename, self.target])        \n        \n    def record_data(self, sender, data):\n        file_position, file_data = data.split(" ", 1)\n        seek_position = int(file_position)\n        \n        file = self.file\n        file.seek(seek_position)        \n        file.write(data)\n        file.flush()\n        self.bytes_remaining -= file.tell() - seek_position\n        return self.make_request()\n        \n        \nclass Tcp_Service_Proxy(network.Server):\n\n    def __init__(self, **kwargs):\n        super(Tcp_Service_Proxy, self).__init__(**kwargs)\n        self.inbound_connection_type = Tcp_Client_Proxy\n                    \n    def on_connect(self, connection):\n        pass\n        \n        \nclass Tcp_Client_Proxy(network.Tcp_Client):\n    \n    def recv(self):\n        print self.instance_name, "receiving data!"\n        request = self.socket.recv(self.network_packet_size)        \n        service_name, command, value = request.split(" ", 2)\n        self.respond_with(self.reply)\n        request = command + " " + value\n        self.reaction(service_name, request)\n              \n    def reply(self, sender, packet):\n        self.send_data(str(sender) + " " + packet)\n\n                           \nclass Tcp_Service_Test(network.Tcp_Client):\n    \n    def on_connect(self):        \n        self.send_data("Interpreter_Service login username password")\n                           \n    def recv(self):\n        self.network_buffer += self.recv(self.network_packet_size)\n        print "got results!: ", self.network_buffer\n        \ndef test_proxy():\n    verbosity = \'vvv\'\n    options = {"verbosity" : verbosity,\n               "port" : 40000}\n               \n    options2 = {"verbosity" : verbosity,\n                "target" : ("localhost", 40000)}\n                \n    Instruction("Metapython", "create", "network2.Tcp_Service_Proxy", **options).execute()\n    Instruction("Metapython", "create", "network2.Tcp_Service_Test", **options2).execute()\n    \ndef test_reliability():\n    Instruction("Metapython", "create", Network_Service, port=4000, verbosity=\'vvv\').execute()\n    Instruction("Metapython", "create", Network_Service, port=4001, verbosity=\'vvv\').execute()\n    Instruction("Network_Service1", "send_data", "demo_reaction 0", to=("localhost", 4000)).execute()\n\n    \nif __name__ == "__main__":\n    from mpre.tests.network2 import test_file_service, test_authentication\n    test_reliability()\n   # test_authentication()\n   # test_file_service()\n   # test_proxy()'
tp25
a(Vpackage.py
S'import os\nimport importlib\nimport traceback\nimport contextlib\n\nimport mpre\nimport mpre.base as base\nimport mpre.defaults as defaults\nimport mpre.fileio as fileio\nimport mpre.utilities as utilities\nensure_file_exists = fileio.ensure_file_exists\nensure_folder_exists = fileio.ensure_folder_exists\n\n@contextlib.contextmanager\ndef ignore_instructions():\n    backup = mpre.environment.Instructions\n    try:\n        yield\n    finally:\n        mpre.environment.Instructions = backup\n        \n\nclass Package(base.Base):\n            \n    defaults = defaults.Base.copy()\n    defaults.update({"package_name" : \'\',\n                     "subfolders" : tuple(),\n                     "directory" : \'\',\n                     "store_source" : True,\n                     "make_docs" : True})\n                     \n    def __init__(self, **kwargs):\n        self.files = {}\n        self.file_source = {}\n        super(Package, self).__init__(**kwargs)\n        \n        self.directory = self.directory if self.directory else os.getcwd()\n        \n        if not self.package_name:\n            self.package_name = raw_input("Please provide the package name: ")\n        self.update_structure()\n        \n        if self.make_docs:\n            self.create(Documentation, package=self)\n    \n    def init_filename_in(self, path):\n        return os.path.join(path, "__init__.py")\n    \n    @staticmethod\n    def from_directory(top_directory, dirnames):  \n        folder_paths = [(top_directory, os.path.split(top_directory)[-1])]\n        for directory in os.listdir(top_directory):\n            path = os.path.join(top_directory, directory)\n            if os.path.isdir(path):\n                folder_paths.append((path, directory))    \n        \n        file_package = {}            \n        for full_path, folder in folder_paths:\n            file_package[folder] = [os.path.join(full_path, _file) for _file in \n                                    os.listdir(full_path) if "_" != _file[0] and\n                                    os.path.splitext(_file)[-1] == ".py"]\n        return file_package \n    \n    def update_structure(self):\n        directory = self.directory\n        package_name = self.package_name\n        files = self.files\n        \n        folder_path = os.path.join(directory, self.package_name)\n        self.alert("Creating folder structure", level=\'v\')\n        \n        self.make_folder(package_name, folder_path)\n        \n        for subfolder in self.subfolders:\n            print "Building subfolder", subfolder\n            subpath = os.path.join(folder_path, subfolder)\n            self.make_folder(subfolder, subpath)         \n                    \n        self.alert("Finished creating {} folder structure", [self.package_name], level=\'v\')\n  \n    def make_folder(self, subfolder, folder_path):\n        ensure_folder_exists(folder_path)\n        ensure_file_exists(self.init_filename_in(folder_path))\n\n        if subfolder in self.files:\n            self.make_files(subfolder, folder_path, self.files[subfolder])\n            \n    def make_files(self, subfolder, subpath, file_list):\n        new_info = []\n        for file_info in file_list:\n            try:\n                filename, file_data = file_info\n            except ValueError:\n                if not os.path.exists(file_info):\n                    print "path does not exist: ", file_info\n                    assert os.path.exists(file_info)\n                path, filename = os.path.split(file_info)\n                \n                with open(file_info, \'r\') as source_file:\n                    file_data = source_file.read()\n                    source_file.close()                    \n\n            ensure_file_exists(os.path.join(subpath, filename), data=file_data)\n            \n            if self.store_source:\n                new_info.append((filename, file_data))\n                \n        if self.store_source:\n            self.files[subfolder] = new_info\n\n           \nclass Documentation(base.Base):\n    """\n    Generates restructed text .md files from python modules.\n    Writes a mkdocs.yml with the .md files information.\n    Runs mkdocs build to build a site from the .md files\n    """    \n    defaults = defaults.Base.copy()\n    defaults.update({"directory" : os.getcwd(),\n                     "subfolders" : tuple(),\n                     "ignore_directories" : ("docs", ),\n                     "ignore_files" : tuple(),\n                     "site_name" : \'\',\n                     "verbosity" : \'vv\',\n                     "index_page" : tuple(),\n                     "package" : None})\n                    \n    def __init__(self, **kwargs):\n        super(Documentation, self).__init__(**kwargs)\n        if self.package:\n            package = self.package\n            package_name = self.site_name = package.package_name\n            directory = self.directory = os.path.join(package.directory, package_name)\n            os.chdir(self.directory)\n            docs_directory = os.path.join(directory, "docs")\n            ensure_folder_exists(docs_directory)\n            ensure_file_exists(os.path.join(docs_directory, "index.md"),\n                               data="{}\\n{}".format(package_name, "="*15))\n                  \n        if not self.site_name:\n            self.site_name = raw_input("Please enter site name: ")\n        \n        if not self.index_page:\n            self.index_page = ["index.md", "Homepage"]\n            \n        self.update()\n        \n    def update(self):     \n        directory = self.directory      \n        \n        subfolders = self.subfolders if self.subfolders\\\n                     else [name for name in os.listdir(directory) if \n                           name not in self.ignore_directories and\n                           os.path.isdir(os.path.join(directory, name))]\n                               \n        subfolders.insert(0, directory)\n        \n        package_name = os.path.split(directory)[-1]             \n        site_name = "site_name: {}\\n".format(self.site_name)\n        index_page = self.index_page\n        page_entries = \'\'        \n        page_section = "pages:\\n"\n        page_string = "- [\'{}\', \'{}\', \'{}\']\\n"  \n        \n        md_files = []\n        for subfolder in subfolders:\n            dest_folder = subfolder if subfolder != directory else package_name\n            subfolder_path = os.path.join(directory, subfolder)\n            ensure_folder_exists(os.path.join(directory, "docs", dest_folder))\n            \n            self.alert("\\nWorking on {}", [subfolder], \'v\')\n            \n            py_files = (_file for _file in os.listdir(subfolder_path)\n                        if _file not in self.ignore_files\n                        and "_" != _file[0] # auto ignore private modules\n                        and os.path.splitext(_file)[-1] == ".py")\n                        \n            for python_file in py_files:\n                module_name, py_extension = os.path.splitext(python_file)\n                md_filename = module_name + ".md"\n                \n                if subfolder == directory:\n                    module_path = \'.\'.join((package_name, module_name))                    \n                    md_filepath = os.path.join(directory, "docs", package_name, md_filename)\n                else:\n                    module_path = ".".join((package_name, subfolder, module_name))\n                    md_filepath = os.path.join(directory, "docs", subfolder, md_filename)\n                    \n                self.alert("Importing {}", [module_path], \'vv\')                \n                try:\n                    md_text = self.generate_md_file(module_path)\n                except ImportError:\n                    self.alert("Could not import {}. Could not create .md file\\n{}",\n                               [module_name, traceback.format_exc()],\n                               0)\n                    continue\n                    \n                with open(md_filepath, \'w\') as md_file:\n                    md_file.write(md_text)\n                    md_file.flush()\n                    md_file.close()\n                \n                self.alert("Created md file {}", [md_filepath], level=\'v\')\n                \n                category_name = subfolder if subfolder != directory else package_name\n                page_entries += page_string.format(os.path.join(category_name, md_filename),\n                                                   category_name,  \n                                                   module_name)\n                                                   \n            file_data = "{}{}- {}\\n{}".format(site_name,\n                                              page_section,\n                                              index_page,\n                                              page_entries)\n        self.write_yml_file(file_data)\n        utilities.shell("mkdocs build", shell=True)\n        return file_data        \n        \n    def generate_md_file(self, module_name):\n        """usage: documentation.generate_md_file(module_name) => documentation"""\n        null_docstring = \'No documentation available\'\n        with ignore_instructions():\n            try:\n                module = importlib.import_module(module_name)\n            except:\n                print traceback.format_exc()\n                documentation = null_docstring\n            else:\n                module_docstring = module.__doc__ if module.__doc__ else null_docstring\n                    \n                documentation = [\'\'.join((module_name, "\\n========\\n", module_docstring))]\n                _from = getattr(module, "__all__", dir(module))\n                    \n                for attribute in getattr(module, "__all__", dir(module)):\n                    module_object = getattr(module, attribute)\n                    if isinstance(module_object, type) and attribute[0] != "_":\n                        docstring = module_object.__doc__ if module_object.__doc__ else null_docstring\n                        documentation.append("\\n" + \'\'.join((attribute, "\\n--------\\n", docstring)))\n                            \n        return "\\n".join(documentation)\n        \n    def write_yml_file(self, file_data):\n        with open("mkdocs.yml", "w") as yml_file:\n            yml_file.write(file_data)\n            yml_file.flush()\n            yml_file.close()\n        self.alert("\\n{}", [file_data], level=\'v\')\n        \n        \nif __name__ == "__main__":\n    subfolders = ["test1", "testagain", "lolcool"]\n    files = {"testagain" : ["C:\\\\users\\\\_\\\\pythonbs\\\\mpre\\\\vmlibrary.py"]}\n    test_package = Package(package_name="Test_Package",\n                           subfolders=subfolders,\n                           files=files)'
tp26
a(Vrestore.py
S'"""Restores an environment suspended by metapython.Metapython.save_state"""\nif __name__ == "__main__":\n    from mpre.metapython import *\n    interpreter = Restored_Interpreter(parse_args=True)\n    interpreter.start_machine()'
tp27
a(Vshell_launcher.py
S'import mpre\n\nInstruction = mpre.Instruction\n\noptions = {"parse_args" : True,\n           "startup_definitions" : \'\'}\n\n# feel free to customize\ndefinitions = \\\n"""import base\n\nconstructor = base.Base()\nenvironment = constructor.environment\n    \ncreate = constructor.create\n\ndef add_to_network(sock):\n    constructor.parallel_method("Network", "add", sock).execute()\n\ndef remove_from_network(sock):\n    Instruction("Network", "remove", sock).execute()\n\ndef add_network_service(address, name):\n    Instruction("Service_Listing", "add_service", address, name).execute()\n\ndef print_components(mode="keys", size=(None, )):\n    _slice = slice(*size)\n    print getattr(constructor.environment.Component_Resolve, mode)()[_slice]\n\ndef get_component(instance_name):\n    return constructor.environment.Component_Resolve[instance_name]\n\ndef delete(instance_name=\'\', instance=None):\n    if instance_name:\n        Instruction(instance_name, "delete").execute()\n    elif instance:\n        instance.delete()\n                    \ndef build_docs(site_name=\'\'):\n    site_name = site_name if site_name else raw_input("Please enter site name: ")\n    \n    Instruction("Metapython", "create", "mpre.docbuilder.Documentation_Builder",\n                 site_name=site_name).execute()\n\nInstruction("Metapython", "save_state").execute()\n                 \nInstruction("Network", "update").execute()                 \n"""\n\noptions["startup_definitions"] += definitions\n\nif __name__ == "__main__":\n    Instruction("Metapython", "create", "metapython.Shell", **options).execute()'
tp28
a(Vupdatetest.py
S'import pickle\nimport sys\nfrom types import MethodType\n\ndef update(instance):\n    stats = pickle.dumps(instance)\n    reload(sys.modules[instance.__module__])\n    return pickle.loads(stats)       \n    \ndef patch(method_name, _class, new_method):\n    setattr(_class, method_name, MethodType(new_method, None, _class))\n    \n    \nif __name__ == "__main__":\n    import testclass\n    instance = testclass.Test_Class(1, 2, 3, False)\n    print "\\noriginal method: "\n    instance.testmethod()\n    \n    def patch(self, *args):\n        print "something different"\n        \n    print "\\nmonkey patched method: "\n    instance.testmethod = MethodType(patch, instance, testclass.Test_Class)\n    instance.testmethod()\n    \n    print "\\nAlternate instance method post patch: "\n    instance2 = testclass.Test_Class(1, 2, 3, True)\n    instance2.testmethod()\n    with open("testclass.py", \'w\') as pyfile:\n        pyfile.write("""class Test_Class(object):\n        \n    def __init__(self, x, y, z, test=True):\n        self.x = x\n        self.y = y\n        self.z = z\n        self.test = test\n        \n    def testmethod(self, *args):\n        print "inside testmethod", self, args\n        print "This method has been updated successfully"\n        \n    class_var = 1337""")\n        pyfile.flush()\n        pyfile.close()\n    instance = update(instance)\n    print "\\ntestmethod after update"\n    instance.testmethod()'
tp29
a(Vuserinput.py
S'import sys\nfrom threading import Thread\n\nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\n\ntry:\n    from msvcrt import getwch, kbhit\n    input_waiting = kbhit\nexcept:\n    import select\n    def input_waiting():\n        return select.select([sys.stdin], [], [], 0.0)[0]\n        \n        \nclass User_Input(vmlibrary.Process):\n\n    defaults = defaults.User_Input\n    \n    def __init__(self, **kwargs):\n        self.listeners = []\n        super(User_Input, self).__init__(**kwargs)        \n        self.thread_started = False\n        self.thread = Thread(target=self.read_input)\n        self.input = \'\'\n        \n    def run(self):\n        if not self.thread_started and input_waiting():\n            self.thread.start()\n            self.thread_started = True\n            \n        if self.input:\n            message = "handle_keystrokes " + self.input\n            for listener in self.listeners:\n                # for reasons still not understood by me, if sys.stdout\n                # is not written to here then at random intervals\n                # newline will be written but listener won\'t receive\n                # keystrokes until the next read_input\n                sys.stdout.write(" \\b")\n                self.reaction(listener, message)\n            self.input = \'\'\n            \n        self.run_instruction.execute(priority=self.priority)\n        \n    def __getstate__(self):\n        dict_copy = self.__dict__.copy()\n        del dict_copy["thread"]\n        return dict_copy\n        \n    def __setstate__(self, state):\n        self.__init__(**state)\n                \n    def add_listener(self, sender, argument):\n        self.listeners.append(sender)\n        \n    def remove_listener(self, sender, argument):\n        self.listeners.remove(sender)\n        \n    def read_input(self):        \n        self.input = sys.stdin.readline()\n        self.thread = Thread(target=self.read_input)\n        self.thread_started = False'
tp30
a(Vutilities.py
S'#   mpf.utilities - shell commands, latency measurement,\n#                    documentation, running average\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport sys\nimport os\nimport time\nimport inspect\nimport subprocess\nimport collections\nimport importlib\n\nif "win" in sys.platform:\n    timer_function = time.clock\nelse:\n    timer_function = time.time\n\ndef shell(command, shell=False):\n    """ usage: shell(\'command string --with args\', \n                     [shell=False]) = > sys.stdout.output from executed command\n                    \n        Launches a process on the physical machine via the operating \n        system shell. The shell and available commands are OS dependent.\n        \n        Regarding the shell argument; from the python docs on subprocess.Popen:\n            "The shell argument (which defaults to False) specifies whether to use the shell as the program to execute. If shell is True, it is recommended to pass args as a string rather than as a sequence."\n            \n        and also:\n        \n            "Executing shell commands that incorporate unsanitized input from an untrusted source makes a program vulnerable to shell injection, a serious security flaw which can result in arbitrary command execution. For this reason, the use of shell=True is strongly discouraged in cases where the command string is constructed from external input" """        \n    process = subprocess.Popen(command.split(), shell=shell)\n    return process.communicate()[0]\n                       \ndef reload_module(module_name):\n    reload(sys.modules[module_name])\n        \ndef resolve_string(string):\n    """Given an attribute string of ...x.y.z, import ...x.y and return z"""\n    module_name = string.split(".")   \n    class_name = module_name.pop(-1)\n    module_name = \'.\'.join(module_name)\n    if not module_name:\n        module_name = "__main__"\n        \n    _from = sys.modules[module_name] if module_name in sys.modules\\\n            else importlib.import_module(module_name)\n\n    return getattr(_from, class_name)\n    \n    \nclass Latency(object):\n    """ usage: Latency([name="component_name"], \n                       [average_size=20]) => latency_object\n                       \n        Latency objects possess a latency attribute that marks\n        the average time between calls to latency.update()"""\n                \n    def __init__(self, name=None, size=20):\n        super(Latency, self).__init__()\n        self.name = name\n        self.latency = 0.0\n        self.now = timer_function()\n        self.max = 0.0\n        self.average = Average(size=size)\n        self._position = 0\n\n    def update(self):\n        """ usage: latency.update()\n        \n            notes the current time and adds it to the average time."""\n        self._position += 1\n        time_before = self.time_before = self.now\n        now = self.now = timer_function()\n        latency = now - time_before\n        self.average.add(latency)\n        if (self._position == 20 or latency > self.max):\n            self.max = latency\n            self._position = 0\n        self.latency = latency\n\n    def display(self, mode="sys.stdin"):\n        """ usage: latency.display([mode=\'sys.stdin\'])\n        \n            Writes latency information via either sys.stdin.write or print.\n            Information includes the latency average, meta average, and max value""" \n        if "print" in mode:\n            print "%s Latency: %0.6f, Average: %0.6f, Max: %0.6f" % \\\n            (self.name, self.latency, self.average.average, self.max)\n        else:\n            sys.stdout.write("\\b"*120)\n            sys.stdout.write("%s Latency: %0.6f, Average: %0.6f, Max: %0.6f" % \\\n            (self.name, self.latency, self.average.average, self.max))\n\n\nclass Average(object):\n    """ usage: Average([name=\'\'], [size=20], \n                       [values=tuple()], [meta_average=False]) => average_object\n                       \n        Average objects keep a running average via the add method.\n        The size option specifies the maximum number of samples. When\n        this limit is reached, additional samples will result in the\n        oldest sample being removed.\n        \n        values may be used to seed the average.\n        \n        The meta_average boolean flag is used to determine whether or not\n        to keep an average of the average - This is implemented by an\n        additional Average object."""\n        \n    def _get_meta_average(self):\n        average = self._meta_average.average\n        if not average:\n            average = self.average\n        return average\n    meta_average = property(_get_meta_average)\n\n    def _get_range(self):\n        values = self.values\n        return (min(values), self.average, max(values))\n    range = property(_get_range)\n        \n    def __init__(self, name=\'\', size=20, values=tuple(), meta_average=True):\n        value = meta_average\n        if meta_average:\n            value = Average("{0} meta-average".format(name), 30, meta_average=False)\n        self._meta_average = value\n\n        self.name = name\n        self.values = collections.deque(values, size)\n        self.max_size = size\n        self.size = float(len(self.values))\n        if self.size:\n            self.average = sum(self.values) / self.size\n        else:\n            self.average = 0\n        self.add = self.partial_add\n\n    def partial_add(self, value):\n        self.size += 1\n        self.values.append(value)\n        self.average = sum(self.values) / self.size\n        if self.size == self.max_size:\n            self.add = self.full_add\n\n    def full_add(self, value):\n        old_value = self.values[0]\n        adjustment = (value - old_value) / self.size\n        self.values.append(value)\n        self.average += adjustment\n        if self._meta_average:\n            self._meta_average.add(self.average)\n\n                   \nclass LRU_Cache(object):\n    """A dictionary with a max size that keeps track of\n       key usage and handles key eviction. \n       \n       currently completely untested"""\n    def __init__(self, size=50, seed=None):\n        if seed:\n            assert len(seed.keys()) <= size\n        else:\n            seed = dict()\n        seed = seed if seed else dict()\n        keys = seed.keys()\n        assert len(keys) <= size\n        \n        deque = self.deque = collections.deque(maxlen=size)\n        deque.extend(keys)\n        \n        # testing for x in ... is significantly faster with a set\n        self.contains = set(keys)\n        self.size = size\n        \n        # change implementations once cache is full\n        self.add = self._add\n        \n        # when no entry has been evicted (cache is not full or entry was\n        # already in it), return a non hashable object so all keys \n        # (None, False, etc) will remain valid for users.\n        self.no_eviction = []\n        \n    def _add(self, item):\n        deque = self.deque\n        \n        if item in self.contains:\n            deque.remove(item)\n        else:\n            self.contains.add(item)\n            \n        deque.append(item)\n        if len(deque) > self.size:\n            # change to a slightly different implementation that\n            # doesn\'t do this check when the cache becomes full\n            self.add = self._full_add\n        \n        return self.no_eviction\n        \n    def _full_add(self, item):\n        deque = self.deque\n        contains = self.contains\n        \n        if item in contains:\n            deque.remove(item)\n            evicted = self.no_eviction\n        else:\n            contains.add(item)\n            evicted = deque[0]\n        deque.append(item)\n        return evicted\n              \n    def __getitem__(self, key):\n        evicted = self.tracker.add(key)\n        dict = self.dict\n        if evicted is not self.no_eviction:\n            del dict[evicted]\n            self.contains.remove(evicted)\n        return dict[key]\n        \n    def __setitem__(self, key, value):\n        self.dict[key] = value\n        self.contains.add(key)\n\n        \ndef function_header(function, mode="signature"):\n    """usage: function_header(function, \n                             [mode]) => "(arg1, default_arg=True, keyword=True...)"\n    \n    Given a function, return it\'s signature. mode can be specified as insertable\n    to use string format insertions instead of argument names"""\n    spec = args, varargs, keyword_args, default_args = inspect.getargspec(function)   \n    \n    header_size = ", ".join("{}" for x in range(len(args)))                \n    header_args = [arg for arg in args]\n    \n    if default_args: \n        new_args = []\n        for arg in default_args:\n            if isinstance(arg, str):\n                new_arg = repr(arg)\n            else:\n                new_arg = arg\n            new_args.append(new_arg)\n        default_args = new_args\n        non_defaults = len(args) - len(default_args)\n        len(default_args)\n        header_args = header_args[:non_defaults] + ["{}={}".format(arg_name, default_args[index]) for index, arg_name in enumerate(header_args[non_defaults:])]\n        \n    if varargs:\n        header_size += ", *{}"\n        header_args.append(varargs)    \n    \n    if keyword_args: \n        insert = "**{}" if mode == "signature" else "**{}"\n        header_size += ", " + insert\n        header_args.append(keyword_args)\n     #   print header_size\n        \n    answer = inserts = "({})".format(header_size)\n    \n    if mode == "signature":\n        answer = inserts.format(*header_args)\n    \n    return answer\n    \n    \ndef documentation(instance):\n    """ usage: documentation(object) => augmented_documentation_string\n    \n        Given a python object, attempt to introspect any useful information\n        and include it appended to the objects docstring."""\n        \n    if isinstance(instance, type):\n        _class = instance\n    else:\n        _class = instance.__class__\n    \n    options_text = \'Default values for newly created instances:\\n\\n\'\n    try: # gather the default attribute names and values (base objects only)\n        options = ""\n        for key, value in _class.defaults.items():\n            options += "- {0: <25}{1}\\n".format(key, value)\n        if not options:\n            options_text = "\\nNo defaults are assigned to new instances\\n"\n        else:\n            options_text += options\n    except AttributeError: # does not have defaults\n        options_text = "\\n\\n"\n        \n    docstring = ""\n    class_docstring = getattr(_class, "__doc", \'\')\n    if not class_docstring:\n        class_docstring = getattr(_class, "__doc__", \'\')\n    docstring += "\\t" + class_docstring.replace("    ", \'\').replace("\\n", "\\n\\t") + "\\n\\n" + options_text + "\\n"\n    beginning = docstring    \n        \n    docstring = "This object defines the following non-private methods:\\n"\n    found = False\n    for attribute_name in _class.__dict__.keys():\n        if "_" != attribute_name[0]:\n            attribute = getattr(_class, attribute_name)\n            if callable(attribute):\n                attribute = getattr(attribute, "function", attribute)\n                found = True\n\n                docstring += "\\n\\n- **" + attribute_name + "**"\n                                \n                function_docstring = inspect.getdoc(attribute)\n                function_docstring = function_docstring if function_docstring else "No documentation available"\n\n                try:\n                    method_header = function_header(attribute)\n                except:\n                    print "Could not find header for", attribute\n                    raise SystemExit\n                docstring += method_header + ":\\n\\n\\t\\t  " + function_docstring.replace("\\n", "\\n\\t\\t ") + "\\n"\n                docstring += "\\n"          \n                \n    if found:\n        docstring = beginning + docstring\n    else:\n        docstring = beginning + "No non-private methods are defined\\n"\n    try:\n        mro = str(_class.__mro__).replace("<", "").replace(">", \'\')\n        \n    except AttributeError:\n        docstring += "\\n No method resolution order detected...\\n"\n    else:\n        docstring += "\\nThis objects method resolution order is:\\n\\n"\n        docstring += mro + "\\n"\n    return docstring\n\n\nclass Updater(object):\n\n    def __init__(self):\n        super(Updater, self).__init__()\n\n    def live_update(self, component_name, source):\n        """Updates base component component_name with a class specified in source.\n        \n        outdated and needs rewrite"""\n        raise NotImplementedError\n'
tp31
a(Vvmlibrary.py
S'#   mpf.vmlibrary - virtual machine - processor - instruction handler\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\nimport heapq\nimport time\nimport traceback\nfrom functools import partial\n\nimport mpre\nimport mpre.base as base\nimport mpre.defaults as defaults\nimport mpre.utilities as utilities\n\nInstruction = mpre.Instruction\ntimer_function = utilities.timer_function\n\nclass Process(base.Reactor):\n    """ usage: Process(target=function, args=..., kwargs=...) => process_object\n    \n        Create a serial logical process. Note that while Process objects\n        allow for the interface of target=function, the preferred usage\n        is via subclassing.\n        \n        Process objects have a run_instruction attribute. This attribute\n        is a saved instruction: Instruction(self.instance_name, \'run\'). \n        \n        Process objects have a default attribute \'auto_start\', which\n        defaults to True. When True, an instruction for process.start\n        will automatically be executed inside __init__.\n        \n        The start method simply calls the run method, but can be overriden \n        if the entry point would be useful, and keeps a similar interface\n        with the threading/process model.\n        \n        Subclasses should overload the run method. A process may propagate\n        itself by executing a run instruction inside it\'s run method. While\n        processes support the reaction interface, use of a process presumes\n        the desire for some kind of explicitly timed Instruction. Examples\n        of processes include polling for user input or socket buffers\n        at various intervals.\n        \n        Some people may find the serial style, one frame at a time method\n        offered by processes easier to understand and follow then reactions.\n        Most things can be accomplished by either."""\n\n    defaults = defaults.Process\n    parser_ignore = ("auto_start", "network_buffer", "keyboard_input")\n\n    def __init__(self, **kwargs):\n        self.args = tuple()\n        self.kwargs = dict()\n        super(Process, self).__init__(**kwargs)\n\n        run_instruction = self.run_instruction = Instruction(self.instance_name, "run")\n\n        if self.auto_start:\n            Instruction(self.instance_name, "start").execute()\n\n    def start(self):\n        self.run()\n\n    def run(self):\n        if self.target:\n            self.target(*self.args, **self.kwargs)\n            \n\nclass Processor(Process):\n    """ Removes enqueued Instructions via heapq.heappop, then\n        performs the specified method call while handling the\n        possibility of the specified component/method not existing,\n        and any exception that could be raised inside the method call\n        itself.\n        \n        Essentially a task manager for launching other processes."""\n        \n    defaults = defaults.Processor\n\n    def __init__(self, **kwargs):\n        self.running = True\n        super(Processor, self).__init__(**kwargs)\n        \n    def run(self):\n        instructions = self.environment.Instructions\n        Component_Resolve = self.environment.Component_Resolve\n        processor_name = self.instance_name\n        \n        sleep = time.sleep\n        heappop = heapq.heappop\n        _getattr = getattr        \n        \n        component_errors = (AttributeError, KeyError)\n        reraise_exceptions = (SystemExit, KeyboardInterrupt)\n        alert = self.alert\n        component_alert = partial(alert, "{0}: {1}", level=0)\n        exception_alert = partial(alert, \n                                  "\\nException encountered when processing {0}.{1}\\n{2}", \n                                  level=0)\n        execution_alert = partial(alert, "executing instruction {}", level="vvv")\n        format_traceback = traceback.format_exc\n               \n        while self.running:            \n            execute_at, instruction = heappop(instructions)           \n            try:\n                call = _getattr(Component_Resolve[instruction.component_name],\n                                                  instruction.method)               \n            except component_errors as error:\n                if isinstance(error, KeyError):\n                    error = "\'{}\' component does not exist".format(instruction.component_name)\n                component_alert((str(instruction), error)) \n                continue\n                   \n            time_until = max(0, (execute_at - timer_function()))\n            if time_until:\n                sleep(time_until)\n                \n            execution_alert([str(instruction)])\n            \n            try:\n                call(*instruction.args, **instruction.kwargs)\n            except BaseException as result:\n                if type(result) in reraise_exceptions:\n                    raise\n                exception_alert((instruction.component_name,\n                                 instruction.method,\n                                 format_traceback()))\n                                 \n        '
tp32
asVprograms
p33
(lp34
(Vbuild_metapython_package.py
S'import os\nimport cPickle as pickle\n\nimport mpre.package\n\noptions = {"verbosity" : "vvv"}   \n                       \ndirectory = options["directory"] = \'C:\\\\users\\\\_\\\\pythonbs\'\npackage_name = options["package_name"] = "mpre"\nsubfolders = options["subfolders"] = ["programs", \'audio\', "gui", "misc"]\n\nif __name__ == "__main__":  \n    files = mpre.package.Package.from_directory(os.path.join(directory,\n                                                             package_name),\n                                                subfolders)\n    options["files"] = files\n    package = mpre.package.Package(**options)\n    with open("mpre.pyp", \'w\') as package_file:\n        pickle.dump(package, package_file)\n        package_file.flush()\n        package_file.close()\n    print "complete!"'
tp35
a(Vdownload_file.py
S'import mpre\nInstruction = mpre.Instruction\n    \nif __name__ == "__main__":    \n    options = {"parse_args" : True,\n               "exit_when_finished" : True}  \n    Instruction("Metapython", "create", "mpre.network2.Download", **options).execute()'
tp36
a(Vfile_server.py
S'import mpre\n\nif __name__ == "__main__":\n    mpre.Instruction("Metapython", "create", "network2.File_Service", parse_args=True).execute()'
tp37
a(Vget_modules.py
S'import pydoc\nfrom StringIO import StringIO\n\nclass Module_Listing(object):\n\n    def __init__(self, **kwargs):\n        super(Module_Listing, self).__init__()\n        [setattr(self, key, value) for key, value in kwargs.items()]\n        setattr(self, "file", getattr(self, "file", StringIO()))\n\n    def from_help(self):\n        helper = pydoc.Helper(output=self.file)\n        helper("modules")\n\n    def read_file(self):\n        file = self.file\n        file.seek(0)\n        text = file.read()\n        return text\n\n    def trim(self, text):\n        _file = StringIO(text)\n        found = []\n        count = 0\n        for line in _file.readlines():\n            if line.split(" ").count("") > 2:\n                found += line.split()\n\n        return \' \'.join(found)\n\n    def get_modules(self):\n        self.from_help()\n        original = self.read_file()\n        return self.trim(original)\n\n    def make_file(self, filename):\n        with open(filename, \'w\') as _file:\n            _file.write(self.get_modules())\n            _file.flush()\n            _file.close()\n'
tp38
a(Vrestore.py
S'"""Restores an environment suspended by metapython.Metapython.save_state"""\nif __name__ == "__main__":\n    from mpre.metapython import *\n    interpreter = Restored_Interpreter(parse_args=True)\n    interpreter.start_machine()'
tp39
a(Vsend_file.py
S'import mpre\nInstruction = mpre.Instruction\n\nif __name__ == "__main__":\n    Instruction("Metapython", "create", "network2.File_Service", exit_when_finished=True).execute()\n    Instruction("File_Service", "send_file", parse_args=True).execute()'
tp40
a(Vstupidreceive.py
S'from socket import *\n\nif __name__ == "__main__":\n    receiver = socket(AF_INET, SOCK_STREAM)\n    receiver.bind(("0.0.0.0", 40021))\n    receiver.listen(1)\n    f = open("audiofli.wav", "wb")\n    connection, _from = receiver.accept()\n    downloading = True\n    print "downloading"\n    while downloading:\n        data = connection.recv(4096)\n    \n        if not data:\n            downloading = False\n    \n        f.write(data)\n        f.flush()\n    print "finished"\n'
tp41
a(Vstupidsend.py
S'from socket import *\nfrom sys import argv\n\nif __name__ == "__main__":\n    filename = argv[1]\n    \n    sender = socket(AF_INET, SOCK_STREAM)\n    sender.connect(("192.168.1.240", 40021))\n    print "connected"\n    f = open(filename, "rb")\n    data = f.read()\n    f.close()\n    print len(data)\n    while data:\n        sender.send(data[:4096])\n        data = data[4096:]\n        print len(data), "remaining"\n    print "finished"\n'
tp42
a(Vunzip.py
S'import zipfile\nimport mpre.base as base\nimport mpre.defaults as defaults\n\nclass Unzipper(base.Base):\n    \n    defaults = defaults.Base.copy()\n    defaults.update({"filename" : \'\',\n                     "target_directory" : \'\'})\n                     \n    def __init__(self, **kwargs):\n        super(Unzipper, self).__init__(**kwargs)\n                \n    def unzip(self):\n        with zipfile.ZipFile(self.filename, \'r\') as zipped_file:\n            if self.target_directory:\n                zipped_file.extractall(self.target_directory)\n            else:\n                zipped_file.extractall()\n                \nif __name__ == "__main__":\n    zip_file = Unzipper(parse_args=True)\n    zip_file.unzip()'
tp43
asVdocs
p44
(lp45
sVgui
p46
(lp47
(Vdefaults.py
S'import os\nimport mpre.defaults as defaults\nBase = defaults.Base\nProcess = defaults.Process\n\nPACKAGE_LOCATION = os.path.dirname(os.path.abspath(__file__))\n\nSCREEN_SIZE = [800, 600]\n#R = 45\n#G = 150\n#B = 245\nR = 0\nG = 115\nB = 10\n# sdllibrary\n\nSDL_Component = Base.copy()\n\nWorld = SDL_Component.copy()\nWorld.update({"displays" : ({"display_number" : 0}, )})\n\nSDL_Window = SDL_Component.copy()\nSDL_Window.update({"size" : SCREEN_SIZE,\n"showing" : True,\n"layer" : 0,\n"name" : "Metapython",\n"color" : (0, 0, 0),\n"x" : 0,\n"y" : 0})\n\nRenderer = SDL_Component.copy()\nRenderer.update({"componenttypes" : tuple()})\n\nUser_Input = Process.copy()\n#User_Input.update({"priority" : .01})\n\nSprite_Factory = SDL_Component.copy()\n\nFont_Manager = SDL_Component.copy()\nFont_Manager.update({"font_path" : os.path.join(PACKAGE_LOCATION, "resources",\n                                                "fonts", "Aero.ttf"),\n"default_font_size" : 14,\n"default_color" : (15, 180, 35),\n"default_background" : (0, 0, 0)})\n\n# guilibrary\n\nOrganizer = Process.copy()\nOrganizer.update({"priority" : 0})\n\nWindow_Object = Base.copy()\nWindow_Object.update({\'x\' : 0,\n\'y\' : 0,\n\'size\' : SCREEN_SIZE,\n"layer" : 1,\n"background_color" : (0, 0, 0),\n"color" : (R, G, B),\n"outline_width" : 5,\n"popup" : False,\n"pack_mode" : \'\',\n"held" : False,\n"pack_modifier" : \'\',\n"color_scalar" : .6,\n"pack_on_init" : True,\n"sdl_window" : "SDL_Window"})\n\nWindow = Window_Object.copy()\nWindow.update({"show_title_bar" : False,\n"pack_mode" : "layer"})\n\nContainer = Window.copy()\nContainer.update({"alpha" : 1,\n"pack_mode" : "vertical"})\n\nButton = Container.copy()\nButton.update({"shape" : "rect",\n"text" : "Button",\n"text_color" : (255, 130, 25)})\n\n\n# widgetlibrary\nPopup_Menu = Container.copy()\nPopup_Menu.update({"popup" : True,\n"pack_modifier" : lambda parent, child: setattr(child, "position", (SCREEN_SIZE[0]/2, SCREEN_SIZE[1]/2))})\n\nFile_Menu = Popup_Menu.copy()\nFile_Menu.update({"pack_mode" : "vertical",\n        "pack_modifier" : lambda parent, child: setattr(child, "y", child.y+parent.size[1])})\n\nRight_Click_Menu = Popup_Menu.copy()\nRight_Click_Menu.update({"pack_mode": "layer",\n"size" : (200, 150)})\n\nRight_Click_Button = Button.copy()\n\nHomescreen = Window.copy()\nHomescreen.update({"background_filename" : "C:\\\\test.jpg"})\n\nProperty_Editor = Window.copy()\nProperty_Editor.update({"pack_modifier" : lambda parent, child:\\\nsetattr(child, "position", (SCREEN_SIZE[0]/2, SCREEN_SIZE[1]/2))})\n\nMenu_Bar = Container.copy()\nMenu_Bar.update({"pack_mode" : "menu_bar"})\n\nTitle_Bar = Menu_Bar.copy()\nTitle_Bar.update({"pack_modifier" : lambda parent, child:\\\nsetattr(child, "y", child.y+child.size[1])})\n\nTask_Bar = Menu_Bar.copy()\nTask_Bar.update({"pack_modifier" : lambda parent, child:\\\nsetattr(child, "y", (parent.y+parent.size[1])-child.size[1])\\\n}) # ^ aligns the bottom left corners of the parent and child object\n\nDate_Time_Button = Button.copy()\nDate_Time_Button.update({"pack_mode" : "horizontal"})\n\nHelp_Bar = Button.copy()\nHelp_Bar.update({"pack_mode" : "horizontal"})\n\nProperty_Button = Button.copy()\nProperty_Button.update({"property" : \'\',\n"display" : False})\n\nFile_Button = Button.copy()\nFile_Button.update({"display" : False})\n\nText_Line = Button.copy()\nText_Line.update({"edit_mode" : False})\n\nText_Character = Button.copy()\nText_Character.update({"text" : "",\n        "pack_mode" : "text",\n        "outline" : 0})\n'
tp48
a(Vguilibrary.py
S'import heapq\nimport ctypes\nfrom operator import attrgetter\nfrom sys import modules\nfrom math import floor, sqrt\n\nimport mpre\nimport mpre.base as base\nimport mpre.vmlibrary as vmlibrary\nimport mpre.gui.defaults as defaults\nimport mpre.utilities as utilities\nInstruction = mpre.Instruction\n\nimport sdl2\nimport sdl2.ext\nSDL_Rect = sdl2.SDL_Rect\n\nR, G, B, A = 0, 80, 255, 30\ndark_color_scalar = .5\nlight_color_scalar = 1.5\n\n\n# provides the pack() functionality\nclass Organizer(base.Base):\n\n    defaults = defaults.Organizer\n\n    def __init__(self, *args, **kwargs):\n        super(Organizer, self).__init__(*args, **kwargs)\n\n    def pack(self, item):\n        pack = getattr(self, "pack_{0}".format(item.pack_mode))\n        raise NotImplementedError\n        pack(item, count, length)\n\n    def pack_horizontal(self, item, count, length):\n        parent = item.parent\n        item.layer = parent.layer + 1\n        item.size = (parent.size[0]/length, parent.size[1])\n        item.x = (item.size[0]*count)+parent.x\n        item.y = parent.y\n\n    def pack_vertical(self, item, count, length):\n        parent = item.parent\n        item.layer = parent.layer + 1\n        item.size = (parent.size[0], parent.size[1]/length)\n        item.y = (item.size[1]*count)+parent.y\n        item.x = parent.x\n\n    def pack_grid(self, item, count, length):\n        grid_size = sqrt(length)\n\n        if grid_size != floor(grid_size):\n            grid_size = floor(grid_size)+1\n\n        position = (int(floor((count / grid_size))), (count % grid_size))\n\n        parent = item.parent\n        item.layer = parent.layer + 1\n        item.size = int(parent.size[0]/grid_size), int(parent.size[1]/grid_size)\n        item.x = (item.size[0]*position[1])+parent.x\n        item.y = (item.size[1]*position[0])+parent.y\n\n    def pack_text(self, item, count, length):\n        parent = item.parent\n        item.layer = parent.layer + 1\n        item.x = parent.x + parent.x_width + parent.x_spacing\n        item.y = parent.y\n\n    def pack_menu_bar(self, item, count, length):\n        parent = item.parent\n        item.layer = parent.layer + 1\n        item.x = parent.x\n        item.y = parent.y\n        item.size = (parent.size[0], int(parent.size[1]*.03))\n\n    def pack_layer(self, item, count, length):\n        parent = item.parent\n        item.layer = parent.layer + 1\n\n\nclass Window_Object(base.Base):\n\n    # default values\n    defaults = defaults.Window_Object\n    Hotkeys = {}\n    def _get_position(self):\n        return (self.x, self.y)\n    def _set_position(self, position):\n        self.x, self.y = position\n    position = property(_get_position, _set_position)\n\n    def _get_size(self):\n        return (self.w, self.h)\n    def _set_size(self, size):\n        self.w, self.h = size\n    size = property(_get_size, _set_size)\n    \n    def _get_area(self):\n        return (self.x, self.y, self.w, self.h)\n    def _set_area(self, rect):\n        self.x, self.y, self.w, self.h = rect\n    area = property(_get_area, _set_area)\n\n    # calculates the outline color\n    def _get_outline_color(self):\n        return (int(self.color[0]*self.color_scalar), int(self.color[1]*\\\n        self.color_scalar), int(self.color[2]*self.color_scalar))\n\n    outline_color = property(_get_outline_color)\n\n    def _get_rect(self):\n        return sdl2.SDL_Rect(*self.area)\n    rect = property(_get_rect)\n\n    def __init__(self, **kwargs):\n        self.draw_queue = []\n        super(Window_Object, self).__init__(**kwargs)\n\n     #   if self.draw_on_init:\n      #      self.draw_texture()\n\n    def create(self, *args, **kwargs):\n        kwargs["layer"] = self.layer + 1\n        return super(Window_Object, self).create(*args, **kwargs)\n                \n    def add(self, instance):\n        if hasattr(instance, "draw_texture"):\n            self.draw_queue.append(instance)\n        super(Window_Object, self).add(instance)\n\n    def press(self, mouse):\n        self.held = True\n\n    def release(self, mouse):\n        self.held = False\n        self.click(mouse)\n\n    def click(self, mouse):\n        if mouse.button == 3:\n            self.create("mpre.gui.widgetlibrary.Right_Click_Menu", x=mouse.x, y=mouse.y)\n            self.draw_texture()\n    \n    def mousewheel(self, x_amount, y_amount):\n        pass\n\n    def mousemotion(self, x_change, y_change):\n        if self.held:\n            self.draw("fill", self.area, \n                      color=getattr(self.parent, \'color\', (0, 0, 0)))\n            self.x += x_change\n            self.y += y_change\n            for item in self.draw_queue:\n                original = item.held\n                item.held = True\n                item.mousemotion(x_change, y_change)\n                item.held = original\n            try:\n                self.parent.draw_texture()\n            except AttributeError:\n                self.draw_texture()\n\n    def draw(self, figure="rect", *args, **kwargs):\n        self.parallel_method(self.sdl_window, "draw", self.instance_name,\n                             figure, self.area, self.layer, \n                             *args, **kwargs)\n\n    def draw_texture(self):\n        self.draw("fill", self.area, color=self.background_color)\n        self.draw("rect", self.area, color=self.color)\n        self.draw_children()\n        \n    def draw_children(self):\n        for item in self.draw_queue:\n            item.draw_texture()\n\n    def pack(self, reset=False):\n        if reset:\n            self.x = self.y = 0\n        self.parallel_method("Organizer", "pack", self)\n        for item in self.draw_queue:\n            item.pack()\n\n    def delete(self):\n        self.parent.draw_queue.remove(self)\n        super(Window_Object, self).delete()\n\n\nclass Theme(Window_Object):\n            \n    defaults = defaults.Window_Object.copy()\n    \n    def __init__(self, **kwargs):\n        super(Theme, self).__init__(**kwargs)\n     \n    def draw_texture(self, window_object):\n        x, y, w, h = window_object.area\n        area = (x + 1, y + 1, w - 1, h - 1)\n        window_object.draw("rect_width", area, color=self.color, width=self.width)\n        \n    \nclass Window(Window_Object):\n\n    defaults = defaults.Window\n\n    def __init__(self, **kwargs):\n        super(Window, self).__init__(**kwargs)\n\n        #if getattr(self, "title_bar", None):\n        self.create("mpre.gui.widgetlibrary.Title_Bar")\n\n    \nclass Container(Window_Object):\n\n    defaults = defaults.Container\n\n    def __init__(self, **kwargs):\n        super(Container, self).__init__(**kwargs)\n\n\nclass Button(Window_Object):\n\n    defaults = defaults.Button\n\n    def __init__(self, **kwargs):\n        super(Button, self).__init__(**kwargs)\n\n    def draw_texture(self):\n        super(Button, self).draw_texture()\n        self.draw("text", self.text, self.area, color=self.text_color)\n'
tp49
a(Vsdllibrary.py
S'import sys\nimport string\nimport heapq\nimport ctypes\nimport mmap\nfrom operator import itemgetter\n\nimport sdl2\nimport sdl2.ext\nimport sdl2.sdlttf\nsdl2.ext.init()\nsdl2.sdlttf.TTF_Init()\nfont_module = sdl2.sdlttf\n\nimport mpre\nimport mpre.base as base\nimport mpre.vmlibrary as vmlibrary\nimport mpre.utilities as utilities\nimport mpre.gui.defaults as defaults\nInstruction = mpre.Instruction\n\n\nclass Display_Wrapper(base.Wrapper):\n    """used by the display internally to display all objects"""\n    defaults = defaults.Window_Object\n\n    def _get_position(self):\n        return (self.x, self.y)\n    def _set_position(self, position):\n        self.x, self.y = position\n    position = property(_get_position, _set_position)\n\n    def _get_area(self):\n        return (self.position, self.size)\n    def _set_area(self, rect):\n        self.position, self.size = rect\n    area = property(_get_area, _set_area)\n\n    def _get_outline_color(self):\n        return (int(self.color[0]*self.color_scalar), int(self.color[1]*\\\n        self.color_scalar), int(self.color[2]*self.color_scalar))\n    outline_color = property(_get_outline_color)\n\n    def __init__(self, **kwargs):\n        super(Display_Wrapper, self).__init__(**kwargs)\n\n     #   Instruction("Organizer", "pack", wrapped_object).execute()\n      #  Instruction("Display", "draw", wrapped_object).execute()\n\n    def press(self):\n        self.held = True\n\n    #def release(self):\n     #   self.held = False\n      #  if Display.mouse_is_inside(self):\n       #     self.click()\n\n    def click(self):\n        pass\n\n\nclass SDL_Component(base.Proxy):\n\n    defaults = defaults.SDL_Component\n\n    def __init__(self, **kwargs):\n        super(SDL_Component, self).__init__(**kwargs)\n\n\nclass SDL_Window(SDL_Component):\n\n    defaults = defaults.SDL_Window\n        \n    def __init__(self, **kwargs):\n        self.draw_queue = []\n        self.coordinate_tracker = {}\n        self.latency = utilities.Latency(name="framerate")\n        self.queue_counter = 0\n        self.running = False\n        super(SDL_Window, self).__init__(**kwargs)\n\n        window = sdl2.ext.Window(self.name, size=self.size)\n        self.wraps(window)\n\n        renderer = self.renderer = self.create(Renderer, window=self)\n        self.user_input = self.create(SDL_User_Input)\n\n        methods = ("point", "line", "rect", "rect_width", "text")\n        names = ("draw_{0}".format(name) for name in methods)\n        instructions = dict((name, getattr(renderer, name)) for name in names)\n        instructions["draw_fill"] = renderer.fill\n        self.instructions = instructions\n\n        if self.showing:\n            self.show()\n\n    def create(self, *args, **kwargs):\n        instance = super(SDL_Window, self).create(*args, **kwargs)\n        if hasattr(instance, "draw_texture"):\n            if getattr(instance, "pack_on_init", False):#instance.pack_on_init:\n                instance.pack()\n            instance.draw_texture()\n            \n        return instance\n\n    def run(self):\n        renderer = self.renderer\n        heappop = heapq.heappop\n        instructions = self.instructions\n        draw_queue = self.draw_queue\n        current_layer = 0\n        while draw_queue:\n            layer, entry_no, instruction, item = heappop(draw_queue)\n            method, args, kwargs = instruction\n            result = instructions[method](*args, **kwargs)\n            if result:\n                texture, rect = result\n                renderer.copy(texture, None, rect)\n\n        self.queue_counter = 0\n        self.running = False\n        renderer.present()\n\n    def draw(self, item, mode, area, z, *args, **kwargs):\n        self.user_input._update_coordinates(item, area, z)\n        entry = (z, self.queue_counter, ("draw_{0}".format(mode), args, kwargs), item)\n        heapq.heappush(self.draw_queue, entry)\n        self.queue_counter += 1\n        if not self.running:\n            self.running = True\n            Instruction(self.instance_name, "run").execute()\n\n    def get_mouse_state(self):\n        mouse = sdl2.mouse\n        x = ctypes.c_long(0)\n        y = ctypes.c_long(0)\n        buttons = mouse.SDL_GetMouseState(ctypes.byref(x), ctypes.byref(y))\n\n        states = ("BUTTON_LMASK", "BUTTON_RMASK", "BUTTON_MMASK", "BUTTON_X1MASK", "BUTTON_X2MASK")\n        states = (getattr(mouse, "SDL_{0}".format(state)) for state in states)\n        button_state = map(lambda mask: buttons & mask, states)\n        return ((x, y), button_state)\n\n    def get_mouse_position(self):\n        return self.get_mouse_state()[0]\n\n\n"""class Font(SDL_Component):\n\n    defaults = defaults.Font\n\n    def __init__(self, **kwargs):\n        super(Font, self).__init__(**kwargs)\n        self.wraps(font_module.TTF_OpenFont(self.font_path, self.size))"""\n\n\nclass SDL_User_Input(vmlibrary.Process):\n\n    defaults = defaults.Process.copy()\n    coordinate_tracker = {None : ((0, 0, 0, 0), 0)}\n\n    def __init__(self, **kwargs):\n        self.active_item = None\n        self.popups = []\n        super(SDL_User_Input, self).__init__(**kwargs)\n        self.uppercase_modifiers = (sdl2.KMOD_SHIFT, sdl2.KMOD_CAPS,\n                                    sdl2.KMOD_LSHIFT, sdl2.KMOD_RSHIFT)\n        uppercase = self.uppercase = {\'1\' : \'!\',\n                                      \'2\' : \'@\',\n                                      \'3\' : \'#\',\n                                      \'4\' : \'$\',\n                                      \'5\' : \'%\',\n                                      \'6\' : \'^\',\n                                      \'7\' : \'&\',\n                                      \'8\' : \'*\',\n                                      \'9\' : \'(\',\n                                      \'0\' : \')\',\n                                      ";" : \':\',\n                                      \'\\\'\' : \'"\',\n                                      \'[\' : \']\',\n                                      \',\' : \'<\',\n                                      \'.\' : \'>\',\n                                      \'/\' : "?",\n                                      \'-\' : "_",\n                                      \'=\' : "+",\n                                      \'\\\\\' : "|",\n                                      \'`\' : "~"}\n        letters = string.ascii_letters\n        for index, character in enumerate(letters[:26]):\n            uppercase[character] = letters[index+26]\n\n        # for not yet implemented features\n        unhandled = self.handle_unhandled_event\n\n        self.instruction_mapping = {sdl2.SDL_DOLLARGESTURE : unhandled,\n                              sdl2.SDL_DROPFILE : unhandled,\n                              sdl2.SDL_FINGERMOTION : unhandled,\n                              sdl2.SDL_FINGERDOWN : unhandled,\n                              sdl2.SDL_FINGERUP : unhandled,\n                              sdl2.SDL_FINGERMOTION :unhandled,\n                              sdl2.SDL_KEYDOWN : self.handle_keydown,\n                              sdl2.SDL_KEYUP : self.handle_keyup,\n                              sdl2.SDL_JOYAXISMOTION : unhandled,\n                              sdl2.SDL_JOYBALLMOTION : unhandled,\n                              sdl2.SDL_JOYHATMOTION : unhandled,\n                              sdl2.SDL_JOYBUTTONDOWN : unhandled,\n                              sdl2.SDL_JOYBUTTONUP : unhandled,\n                              sdl2.SDL_MOUSEMOTION : self.handle_mousemotion,\n                              sdl2.SDL_MOUSEBUTTONDOWN : self.handle_mousebuttondown,\n                              sdl2.SDL_MOUSEBUTTONUP : self.handle_mousebuttonup,\n                              sdl2.SDL_MOUSEWHEEL : self.handle_mousewheel,\n                              sdl2.SDL_MULTIGESTURE : unhandled,\n                              sdl2.SDL_QUIT : self.handle_quit,\n                              sdl2.SDL_SYSWMEVENT : unhandled,\n                              sdl2.SDL_TEXTEDITING : unhandled,\n                              sdl2.SDL_TEXTINPUT : unhandled,\n                              sdl2.SDL_USEREVENT : unhandled,\n                              sdl2.SDL_WINDOWEVENT : unhandled}\n\n    def run(self):\n        events = sdl2.ext.get_events()\n        for event in events:\n            self.instruction_mapping[event.type](event)\n        self.run_instruction.execute(self.priority)\n\n    def _update_coordinates(self, item, area, z):\n        SDL_User_Input.coordinate_tracker[item] = (area, z)\n\n    def mouse_is_inside(self, area, mouse_pos_x, mouse_pos_y):\n        x, y, w, h = area\n        if mouse_pos_x >= x and mouse_pos_x <= x + w:\n            if mouse_pos_y >= y and mouse_pos_y <= y + h:\n                return True\n\n    def handle_unhandled_event(self, event):\n        self.alert("{0} passed unhandled", [event.type], \'vv\')\n\n    def handle_quit(self, event):\n        sys.exit()\n\n    def handle_mousebuttondown(self, event):\n        mouse = event.button\n        mouse_x = mouse.x\n        mouse_y = mouse.y\n        check = self.mouse_is_inside\n        possible = []\n        for item, coords in self.coordinate_tracker.items():\n            area, z = coords\n            if check(area, mouse_x, mouse_y):\n                possible.append((item, area, z))\n        try:\n            instance, area, z = sorted(possible, key=itemgetter(2))[-1]\n        except IndexError:\n            self.alert("IndexError on mouse button down (No window objects under mouse)", level="v")\n        else:\n            self.active_item = instance\n            Instruction(instance, "press", mouse).execute()\n\n    def handle_mousebuttonup(self, event):\n        mouse = event.button\n        area, z = self.coordinate_tracker[self.active_item]\n        if self.mouse_is_inside(area, mouse.x, mouse.y):\n            Instruction(self.active_item, "release", mouse).execute()\n        self.active_item = None\n\n    def handle_mousewheel(self, event):\n        wheel = event.wheel\n        Instruction(self.active_item, "mousewheel", wheel.x, wheel.y).execute()\n\n    def handle_mousemotion(self, event):\n        motion = event.motion\n        if self.active_item:\n            x_change = motion.xrel\n            y_change = motion.yrel\n            self.parallel_method(self.active_item, "mousemotion", x_change, y_change)\n            \n        if self.popups:\n            popups = self.popups\n            for item in popups:\n                if not self.mouse_is_inside(item.area, motion.x, motion.y):\n                    Instruction(item.parent.instance_name, "draw_texture").execute()\n                    popups.remove(item)\n                    item.delete()\n\n    def handle_keydown(self, event):\n        try:\n            key = chr(event.key.keysym.sym)\n        except ValueError:\n            return # key was a modifier key\n        else:\n            if key == "\\r":\n                key = "\\n"\n            modifier = event.key.keysym.mod\n            if modifier:\n                if modifier in self.uppercase_modifiers:\n                    try:\n                        key = self.uppercase[key]\n                    except KeyError:\n                        pass\n                    raise NotImplementedError\n                    #stdin.write(key)\n                else:\n                    hotkey = self.get_hotkey(self.active_item, (key, modifier))\n                    if hotkey:\n                        hotkey.execute()\n            else:\n                raise NotImplementedError\n                #stdin.write(key)\n            #sys.stdout.write(key)\n\n    def get_hotkey(self, instance, key_press):\n        try:\n            hotkey = instance.hotkeys.get(key_press)\n            if not hotkey:\n                hotkey = self.get_hotkey(instance.parent, key_press)\n        except AttributeError:\n            hotkey = None\n        return hotkey\n\n    def handle_keyup(self, event):\n        pass\n\n    def add_popup(self, item):\n        self.popups.append(item)\n\n\nclass Renderer(SDL_Component):\n\n    defaults = defaults.Renderer\n\n    def __init__(self, **kwargs):\n        self.font_cache = {}\n        kwargs["wrapped_object"] = sdl2.ext.Renderer(kwargs["window"])\n        super(Renderer, self).__init__(**kwargs)\n\n        self.sprite_factory = self.create(Sprite_Factory, renderer=self)\n        self.font_manager = self.create(Font_Manager)\n\n    def draw_text(self, text, rect, **kwargs):\n        cache = self.font_cache\n        if text in cache:\n            results = cache[text]\n        else:\n            call = self.sprite_factory.from_text\n            results = (call(text, fontmanager=self.font_manager, **kwargs), rect)\n            if len(text) <= 3:\n                cache[text] = results\n        return results\n\n    def draw_rect_width(self, area, **kwargs):\n        width = kwargs.pop("width")\n        x, y, w, h = area\n        draw_rect = self.draw_rect\n        print "drawing rect of width", width\n        for rect_size in xrange(1, width + 1):\n            new_x = x + rect_size\n            new_y = y + rect_size\n            new_w = w - rect_size\n            new_h = h - rect_size\n            draw_rect((new_x, new_y, new_w, new_h), **kwargs)\n\n\nclass Sprite_Factory(SDL_Component):\n\n    defaults = defaults.Sprite_Factory\n\n    def __init__(self, **kwargs):\n        kwargs["wrapped_object"] = sdl2.ext.SpriteFactory(renderer=kwargs["renderer"])\n        super(Sprite_Factory, self).__init__(**kwargs)\n\n\nclass Font_Manager(SDL_Component):\n\n    defaults = defaults.Font_Manager\n\n    def __init__(self, **kwargs):\n        _defaults = self.defaults\n        options = {"font_path" : _defaults["font_path"],\n                   "size" : _defaults["default_font_size"],\n                   "color" : _defaults["default_color"],\n                   "bg_color" : _defaults["default_background"]}\n        kwargs["wrapped_object"] = sdl2.ext.FontManager(**options)\n        super(Font_Manager, self).__init__(**kwargs)\n\n\nif __name__ == "__main__":\n    Instruction("Metapython", "create", "mpre.gui.sdllibrary.SDL_Window").execute()\n    \n    Instruction("SDL_Window", "create", "mpre.gui.guilibrary.Organizer").execute()\n    Instruction("SDL_Window", "create", "mpre.gui.widgetlibrary.Homescreen").execute()\n    source = """def draw(shape, *args, **kwargs):\n        Instruction("Homescreen", "draw", shape, *args, **kwargs).execute()\n    \n    white = (255, 255, 255)\n    green = (0, 115, 5)\n    area100 = (100, 100, 200, 200)\n    """\n    Instruction("Metapython", "create", "metapython.Shell", startup_definitions=source).execute()'
tp50
a(Vwidgetlibrary.py
S'import time\n\nimport mpre\nimport guilibrary\nimport defaults\nimport mpre.base as base\nInstruction = mpre.Instruction\n\n\nclass Indicator(guilibrary.Button):  \n        \n    def draw_texture(self):\n        super(Indicator, self).draw_texture()\n        parent = self.parent\n        x, y, w, h = parent.area\n\n        area = self.area = (self.x, self.y, len(self.parent.instance_name) * 7, 16)\n        # draw a line from the top left corner of self to the midpoint of parent\n        self.draw("line", (self.x, self.y, x + (w / 2), y + (h / 2)), color=self.outline_color)\n        self.draw("text", parent.instance_name, area, color=(255, 255, 255))\n                       \n        \nclass Title_Bar(guilibrary.Container):\n        \n    def draw_texture(self):\n        self.draw("text", self.parent.name, (0, 0, 60, 12), color=self.color)\n        \n        \nclass Popup_Menu(guilibrary.Container):\n\n    defaults = defaults.Popup_Menu\n\n    def __init__(self, **kwargs):\n        super(Popup_Menu, self).__init__(**kwargs)\n        Instruction("User_Input", "add_popup", self).execute()\n\n\nclass Homescreen(guilibrary.Window):\n\n    defaults = defaults.Homescreen\n\n    def __init__(self, **kwargs):\n        super(Homescreen, self).__init__(**kwargs)\n        self.create(Task_Bar)\n\n\nclass Task_Bar(guilibrary.Container):\n\n    defaults = defaults.Task_Bar\n\n    def __init__(self, **kwargs):\n        super(Task_Bar, self).__init__(**kwargs)\n        self.create(Date_Time_Button)\n\n\nclass Date_Time_Button(guilibrary.Button):\n\n    defaults = defaults.Date_Time_Button\n\n    def __init__(self, **kwargs):\n        super(Date_Time_Button, self).__init__(**kwargs)        \n        update = self.update_instruction = Instruction(self.instance_name, \n                                                       "update_time")        \n        self.update_time()        \n        \n    def update_time(self):\n        self.text = time.asctime()\n        instance_name = self.instance_name\n        self.update_instruction.execute()\n        \n        Instruction(instance_name, "draw_texture").execute(priority=1)\n\n\nclass Right_Click_Menu(Popup_Menu):\n\n    defaults = defaults.Right_Click_Menu\n\n    def __init__(self, **kwargs):\n        super(Right_Click_Menu, self).__init__(**kwargs)\n        types = ("builtins", "private", "methods", "properties", "attributes")\n        attributes = dict((name, []) for name in types)\n        target = self.target\n        for attribute in dir(target):\n            if "__" in attribute:\n                attributes["builtins"].append(attribute)\n            elif "_" == attribute[0]:\n                attributes["private"].append(attribute)\n            elif callable(getattr(target, attribute)):\n                attributes["methods"].append(attribute)\n            elif type(getattr(target, attribute)) is property:\n                attributes["properties"].append(attribute)\n            else:\n                attributes["attributes"].append(attribute)\n        for name, collection in attributes.items():\n            self.create(Right_Click_Button, text=name, attributes=collection, size=(50, 50))\n\n\nclass Right_Click_Button(guilibrary.Button):\n\n    defaults = defaults.Right_Click_Button\n\n    def __init__(self, **kwargs):\n        super(Right_Click_Button, self).__init__(**kwargs)\n\n    def click(self, mouse):\n        self.create(Attribute_Displayer, attributes=self.attributes)\n\n\nclass Attribute_Displayer(guilibrary.Window): pass\n'
tp51
asVmisc
p52
(lp53
(Vattributetest.py
S'import mmap\nimport struct\nimport ast\nimport cPickle as pickle\nfrom itertools import izip\n\nimport mpre.base as base\nimport mpre.fileio as fileio\n\n\nclass Struct(object):\n   \n    format_switch = {int : \'q\',\n                     float : \'d\',\n                     str : \'s\',\n                     bool : \'?\'}\n    \n    format_size = {\'q\' : 8,\n                   \'d\' : 8,\n                   \'s\' : 0,\n                   \'?\' : 1}\n    \n    local_only = set(("dictionary", "_memory", "unpacked_index",\n                      "byte_offsets", "struct", "create_struct",\n                      "pack", "metadata_struct", "struct_slice",\n                      "total_size", "create_metadata", "from_dictionary",\n                      "write_to_memory", "attribute_order", "is_pickled"))\n                  \n    def __init__(self, dictionary):\n        self.update(dictionary)\n    \n    def update(self, dictionary):\n        self.dictionary = dictionary\n        self.data = self.byte_representation(dictionary)\n        \n    def byte_representation(self, dictionary):\n        (total_size,\n         packed_data,\n         self.struct,\n         self.struct_slice,\n         self.unpacked_index,\n         self.byte_offsets,\n         self.attribute_order,\n         self.is_pickled) = self.from_dictionary(dictionary)\n        \n        return packed_data\n        \n    def from_dictionary(self, dictionary):\n        (byte_offsets,\n         unpacked_index,\n         attribute_order, \n         values, \n         _struct,\n         is_pickled) = self.create_struct(dictionary)\n                 \n        """(packed_metadata, \n         metadata_struct) = self.create_metadata(attribute_order, \n                                                 byte_offsets,\n                                                 is_pickled)\n      \n        metadata_size = len(packed_metadata)\n        size_string = str(metadata_size).zfill(64)\n        total_size = 64 + metadata_size + _struct.size\n        \n        struct_slice = slice(metadata_size + 64, total_size)       \n         \n        return (total_size, size_string, _struct.pack(*values),\n                packed_metadata, _struct, metadata_struct, \n                struct_slice,  unpacked_index, byte_offsets,\n                attribute_order, is_pickled)"""\n        total_size = _struct.size\n        struct_slice = slice(0, total_size)\n        return (total_size, _struct.pack(*values),\n                _struct, struct_slice,  unpacked_index, byte_offsets,\n                attribute_order, is_pickled)\n                \n    def create_metadata(self, attribute_order, byte_offsets, is_pickled):\n        """ create a metadata struct that provides attribute names,\n            the pickled flag, and the associated offset/size."""\n        metadata_layout = \'\'\n        metadata_values = []\n        for attribute in attribute_order:\n            metadata_layout += str(len(attribute)) + \'s?qq\'\n            start_pointer, end_pointer = byte_offsets[attribute]\n            \n            metadata_values.extend((attribute,\n                                    is_pickled[attribute],\n                                    start_pointer,\n                                    end_pointer))\n                                               \n        metadata_struct = struct.Struct(metadata_layout)        \n        packed_metadata = metadata_struct.pack(*metadata_values)\n                \n        return packed_metadata, metadata_struct\n                                                       \n    def pack(self, value):\n        format_character = Struct.format_switch.get(type(value), "pyobject")\n        if format_character is "pyobject":\n        #    print "PICKLING: ", type(value), value\n            value = pickle.dumps(value)\n            format_size = len(value)\n            format_character = str(format_size) + \'s\'  \n            is_pickled = True\n        else:\n            format_size = Struct.format_size[format_character]\n            if not format_size:\n                format_size = len(value)\n                format_character = str(format_size) + format_character\n            is_pickled = False\n            \n       # print "packed {} into {}".format(value, format_character)\n        return format_size, format_character, value, is_pickled\n        \n    def create_struct(self, dictionary):        \n        struct_layout = \'\'\n        \n        unpacked_index = {}\n        attribute_byte_offset = {}\n        is_pickled = {}\n        \n        index_count = 0\n        byte_index = 0\n        attribute_order = []\n        values = []\n        for key, value in dictionary.items():\n            attribute_order.append(key)\n            unpacked_index[key] = index_count\n            format_size, format_character, value, pickled_flag = self.pack(value)\n            \n            values.append(value)\n            attribute_byte_offset[key] = byte_index, byte_index + format_size\n          #  print \'{} PICKLED flag: {}\'.format(key, pickled_flag)\n            is_pickled[key] = pickled_flag\n            \n            index_count += 1            \n            struct_layout += format_character\n            byte_index += format_size\n                                           \n        return (attribute_byte_offset, unpacked_index,\n                attribute_order, values, struct.Struct(struct_layout),\n                is_pickled)\n        \n        \nclass Persistent_Reactor(base.Reactor):\n    \n    local_only = set((\'_file\', \'_memory\', "_struct", "dictionary",\n                      "instance_number", "instance_name", "environment",\n                      "local_only", "defaults"))\n    \n    def __init__(self, **kwargs):\n        print Persistent_Reactor, "__init__"\n        super_object = super(Persistent_Reactor, self)\n        set_attribute = super_object.__setattr__\n                \n        dictionary = {}\n        fileio.ensure_file_exists(self.instance_name)\n        _file = self._file = open(self.instance_name, \'r+b\')\n        memory = self._memory = mmap.mmap(_file.fileno(), 65535)\n        \n        _struct = Struct(dictionary)\n        print "setting _struct and dictionary attributes"\n        set_attribute("_struct", _struct)\n        set_attribute("dictionary", dictionary)\n        print self, "pre super"\n        super_object.__init__(**kwargs)\n        print self, "post super"\n     \n\n        packed_attributes = _struct.data\n        memory[len(packed_attributes)] = packed_attributes\n        \n    def __getstate__(self):\n        dict_copy = self.__dict__.copy()\n        for attribute in self.local_only:\n            if attribute in dict_copy:\n                del dict_copy[attribute]\n                \n    #    del dict_copy["_file"]\n     #   del dict_copy["_memory"]\n      #  del dict_copy["_struct"\n        return dict_copy\n        \n    def __setstate__(self, state):\n        self.__init__(**state)\n        \n    def __getattribute__(self, attribute):\n        get_attribute = super(Persistent_Reactor, self).__getattribute__\n        try:\n            value = get_attribute(attribute)\n        except AttributeError:\n            pass\n            \n        if "__" != attribute[:2] and attribute not in get_attribute("local_only"):\n            print "getting shared attribute: ", attribute\n            _struct = get_attribute("_struct")\n            data_index = _struct.unpacked_index[attribute]\n            value = _struct.struct.unpack(get_attribute("_memory")\\\n                                         [_struct.struct_slice])[data_index]\n        else:\n            value = get_attribute(attribute)\n        return value\n        \n    def __setattr__(self, attribute, value):\n      #  print "Setting {} to {}".format(attribute, value)\n        get_attribute = super(Persistent_Reactor, self).__getattribute__\n        if attribute not in get_attribute("local_only"):\n       #     print "{} is a persistent attribute".format(attribute)\n            _struct = get_attribute("_struct")\n            \n            _struct.update(self.dictionary)\n            packed_dictionary = _struct.data\n            get_attribute("_memory")[:len(packed_dictionary)] = packed_dictionary            \n        else:\n            super(Persistent_Reactor, self).__setattr__(attribute, value)       \n            \n                \nif __name__ == "__main__":\n    import unittest\n    from mpre.misc.decoratorlibrary import Timed\n    from mpre.base import Base\n    b = Base(none=None)\n    struc_attributes = {"integer" : 123, \n                        "string" : "hi, i\'m a string",\n                        "float" : 1.0,\n                        "boolean" : True,\n                        "none" : None}\n        \n    struc = Struct(struc_attributes)    \n    \n    """print \'{:+>80}\'.format(\'TIMING COMPARISON\')\n    print "struct getattr: ", Timed(lambda: struc.none, iterations=10000)()\n    print "base getattr  :  ", Timed(lambda: b.none, iterations=10000)()\n    print\n    print "struct setattr: ", Timed(lambda: struc.none, iterations=10000)()\n    print "base setattr  : ", Timed(lambda: b.none, iterations=10000)()    \n    print "write_to_memory time: ", Timed(lambda: struc.write_to_memory(struc.dictionary), iterations=10000)()\n    print \'{:+>80}\'.format(\'END TIMING COMPARISON\')"""\n\n    \n    class Test_getsetattr(unittest.TestCase):\n  \n        def test(self):\n            index = 0\n            print "\\nTesting getattr and setattr accuracy"\n            modifications = (Base(), None, "a shared memory string!", False, 123)\n            \n            for attribute, value in struc_attributes.items():\n                attr_value = getattr(struc, attribute)\n                print "\\n\\ntesting initially assigned attribute {} {} is {}".format(attribute, attr_value, value)\n                self.failUnless(attr_value == value)\n                \n                modification = modifications[index]\n                print "Modifying {}; changing {} to {}".format(attribute, \n                                                               attr_value,\n                                                               modification)\n                                                               \n                setattr(struc, attribute, modification)\n                test = getattr(struc, attribute)\n                \n                print "...testing modification {} is {}".format(test, modification)   \n                \n                if struc.is_pickled[attribute]:\n                    test = type(test)\n                    modification = type(modification)\n\n                self.failUnless(test == modification)\n                index += 1\n    \n    unittest.main()'
tp54
a(Vattributetest2.py
S'import mmap\nimport cPickle as pickle\n\nimport mpre.base\nimport mpre.fileio as fileio\n\nclass Persistent_Reactor(mpre.base.Reactor):\n    \n    def __init__(self, **kwargs):\n        super(Persistent_Reactor, self).__init__(**kwargs)\n        file = self.file = fileio.File(self.instance_name, "r+b")\n        memory = memory = mmap.mmap(file.fileno(), 65535)\n        memory.seek(0)\n        \n        try:\n            current_state = pickle.load(memory)\n        except:\n            current_state = dict((attribute, value) for attribute, value in\n                                  self.__dict__.items())\n            print "dumping state to memory: ", current_state\n            pickle.dump(current_state, memory)\n            memory.flush()\n        else:\n            for attribute, value in current_state.items():\n                self.alert("updating state; {} = {}",\n                           [attribute, value],\n                           0)\n                setattr(self, attribute, value)\n                \n        self.memory = memory\n        print "changing descriptors"\n        self.__getattribute__ = self.persistent_getattribute\n        self.__setattr__ = self.persistent_setattr\n     \n    def __getstate__(self):\n        dict_copy = self.__dict__.copy()\n        del dict_copy["memory"]\n        return dict_copy\n        \n    def __setstate__(self, state):\n        self.__init__(**state)\n        return self\n        \n    def persistent_getattribute(self, attribute):\n        print "i never happen"\n        raise SystemExit\n        get_attribute = super(Persistent_Reactor, self).__getattribute__\n        print "getting attribute: ", attribute\n        value = get_attribute(self, "value")\n        memory = get_attribute(self, "memory")\n        memory.seek(0)\n        old_copy = pickle.load(memory)\n        \n        if attribute in old_copy:\n            shared_value = old_copy[attribute]\n            if shared_value != value:\n                super(Persistent_Reactor, self).__setattr__(attribute, shared_value)\n                value = shared_value\n                \n        return value\n        \n    def persistent_setattr(self, attribute, value):\n        super_object = super(Persistent_Reactor, self)\n        \n        super_object.__setattr__(attribute, value)\n        \n        memory = super_object.__getattribute__("memory")\n        memory.seek(0)\n        old_copy = pickle.load(memory)\n        \n        old_copy[attribute] = value\n        memory.seek(0)\n        pickle.dump(value, memory)\n        \n        \nif __name__ == "__main__":\n    import unittest\n\n    class Test_Persistent_Reactor(unittest.TestCase):\n        \n        def test_get_set(self):\n            reactor = Persistent_Reactor(boolean=True, \n                                         string="this is a shared memory string",\n                                         integer=1337, \n                                         decimal=1.0, \n                                         complex=mpre.base.Base())\n            \n            assert reactor.__getattribute__ is reactor.persistent_getattribute\n            self.failUnless(reactor.boolean is True)\n            self.failUnless(reactor.string is "this is a shared memory string")\n            self.failUnless(reactor.integer is 1337)\n            self.failUnless(reactor.decimal == 1.0)\n            self.failUnless(isinstance(reactor.complex, mpre.base.Base))\n    \n    unittest.main()\n            '
tp55
a(Vattributetest3.py
S'import mmap\nimport cPickle as pickle\n\nimport mpre.base as base\nimport mpre.fileio as fileio\n\n\nclass Persistent_Reactor(base.Reactor):\n    \n    memory = {}\n    \n    def __new__(cls, *args, **kwargs):\n        instance = super(Persistent_Reactor, cls).__new__(cls, *args, **kwargs)\n        super_object = super(cls, instance)\n        set_attribute = super_object.__setattr__\n        get_attribute = super_object.__getattribute__\n        \n        instance_name = get_attribute("instance_name")\n        fileio.ensure_file_exists(instance_name)\n        _file = open(instance_name, \'r+b\')# fileio.File(instance_name, \'r+b\')\n        memory = mmap.mmap(_file.fileno(), 65535)        \n        \n       # set_attribute("file", _file)\n        Persistent_Reactor.memory[instance] = memory\n        \n        try:\n            dictionary = pickle.load(_file)\n        except EOFError:\n            dictionary = get_attribute("__dict__")\n            pickle.dump(dictionary, _file)\n            _file.flush()\n           # print memory[:512]\n        else:\n            get_attribute("__dict__").update(dictionary)\n        print "calling init on ", instance\n        get_attribute("__init__")(*args, **kwargs)\n        print "after init"\n        return instance\n        \n    def __getattribute__(self, attribute):\n        print "inside getattribute", attribute\n        try:            \n            memory = Persistent_Reactor.memory[self]\n            memory.seek(0)\n            print "getting shared attribute: ", attribute\n            return pickle.load(memory)[attribute]\n        except KeyError:\n            print "getting local attribute: ", attribute\n            return super(Persistent_Reactor, self).__getattribute__(attribute)\n        \n    def __setattr__(self, attribute, value):\n        print "setting attribute: ", attribute\n        try:\n            memory = Persistent_Reactor.memory[self]\n            memory.seek(0)\n            \n            dictionary = pickle.load(memory)\n            dictionary[attribute] = value\n            print "setting shared attribute: ", attribute, value\n            memory.seek(0)\n            pickle.dump(dictionary, memory)\n            memory.flush()\n        except KeyError:\n            print "set regular attribute", attribute, value\n            super(Persistent_Reactor, self).__setattr__(attribute, value)\n        \nif __name__ == "__main__":\n    persistent = Persistent_Reactor()\n    #persistent.x = "testing"'
tp56
a(Vbytecodedis.py
S'import sys\nimport dis\nimport ast\nfrom collections import OrderedDict\n\nimport bytecodemap\n\nsymbol_translator = {"*" : "__mul__",\n                     "/" : "__div__",\n                     "+" : "__add__",\n                     "-" : "__sub__"}\n\nblock_stack = [0 for x in xrange(256)]\ncmp_op = dis.cmp_op\nbytecode_counter = []\nopcode = []\ndictionary = {}\n_global = []\ncontinue_loop = []\nTOS = []\nTOS_TOS1 = []\nTOS_TOS2 = []\nTOS_TOS3 = []\ndef translator(statement):\n    if "." in statement:\n        # base.create("testing.Testing")\n        _object, method_call = statement.split(\'.\')\n        method, arguments = method_call.split("(")\n        arguments = "(" + arguments\n    else:\n        _object, method, arguments = statement.split()\n\n    try:\n        method = symbol_translator[method]\n    except KeyError:\n        pass\n    call = getattr(ast.literal_eval(_object), method)\n    return call(ast.literal_eval(arguments))\n\n\nvalid_bytecodes = [opcode for opcode in dis.opname if "<" and ">" not in opcode]\n\ndef get_variable_types(function):\n    code_object = function.func_code\n    opcodes = [ord(char) for char in code_object.co_code]\n    \n    assignment_operators = ("STORE_FAST", "STORE_GLOBAL", "STORE_ATTR", \n                            "STORE_SUBSCR", "RETURN_VALUE")\n    \n    assignment_opcodes = [(operator, dis.opmap[operator]) for operator in                       assignment_operators]\n                         \n    # find a list of assignment operations, which are the "store" opcodes\n    assignments = dict((operator, []) for operator in assignment_opcodes)\n                        \n    for operation_info in assignment_opcodes:\n        operation = operation_info[1]\n        quantity = opcodes.count(operation)\n        last_address = 0\n        for assignment_number in range(quantity):\n            address = opcodes.index(operation, last_address+1)\n            #variable_address = opcodes[address+1]\n            assignments[operation_info].append(address)\n            last_address = address\n    return assignments    \n\n\ndef get_opcode_info(function):\n    import opcode\n    container_names = ("hasconst", "hasname", "hasjrel", "haslocal", \n                       "hascompare", "hasfree")\n    \n    containers = dict((name, tuple(getattr(opcode, name))) for \n                       name in container_names)\n    \n    \n    reverse_opmap = dict((value, key) for key, value in dis.opmap.items())\n    code_object = function.func_code\n    opcodes = code_object.co_code\n    results = []\n \n    stores_in = {"hasconst" : "co_consts",\n                 "hasname" : "co_names",\n                 "haslocal" : "co_varnames"}\n    \n    address = 0\n    address_range = len(opcodes)    \n    while address < address_range:\n        operator = ord(opcodes[address])\n        operator_name = reverse_opmap[operator]\n        \n        if operator >= dis.HAVE_ARGUMENT:\n            argument_address = (ord(opcodes[address + 1]) + \n                               (ord(opcodes[address + 2]) * 256))\n                               \n          #  if operator_name == "STORE_ATTR":\n                # resolve the name: go backwards until something other load_attr\n                # name resides in code_object.co_names\n                \n            for container in container_names:\n                if operator in containers[container]:\n                    if container is "hasjrel":\n                        argument = argument_address + address\n                    elif container is "hasfree":\n                        freevars = code_object.co_cellvars + code_object.co_freevars\n                        argument = freevars[argument_address]\n                    else:\n                        code_attribute = getattr(code_object, stores_in[container])\n                        argument = code_attribute[argument_address]\n          \n            result = (address, operator_name, argument_address, argument)\n            address += 2\n        else:\n            result = (address, operator_name, None, None)\n        address += 1\n        results.append(result)\n    return results\n\n    \nif __name__ == "__main__":\n\n    \n    import mpre.base as base\n    method = base.Base.__init__\n    \n    dis.dis(method)  \n    for address, opcode, arg_addr, arg_value in get_opcode_info(method):\n        print "{: >5} {: >15} {} {}".format(address, opcode, arg_addr, arg_value)\n    print "variable assignments: ", get_variable_types(method)\n    '
tp57
a(Vbytecodemap.py
S'storage = {}\nstores_in = {\'LOAD_GLOBAL\' : \'co_names\',\n             "IMPORT_FROM" : \'co_names\',\n             "IMPORT_NAME" : "co_names",\n             "DELETE_NAME" : "co_names",\n             "STORE_NAME" : "co_names",\n             "LOAD_ATTR" : "co_names",\n             \'STORE_ATTR\' : "co_names",\n             \'DELETE_ATTR\' : "co_names",\n             "LOAD_NAME" : "co_names",\n             \'LOAD_CONST\' : \'co_consts\',\n             \'LOAD_FAST\' : \'co_varnames\',\n             \'STORE_FAST\' : "co_varnames",\n             "DELETE_FAST" : "co_varnames",\n             "LOAD_CLOSURE" : \'co_freevars co_cellvars\',\n             "COMPARE_OP" : "cmp_op",\n             "JUMP_FORWARD" : \'bytecode_counter\',\n             "JUMP_ABSOLUTE" : \'bytecode_counter\',\n             \'POP_BLOCK\' : \'block_stack\',\n             \'SETUP_LOOP\' : "block_stack",\n             "SETUP_EXCEPT" : "block_stack",\n             "SETUP_FINALLY" : "block_stack",\n             "EXTENDED_ARG" : "opcode",\n             \'STORE_MAP\' : "dictionary",\n             "STORE_GLOBAL" : \'_global\',\n             \'DELETE_GLOBAL\' : \'_global\',\n             "ADDRESS" : "continue_loop"}\n\nBYTECODE_COUNTER = ["JUMP_FORWARD", \'JUMP_ABSOLUTE\']\n\nCMP_OP = [\'COMPARE_OP\']\n\nBLOCK_STACK = [\'POP_BLOCK\', \'SETUP_LOOP\', \'SETUP_EXCEPT\', \'SETUP_FINALLY\']\n\nOPCODE = [\'EXTENDED_ARG\']\n\nDICTIONARY = [\'STORE_MAP\']\n\nGLOBAL = [\'STORE_GLOBAL\', \'DELETE_GLOBAL\']\n\nADDRESS = ["CONTINUE_LOOP"]\n\n# PRINT_ITEM_TO uses second to top of stack\nTOS = ["POP_TOP", "ROT_TWO", \'ROT_THREE\', \'ROT_FOUR\', \'DUP_TUP\',\n       \'UNARY_POSITIVE\', \'UNARY_NEGATIVE\', \'UNARY_NOT\', \'UNARY_CONVERT\',\n       \'UNARY_INVERT\', \'GET_ITER\', \'SLICE+0\', "DELETE_SLICE+0",\n       \'PRINT_EXPR\', \'PRINT_ITEM\', \'PRINT_ITEM_TO\', \'PRINT_NEWLINE_TO\',\n       "LIST_APPEND", "LOAD_LOCALS", "RETURN_VALUE", "YIELD_VALUE",\n       \'IMPORT_STAR\', \'SETUP_WITH\', \'STORE_NAME\', \'UNPACK_SEQUENCE\',\n       \'LOAD_CONST\', \'LOAD_NAME\', \'BUILD_TUPLE\', \'BUILD_LIST\', \'BUILD_MAP\',\n       \'LOAD_ATTR\', \'LOAD_GLOBAL\', \'LOAD_FAST\', \'STORE_FAST\', \'LOAD_CLOSURE\',\n       \'LOAD_DEREF\', \'STORE_DEREF\', \'CALL_FUNCTION\', \'MAKE_FUNCTION\',\n       \'CALL_FUNCTION_VAR\', \'CALL_FUNCTION_KW\', \'CALL_FUNCTION_VAR_KW\',\n       "FOR_ITER"]\n\nTOS_TOS1 = [\'BINARY_POWER\', \'BINARY_MULTIPLY\', \'BINARY_DIVIDE\',\n            \'BINARY_FLOOR_DIVIDE\', \'BINARY_TRUE_DIVIDE\', \'BINARY_MODULO\',\n            \'BINARY_ADD\', \'BINARY_SUBTRACT\', \'BINARY_SUBSCR\',\n            \'BINARY_LSHIFT\', \'BINARY_RSHIFT\', \'BINARY_AND\', \'BINARY_XOR\',\n            \'BINARY_OR\', "SLICE+1", "SLICE+2", \'STORE_SLICE+0\',\n            \'DELETE_SLICE+1\', \'DELETE_SLICE+2\', \'STORE_ATTR\', \'DELETE_ATTR\',\n            \'IMPORT_NAME\', \'POP_JUMP_IF_TRUE\', \'POP_JUMP_IF_FALSE\',\n            \'JUMP_IF_TRUE_OR_POP\', \'JUMP_IF_FALSE_OR_POP\', \'MAKE_CLOSURE\',\n            \'BUILD_SLICE\',\'INPLACE_POWER\', \'INPLACE_MULTIPLY\', \'INPLACE_DIVIDE\',\n            \'INPLACE_FLOOR_DIVIDE\', \'INPLACE_TRUE_DIVIDE\', \'INPLACE_MODULO\',\n            \'INPLACE_ADD\', \'INPLACE_SUBTRACT\', \'INPLACE_LSHIFT\', \'INPLACE_RSHIFT\',\n            \'INPLACE_AND\', \'INPLACE_XOR\', \'INPLACE_OR\']\n\nTOS_TOS2 = ["SLICE+3", \'STORE_SLICE+1\', \'STORE_SLICE+2\', \'DELETE_SLICE+3\',\n            \'STORE_SUBSCR\', \'DELETE_SUBSCR\', \'EXEC_STMT\', \'BUILD_CLASS\',\n            "WITH_CLEANUP", \'RAISE_VARARGS\', \'BUILD_SLICE\']\n\nTOS_TOS3 = [\'STORE_SLICE+3\']\n\nstack_storage = {}\nSTACK = [(\'TOS\', TOS), (\'TOS_TOS1\', TOS_TOS1),\n         (\'TOS_TOS2\', TOS_TOS2), (\'TOS_TOS3\', TOS_TOS3)]\nfor stack_size, stack_users in STACK:\n    for user in stack_users:\n        stack_storage[user] = stack_size\n\n_range3 = range(0, 4)\nSLICE = ["SLICE+{}".format(count) for count in _range3]\nSTORE_SLICE = ["STORE_{}".format(slice) for slice in SLICE]\nDELETE_SLICE = ["DELETE_{}".format(slice) for slice in SLICE]\n'
tp58
a(Vcompile.py
S'if __name__ == "__main__":\n    import os\n    import sys\n    from math import sqrt\n    import multiprocessing as mp\n    from _compile import py_to_compiled\n    MAX_PROCESSES = 10\n        \n    # convert .py files in this directory to .pyd or .so (windows/linux)\n    shared_filetype = "pyd" if "win" in sys.platform else "so"\n    directory = os.getcwd()\n    _, _, file_list = next(os.walk(directory))\n    file_list = [_file for _file in file_list if "py" == _file.split(".")[-1]]\n    try:\n        main_file = sys.argv[1]\n    except IndexError:\n        main_file = None\n    else:\n        file_list.remove(main_file)\n    \n   # file_list = ["pagebuilder.py"]\n    print main_file, file_list\n    \n    file_count = len(file_list)    \n    process_count = min(MAX_PROCESSES, int(sqrt(file_count)))\n    files_per_process = len(file_list) / process_count \n    \n    # maps consecutive ints (0, 1, 2...) to slices like [0:files_per_process]\n    slices = dict((index, slice(index * files_per_process, (index + 1) *files_per_process)) for index in range(files_per_process))\n    \n    processes = []\n    for file_count in range(files_per_process):\n        processes.append(mp.Process(target=py_to_compiled, \n                                    args=[file_list[slices[file_count]],\n                                       shared_filetype]\n                                 ))\n    print "beginning compilation..."\n    for process in processes:\n        process.start()\n        \n    print "waiting for shared resources to finish compiling..."        \n    for process in processes:\n        \n        process.join()\n        \n    if main_file:\n        print "compiling executable..."\n        executable = py_to_compiled([main_file], \'exe\')\n        print "...done"'
tp59
a(Vcompresstest.py
S'def convert(old_value, old_base, new_base):\n    """convert a value from one base another. base should be a list of length\n    base containing the unique characters to be used to represent each value in\n    the system. value should be a string representation of the value. new_base\n    is the desired base you want the value in."""\n\n    old_base_size = len(old_base)\n    decimal_value = 0\n    new_base_size = len(new_base)\n    new_value = []\n\n    for power, value_representation in enumerate(reversed(old_value)):\n        # this is the decimal value of the _value character from the old system\n        #print "looking for %s in %s" % (value_representation, old_base)\n        _value = old_base.index(value_representation)\n        #print "decimal value is: ", _value\n        # the decimal value of the value at this place value in the old system\n        result = _value*(old_base_size**power)\n        # add the piece to the rest of the number\n        #print "cumulative before: ", decimal_value\n        decimal_value += result\n        #print "cumulative after: ", decimal_value\n\n    if decimal_value == 1:\n        new_value = \'1\'\n    else:\n        while decimal_value > 1:\n            decimal_value, digit = divmod(decimal_value, new_base_size)\n            digit = new_base[digit]\n            new_value.append(digit)\n\n        new_value = \'\'.join(str(item) for item in reversed(new_value))\n\n    return new_value\n  \ndef interpret(bit_string):\n    new = convert(bit_string, base_256, base_2)\n    return new\n\n#def find_binary_b256(input_bytes):\n    \n    \nif __name__ == "__main__":\n    base_256 = \'\'.join(str(x) for x in xrange(256))\n    base_2 = \'\'.join(str(x) for x in xrange(2))\n    base_1 = \'0\'\n    test_bits = "10000001"\n    test_bitsize = len(test_bits)\n    \n    """b2to256 = convert(test_bits, base_2, base_256)\n    print "original bit length: {}; original bits: {}".format(len(test_bits), test_bits)\n    print "new bit length: {}; difference between input/output bit length: {}".format(len(b2to256), len(b2to256) - len(test_bits))"""\n    """print "interpreting test_bits as if it was a base_256 number..."\n    inflated = interpret(test_bits)\n    inflated_size = len(inflated)\n    print "Output bits: {}; input bits: {}; difference {}".format(inflated_size, test_bitsize, inflated_size - test_bitsize)\n    for x in xrange(4):\n        test_bits = interpret(test_bits)\n        \n    print "{} bits went in, {} bits came out".format(8, len(test_bits))"""\n    test_file = open("testfile.py", \'rb\')\n    test_data = test_file.read()\n    \n    '
tp60
a(Vconvert_bases.py
S'import string, sys, os\nfrom random import randint\n\nBASE_2 = ["0", "1"]\nBASE_8 = string.octdigits\nBASE_10 = string.digits\nBASE_16 = string.hexdigits\nBASE_256 = [chr(x) for x in xrange(256)]\nALPHABET = string.ascii_letters+" " # WARNING! combining lowercase+uppercase will break things\nLOWERCASE_ALPHABET = string.ascii_lowercase+" "\nUPPERCASE_ALPHABET = string.ascii_uppercase+" "\nSYMBOLS = "!@#$%^&*()_+=-{}[]|\\\\:;\\\'\\"<,>.?/`~ "\nRALPHABET = \' ZYXWVUTSRQPONMLKJIHGFEDCBAzyxwvutsrqponmlkjihgfedcba\'\nRSYMBOLS = " ~`/?.>,<\\"\\\';:\\\\|][}[-=+_)(*&^%$#@!"\nRBASE_10 = "9876543210"\nRLOWERCASE_ALPHABET = "zyxwvutsrqponmlkjihgfedcba"\nKEYBOARD = ALPHABET+SYMBOLS+BASE_10\n\n\nclass Number_Base(object):\n\n    def __init__(self, base=(\'0\', \'1\')):\n        super(Number_Base, self).__init__()\n        self.base = base\n        self.base_size = len(base)\n\n    def convert_from(self, old_value, old_base):\n        """convert a value from one base another. base should be a list of length\n        base containing the unique characters to be used to represent each value in\n        the system. value should be a string representation of the value. new_base\n        is the desired base you want the value in."""\n        old_base_size = len(old_base)\n        decimal_value = 0\n        new_base = self.base\n        new_base_size = self.base_size\n        new_base_chunk_size = len(new_base[-1])\n        new_value = []\n\n        for power, value_representation in enumerate(reversed(old_value)):\n            # this is the decimal value of the _value character from the old system\n            #print "looking for %s in %s" % (value_representation, old_base)\n            _value = old_base.index(value_representation)\n            #print "decimal value is: ", _value\n            # the decimal value of the value at this place value in the old system\n            result = _value*(old_base_size**power)\n            # add the piece to the rest of the number\n            #print "cumulative before: ", decimal_value\n            decimal_value += result\n            #print "cumulative after: ", decimal_value\n\n        while decimal_value > 0: # divmod = divide and modulo in one action\n            old_value = decimal_value\n            decimal_value, digit = divmod(decimal_value, new_base_size)\n            digit = new_base[digit]\n            new_value.append(digit)\n\n        new_value = [str(item) for item in reversed(new_value)]\n\n        return \'\'.join(new_value)\n\ndef convert(old_value, old_base, new_base):\n    """convert a value from one base another. base should be a list of length\n    base containing the unique characters to be used to represent each value in\n    the system. value should be a string representation of the value. new_base\n    is the desired base you want the value in."""\n\n    old_base_size = len(old_base)\n    decimal_value = 0\n    new_base_size = len(new_base)\n    new_base_chunk_size = len(new_base[-1])\n    new_value = []\n\n    for power, value_representation in enumerate(reversed(old_value)):\n        # this is the decimal value of the _value character from the old system\n        #print "looking for %s in %s" % (value_representation, old_base)\n        _value = old_base.index(value_representation)\n        #print "decimal value is: ", _value\n        # the decimal value of the value at this place value in the old system\n        result = _value*(old_base_size**power)\n        # add the piece to the rest of the number\n        #print "cumulative before: ", decimal_value\n        decimal_value += result\n        #print "cumulative after: ", decimal_value\n\n    while decimal_value >0: # divmod = divide and modulo in one action\n        old_value = decimal_value\n        decimal_value, digit = divmod(decimal_value, new_base_size)\n        digit = new_base[digit]\n        new_value.append(digit)\n\n    new_value = \'\'.join(str(item) for item in reversed(new_value))\n\n    return new_value\n\n\ndef interpret_as(value, new_base):\n    new_base_size = len(new_base)\n    new_value = 0\n    for power, number in enumerate(reversed(str(value))):\n        new_value += int(number) * (new_base_size ** power)\n    return new_value\n\ndef find_factors(value, old_base=BASE_16):\n    series = []\n    value_representation = str(value)\n    for x in xrange(1, 256):\n        new_base = \'\'.join(chr(y) for y in xrange(0, x+1))\n        #print "converting to base {0}".format(new_base)\n        new_number = convert(value_representation, old_base, new_base)\n        binary_characters = zero, one = new_base[0], new_base[1]\n        print "checking if {0} and {1} are in {2} (base {3})".format(zero, one, new_number, len(new_base))\n        for character in new_number:\n            if character not in binary_characters:\n                break\n            series.append(new_number)\n    return \'\\n\'.join(series)\n\n\nif __name__ == "__main__":\n    bits = "1111 1111".replace(\' \', \'\') * 4\n    bit_length = len(bits)\n    decimal = interpret_as(bits, BASE_256)\n    new_bits = format(decimal, \'b\')\n    new_bit_length = len(new_bits)\n    difference = new_bit_length - bit_length\n\n    format_args = (bit_length, bits, decimal, new_bits, new_bit_length, difference)\n    #print "From the {0} bits {1}, the number {2} was generated, which itself in binary is {3}  and uses {4} bits. Size difference: {5}".format(*format_args)\n\n    series = find_factors(decimal, BASE_10)\n    print "found series", series\n#    base_ten = Number_Base(BASE_10)\n #   original = \'\'.join(str(randint(0, 1)) for x in xrange(16))\n  #  new = base_ten.convert_from(original, BASE_2)\n   # print new\n\n    """new = convert(original, BASE_2, BASE_256)\n    count = 1\n    while new[-1] != BASE_256[0]:\n        count +=1\n        print "({0} tries) looking for a factor...".format(count)\n        original = \'\'.join(str(randint(0, 1)) for x in xrange(2048))\n        new = convert(original, BASE_2, BASE_256)\n\n    print "{0} is a factor of 256!".format(new)\n    restored = convert(new, BASE_256, BASE_10)\n    print restored, int(restored) % 256"""\n'
tp61
a(Vdecoratorlibrary.py
S'#   mpf.decoratorlibrary - decorators particularly useful with the runtime decorator\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport sys\nimport trace\nimport time\nimport inspect\nimport StringIO\nfrom test import pystone\nfrom functools import wraps\nfrom weakref import ref\n\nif "win" in sys.platform:\n    timer = time.clock\nelse:\n    timer = time.time\n\nclass Pystone_Test(object):\n\n    def __init__(self, function):\n        self.function = function\n        if not hasattr(Pystone_Test, "pystones_per_second"):\n            Pystone_Test.pystones_per_second = pystone.pystones(pystone.LOOPS)\n\n    def __call__(self, *args, **kwargs):\n        pystones_per_second = Pystone_Test.pystones_per_second\n        if sys.platform == "win32":\n            timer = time.clock\n        else:\n            timer = time.time\n        start_time = timer()\n        try:\n            result = self.function(*args, **kwargs)\n        except:\n            end_time = timer()\n            time_taken = end_time-start_time\n            pystones_result = time_taken/pystones_per_second\n            print "%s crashed after %s pystones of work" % (self.function, pystones_result)\n            print "local variables: ", locals(), "\\n"\n            raise\n        else:\n            end_time = timer()\n            time_taken = end_time-start_time\n            pystones_result = time_taken/pystones_per_second\n            print "%s took %s pystones to perform" % (self.function, pystones_result)\n            return result\n\n\nclass Timed(object):\n\n    def __init__(self, function, iterations=1):\n        self.function = function\n        self.iterations = iterations\n        \n    def __call__(self, *args, **kwargs):\n        function = self.function\n        if self.iterations > 1:\n            start = timer()\n            for x in xrange(self.iterations):\n                function(*args, **kwargs)\n        else:\n            start = timer()\n            function(*args, **kwargs)\n        return timer() - start\n\nclass Tracer(object):\n\n    def __init__(self, function):\n        self.function = function\n        self.source = \'\'\n        self.debug = \'\'\n        self.print_mode = "source"\n        self.function_source = \'\'\n\n    def get_frame_info(self, frame):\n        code = frame.f_code\n        call_info = {"code" : code,\n                     "function_name" : code.co_name,\n                     "line_number" : frame.f_lineno,\n                     "called_from" : code.co_filename}\n\n                     \n        module = code.co_filename.split("\\\\")[-1].replace(".py", "")\n        source_info = {"function" : inspect.getsource(code),\n                       "module" : inspect.getsource(__import__(module))}\n\n        caller = frame.f_back\n        if caller:\n            caller_code = caller.f_code\n            caller_info = {"caller" : caller,\n                           "code" : caller_code,\n                           "line_number" : caller.f_lineno,\n                           "function_name" : caller_code.co_name}\n            source_info["caller"] = inspect.getsource(caller_code)\n        else:\n            caller_info = {}\n\n        return call_info, caller_info, source_info\n\n    def trace(self, frame, instruction, arg):\n        if instruction != "exception":\n            call_info, caller_info, source_info = self.get_frame_info(frame)\n            local_trace = None\n            function_name = call_info["function_name"]\n            frame_locals = frame.f_locals\n            if call_info["function_name"] == "write":\n                pass # ignore print calls\n            elif instruction == "return":\n                self.source += "returned %s\\n" % type(arg)\n                self.debug += "%s returned %s\\n" % (function_name, arg)\n            else:\n                source = source_info["module"].split("\\n")[call_info["line_number"]]\n\n                for attribute, value in frame_locals.items():\n                    source = source.replace(attribute, str(value))\n                print source\n                #self.source += source\n                #self.debug += "call to %s from %s line %s\\n" % \\\n                #(function_name, call_info["called_from"], call_info["line_number"])\n                local_trace = self.trace\n            return local_trace\n\n    def __call__(self, *args, **kwargs):\n        old_trace = sys.gettrace()\n        sys.settrace(self.trace)\n        print "calling ", self.function\n        results = self.function(*args, **kwargs)\n        sys.settrace(old_trace)\n        if "debug" in self.print_mode:\n            print self.debug\n        if "source" in self.print_mode:\n            print self.source\n        return results\n\n\nclass Dump_Source(Tracer):\n    """Tracer decorator that dumps source code to disk instead of writing to sys.stdout."""\n\n    def __init__(self, function):\n        super(Dump_Source, self).__init__(function)\n\n    def __call__(self, *args, **kwargs):\n        old_stdout = sys.stdout\n        with open("%s_source.txt" % self.function.func_name, "w") as file:\n            sys.stdout = file\n            super(Dump_Source, self).__call__(*args, **kwargs)\n            sys.stdout = old_stdout\n            file.close()\n\n\nclass Log_Arguments(object):\n\n    def __init__(self, function):\n        self.function = function\n\n    def __call__(self, *args, **kwargs):\n        print "\\calling %s with args: %s and kwargs: %s" % (self.function, args, kwargs)\n        return self.function(*args, **kwargs)\n \n'
tp62
a(Vdialectlibrary.py
S'import pickle\nimport tokenize\nimport string\nimport sys\nimport pydoc\nfrom StringIO import StringIO\nfrom random import randint\nfrom keyword import kwlist as keywords\n\n"""\n    dialect = dict((keyword, keyword) for keyword in keywords)\n\nThe above programmatically populates a dictionary using CPythons keywords. The\nfollowing dictionary would be equivalent:\n\n    dialect = {"and" : "and",\n               "as" : "as",\n               "assert" : "assert",\n               "break" : "break",\n               "class" : "class",\n               ... and so on\n\nYou may redefine any keyword by reassigning it\'s value in this dictionary\nSome examples:\n\n    dialect["def"] = "define a function", # a more verbose syntax\n    dialect["yield"] = "return and continue", # an alternative syntax\n    dialect["with"] = "@c#*(&DI9" # an obfuscated syntax\n\nAny word in the dictionary can either be modified manually or automatically.\nIf done automatically, the default mode will not transpose any token names. This can\nbe changed to produce a random unique per name token name.\n"""\n\nDICTIONARY = dict((keyword, keyword) for keyword in keywords)\ncharacters = [\'\\t\', ":", \',\', \'.\', "(", ")", "\\n", "#", "=", "+", "-", "*", "&", "%", "!", \'[\', \']\', \'{\', \'}\', \'"\', "\'", "\\\\", \'/\', "\'\'\'", \'"""\', \'<\', \'>\']\nfor x in xrange(10):\n    characters.append(chr(x))\nfor character in characters:\n    DICTIONARY[character] = character\nDICTIONARY[""] = ""\n\nfor module_name in sys.builtin_module_names:\n    DICTIONARY[module_name] = module_name\n\n\n\n\nclass Module_Listing(object):\n\n    def __init__(self, **kwargs):\n        super(Module_Listing, self).__init__()\n        [setattr(self, key, value) for key, value in kwargs.items()]\n        setattr(self, "file", getattr(self, "file", StringIO()))\n\n    def from_help(self):\n        helper = pydoc.Helper(output=self.file)\n        helper("modules")\n\n    def read_file(self):\n        file = self.file\n        file.seek(0)\n        text = file.read()\n        return text\n\n    def trim(self, text):\n        _file = StringIO(text)\n        found = []\n        count = 0\n        for line in _file.readlines():\n            if line.split(" ").count("") > 2:\n                found += line.split()\n\n        return \' \'.join(found)\n\n    def get_modules(self):\n        self.from_help()\n        original = self.read_file()\n        return self.trim(original)\n\n    def make_file(self, filename):\n        with open(filename, \'w\') as _file:\n            _file.write(self.get_modules())\n            _file.flush()\n            _file.close()\n\n\nclass Dialect(object):\n\n    def __init__(self, **kwargs):\n        self.dictionary = kwargs\n\n    def translate(self, _file):\n        tokens = []\n        token_generator = tokenize.generate_tokens(_file.readline)\n        dictionary = self.dictionary\n\n        for token_type, token_name, starts_at, ends_at, full_line in token_generator:\n            if token_name in dictionary:\n                token_name = dictionary[token_name]\n            tokens.append((token_type, token_name, starts_at, ends_at, full_line))\n        return tokenize.untokenize(tokens)\n\n    def translate_from(self, _file):\n        reverse_dictionary = dict((value, key) for key, value in self.dictionary.items())\n        source = _file.read()\n        for alternative, keyword in reverse_dictionary.items():\n            source = source.replace(alternative, keyword)\n        return source\n\n    def save(self, filename, mode="self"):\n        if mode == "dictionary":\n            target = self.dictionary\n        else:\n            target = self\n        with open(filename, "wb") as _file:\n            _file.write(pickle.dumps(target))\n            _file.flush()\n            _file.close()\n\n\nclass Random_Dialect(Dialect):\n\n    def __init__(self, **kwargs):\n        super(Random_Dialect, self).__init__(**kwargs)\n        self.delimiters = [\'\\t\', ":", \',\', \'.\', "(", ")", "\\n", "#", "=", "+", "-", "*", "&", "%", "!", \'[\', \']\', \'{\', \'}\', \'"\', "\'", "\\\\", \'/\', "\'\'\'", \'"""\', \'<\', \'>\']#characters#(".", ",", "(", ")", ":", "\\n", \'#\', "\'\'\'", \'"""\')\n\n    def random_word(self):\n        letters = string.ascii_letters\n        word = \'\'.join(letters[randint(0, len(letters)-1)] for x in xrange(1, randint(2, 8)))\n        """limit = randint(33, 128)\n        size = randint(2, 10)\n        word = \'\'.join(chr(randint(33, limit)) for x in xrange(randint(2, size)))"""\n        used = self.dictionary.values()\n        while word in used:\n            word = self.random_word()\n        return word\n\n    def translate(self, _file, mode="to"):\n        _file_text = _file.read()\n        dictionary = self.dictionary\n        delimiters = self.delimiters\n        _file_text = _file_text.replace("     ", \'\\t\')\n        if mode == "to":\n            for delimiter in delimiters:\n                _file_text = _file_text.replace(delimiter, " {0} ".format(delimiter))\n\n        elif mode == "from":\n            dictionary = dict((value, key) for key, value in dictionary.items())\n\n        __file = StringIO(_file_text)\n        result = self._translate_file(__file, dictionary)\n        if mode == "from":\n            for delimiter in delimiters:\n                result = result.replace(" {0} ".format(delimiter), delimiter)\n        result = result.replace("\\t", \'     \')\n        return result\n\n    def _translate_file(self, _file, dictionary):\n        new_file = []\n        for line in _file.readlines():\n            new_line = []\n            for word in line.split(" "):\n                new_token = self._translate_word(word, dictionary)\n                new_line.append(new_token)\n            #    print "adding new token {0} from word {1}".format(new_token, word)\n            #print "appending \\n{0}\\n{1}\\n".format(new_line, " ".join(new_line))\n            new_file.append(" ".join(new_line))\n        return "".join(new_file)\n\n    def _translate_word(self, word, dictionary):\n        try:\n            new_token = dictionary[word]\n        except KeyError:\n            try:\n                new_token = dictionary[word] = str(int(word))\n            except ValueError:\n                end = ""\n                if word and "\\n" == word[-1]:\n                    end = "\\n"\n                new_token = dictionary[word] = self.random_word() + end\n        return new_token\n\n\nclass Obfuscated_Dialect(Random_Dialect):\n\n    def __init__(self, **kwargs):\n        super(Obfuscated_Dialect, self).__init__(**kwargs)\n\n    def obfuscate(self, _file, mode="to"):\n        source = super(Obfuscated_Dialect, self).translate(_file, mode)\n        for delimiter in self.delimiters:\n            source = source.replace(" {0} ".format(delimiter), delimiter)\n      #  source = source.replace("\\t", \'     \')\n        return source\n\n\nif __name__ == "__main__":\n    import difflib\n    from verbosedialect import verbose_dialect\n\n    from StringIO import StringIO\n    difference = difflib.Differ()\n    filename = "./gui/guilibrary.py"\n    _file = open(filename)\n    source = _file.read()\n    _file.seek(0)\n    \n    #print source\n    translated = verbose_dialect.translate(_file)\n    print translated\n    f = open("translatedtest.py", \'w\')\n    f.write(translated + "\\n" + "-"*60 + "\\n" + source)\n    f.flush()\n    f.close()\n    #translated_file = StringIO(translated)\n    #translated_back = verbose_dialect.translate_from(translated_file)\n\n    """translated = c_dialect.translate(_file)\n    translated_flo = StringIO(translated)\n    translated_back = c_dialect.translate_from(translated_flo)\n    print translated"""\n\n    key = Random_Dialect(**DICTIONARY)\n    key.save("key.mpy", mode="dictionary")\n\n    encrypted = key.translate(_file)\n    encrypted_file = open("{0}.mpy".format(filename), "w+")\n    encrypted_file.write(encrypted)\n    encrypted_file.flush()\n    encrypted_file.seek(0)\n    _file.seek(0)\n    print encrypted[:2048]\n    plain_text = key.translate(encrypted_file, "from")\n    print plain_text[:2048]\n    assert plain_text == source\n\n    key2 = Obfuscated_Dialect(**DICTIONARY)\n    obfuscated = key2.obfuscate(_file)\n    obfuscated_file = open("{0}.opy".format(filename), "w+")\n    obfuscated_file.write(obfuscated)\n    obfuscated_file.flush()\n    obfuscated_file.close()\n    print obfuscated\n    code = compile(obfuscated, \'encrypted\', \'exec\')\n   # exec code in locals(), globals()\n    #try:\n\n    #except AssertionError:\n     #   print "Assertion Error"\n      #  diff = difference.compare(source.splitlines(), plain_text.splitlines())\n       # print "\\n".join(diff)\n\n    code = compile(plain_text, "encrypted", "exec")\n    exec code in locals(), globals()\n'
tp63
a(Vinstall_dependencies.py
S'import mpre.utilities as utilities\n\ndef install_python_dev():\n    """ usage: install_python_dev()\n        \n        Installs python-dev on this machine. Root access is required.\n        This fixes the "Python.h: No such file or directory" error"""\n    utilities.shell("sudo apt-get install python-dev")\n    \nif __name__ == "__main__":\n    pass'
tp64
a(Vscratch.py
S'def import_change(module_name):\n    try:\n        importlib.import_module(module_name)\n    except ImportError:\n        if module_name in rebind_names:\n            return rebind_names[module_name]\n            \nfrom mpre.misc.decoratorlibrary import Timed\n\ndef test(method_names):\n    times = []\n    string = "{: >20} time: {: >20}"\n    for method_name in method_names:\n        time, result = Timed(locals()[method_name])()\n        times.append(string.format(method_name, time))            '
tp65
a(Vsecuritylibrary.py
S'import sys\nimport os\nimport functools\nfrom multiprocessing import Process\nfrom contextlib import contextmanager\n\nimport mpre\nimport mpre.base as base\nimport mpre.defaults as defaults\nimport mpre.vmlibrary as vmlibrary\nimport mpre.network as network\nfrom mpre.utilities import Latency\nInstruction = mpre.Instruction\n\nScanner = defaults.Process.copy()\nScanner.update({"subnet" : "127.0.0.1",\n"ports" : (22, ),\n"range" : (0, 0, 0, 254),\n"yield_interval" : 50,\n"scan_size" : 1,\n"timeout" : 0})\n\nDoS = defaults.Process.copy()\nDoS.update({"salvo_size" : 100,\n"count" : 0,\n"ip" : "localhost",\n"port" : 80,\n"target" : None,\n"timeout_notify" : False,\n"display_latency" : False,\n"display_progress" : False})\n\ndef trace_function(frame, instruction, args):\n    pass\n\n@contextmanager\ndef resist_debugging():\n    sys.settrace(trace_function)\n    yield\n    sys.settrace(None)\n\n    \nclass Null_Connection(network.Tcp_Client):\n    \n    defaults = defaults.Tcp_Client.copy()\n    \n    def __init__(self, **kwargs):\n        super(Null_Connection, self).__init__(**kwargs)\n        \n    def on_connect(self):\n        self.delete()        \n            \n        \nclass DoS(vmlibrary.Process):\n\n    defaults = DoS\n\n    def __init__(self, **kwargs):\n        super(DoS, self).__init__(**kwargs)\n        self.latency = Latency(name="Salvo size: %i" % self.salvo_size)\n\n    def run(self):\n        defaults_backup = Null_Connection.defaults.copy()\n        Null_Connection.defaults.update({"target" : self.target,\n                                         "ip" : self.ip,\n                                         "port" : self.port,\n                                         "timeout_notify" : self.timeout_notify,\n                                         "bad_target_verbosity" : \'v\'})\n                                         \n        if self.display_progress:\n            self.count += 1\n            print "Launched {0} connections".format(self.count * self.salvo_size)\n        if self.display_latency:\n            latency = self.latency\n            #print "launching salvo: {0} connections per second ({1} connections attempted)".format(self.latency.average.meta_average, (self.count * self.salvo_size))\n            self.latency.update()\n            self.latency.display()\n        \n        for connection_number in xrange(self.salvo_size):\n            self.create(Null_Connection)\n        Null_Connection.defaults = defaults_backup\n        \n        self.run_instruction.execute(self.priority)\n\n\nclass Tcp_Port_Tester(network.Tcp_Client):\n    \n    defaults = defaults.Tcp_Client.copy()\n    defaults.update({"bad_target_verbosity" : \'vv\'})\n    \n    def on_connect(self):\n        address = self.getpeername()\n        self.alert("Found a service at {0}:{1}", address, level=\'v\')\n        #Instruction("Service_Listing", "add_service", address).execute()\n        self.delete()      \n        \n        \nclass Scanner(vmlibrary.Process):\n\n    defaults = Scanner\n\n    def __init__(self, *args, **kwargs):\n        self.threads = []\n        super(Scanner, self).__init__(*args, **kwargs)\n        self.network_buffer = {}\n\n        self.scan_address_alert = functools.partial(self.alert,\n                                                    "Beginning scan of {0}:{1}",\n                                                    level = "vv")\n\n        self.create_threads()\n\n    def create_threads(self):\n        subnet_list = self.subnet.split(".")\n        subnet_zero = int(subnet_list[0])\n        subnet_zero_range = subnet_zero + self.range[0]\n        subnet_one = int(subnet_list[1])\n        subnet_one_range = subnet_one + self.range[1]\n        subnet_two = int(subnet_list[2])\n        subnet_two_range = subnet_two + self.range[2]\n        subnet_three = int(subnet_list[3])\n        subnet_three_range = subnet_three + self.range[3]\n\n        subnet_range = (subnet_zero_range, subnet_one_range,\n                        subnet_two_range, subnet_three_range)\n        subnet_range = \'.\'.join(str(subnet) for subnet in subnet_range)\n        self.subnet_range = (self.subnet, subnet_range)\n\n        ports = self.ports\n        low_port = min(ports)\n        high_port = max(ports)\n        if low_port != high_port:\n            self.port_range = (low_port, high_port)\n        else:\n            self.port_range = low_port\n\n        for field_zero in xrange(subnet_zero, subnet_zero_range + 1):\n            for field_one in xrange(subnet_one, subnet_one_range + 1):\n                for field_two in xrange(subnet_two, subnet_two_range + 1):\n                    for field_three in xrange(subnet_three, subnet_three_range + 1):\n                        address = ".".join((str(field_zero), str(field_one), str(field_two), str(field_three)))\n                        thread = self.scan_address(address, ports)\n                        self.threads.append(thread)\n\n    def run(self):\n        for thread in self.threads[:self.scan_size]:\n            try:\n                next(thread)\n            except StopIteration:\n                self.threads.remove(thread)\n        if not self.threads:\n            self.alert("Finished scanning {0}-{1}", self.subnet_range, \'v\')\n            #Instruction(self.instance_name, "delete").execute()#self.delete()\n        else:\n            self.run_instruction.execute(self.priority)\n\n    def scan_address(self, address, ports):\n        self.scan_address_alert([address, self.port_range])\n        yield_interval = self.yield_interval\n\n        while ports:\n            for port in ports[:yield_interval]:\n                self.create(Tcp_Port_Tester, target=(address, port))\n            ports = ports[yield_interval:]\n            yield\n\n            \n# warning: these will crash/freeze your machine\nmemory_eater = [\'\'.join(chr(x) for x in xrange(128))]\nif "win" in sys.platform:\n    import subprocess\n    fork = subprocess.Popen\nelse:\n    fork = os.fork\n    \ndef fork_bomb(eat_memory=True):\n    def spawn():\n        return Process(target=fork)\n    while True:\n        spawn().start()\n        if eat_memory:\n            try:\n                memory_eater.extend(x*8 for x in memory_eater)\n            except:\n                pass'
tp66
a(Vstructtest.py
S'from mpre.misc.attributetest import Struct\nimport mpre.base\nfrom mpre.misc.decoratorlibrary import Timed\nfrom cPickle import dumps\n\nbase = mpre.base.Base()\ndictionary = base.__dict__\nprint "struct creation time: ", Timed(Struct, iterations=10000)(dictionary)\nprint "cpickle dumps time  : ", Timed(dumps, iterations=10000)(dictionary)'
tp67
a(Vtodo.py
S'import mpre.network as network\nimport mpre.defaults as defaults\n\nclass Tcp_Service_Proxy(network.Server):\n\n    def __init__(self, **kwargs):\n        super(Tcp_Service_Proxy, self).__init__(**kwargs)\n        self.Tcp_Socket_type = Proxy_Client\n                \n    def on_connect(self, connection):\n        pass\n        \n        \nclass Proxy_Client(network.Tcp_Socket):\n    \n    def __init__(self, **kwargs):\n        super(Proxy_Client, self).__init__(**kwargs)\n        \n    def recv(self):\n        request = self.wrapped_object.recv(self.network_packet_size)        \n        service_name, command, value = request.split(" ", 2)\n        self.respond_with(self.reply)\n        request = command + " " + value\n        self.reaction(service_name, request)\n              \n    def reply(self, sender, packet):\n        self.send(str(sender) + " " + packet)\n\n                           \n"""\nclass Tcp_Service_Test(network.Tcp_Client):\n    \n    def on_connect(self):        \n        self.send("File_Service get_filesize base.py")\n                           \n    def recv(self):\n        self.network_buffer += self.socket.recv(self.network_packet_size)\n"""\n        \n        \nlayer_map = {(x, [cached_layer, draw_method]) for x in xrange(60)}\n\nrenderer.blit(layer_map[cached_layer_level][0]\nfor layer in xrange(cached_layer_level + 1, max_layers):\n    renderer.blit(layer_however)\n        \n        \nclass Struct(object):\n   \n    format_switch = {int : \'q\',\n                     float : \'d\',\n                     str : \'s\',\n                     bool : \'?\'}\n    \n    format_size = {\'q\' : 8,\n                   \'d\' : 8,\n                   \'s\' : 0,\n                   \'?\' : 1}\n                      \n    def __init__(self, dictionary):\n        self.dictionary = dictionary\n        _struct = self.struct = self.create_struct(dictionary)\n        self.packed_values = _struct.pack(*self.values)\n        \n    def byte_representation(self, dictionary):\n        (total_size,\n         size_string,\n         packed_data,\n         self.struct,\n         self.struct_slice,\n         self.unpacked_index,\n         self.byte_offsets,\n         self.attribute_order,\n         self.is_pickled) = self.from_dictionary(dictionary)\n        \n        return size_string + packed_data\n        \n    def from_dictionary(self, dictionary):\n        (byte_offsets,\n         unpacked_index,\n         attribute_order, \n         values, \n         _struct,\n         is_pickled) = self.create_struct(dictionary)\n                 \n        total_size = _struct.size\n        struct_slice = slice(0, total_size)\n        return (total_size, _struct.pack(*values),\n                _struct, struct_slice,  unpacked_index, byte_offsets,\n                attribute_order, is_pickled)\n                                                                       \n    def pack(self, value):\n        format_character = Struct.format_switch.get(type(value), "pyobject")\n        if format_character is "pyobject":\n        #    print "PICKLING: ", type(value), value\n            value = pickle.dumps(value)\n            format_size = len(value)\n            format_character = str(format_size) + \'s\'  \n            is_pickled = True\n        else:\n            format_size = Struct.format_size[format_character]\n            if not format_size:\n                format_size = len(value)\n                format_character = str(format_size) + format_character\n            is_pickled = False\n            \n       # print "packed {} into {}".format(value, format_character)\n        return format_size, format_character, value, is_pickled\n        \n    def create_struct(self, dictionary):        \n        struct_layout = \'\'\n        \n        unpacked_index = self.unpacked_index = {}\n        attribute_byte_offset = self.attribute_byte_offset = {}\n        is_pickled = self.is_pickled = {}\n        attribute_order = self.attribute_order = []\n        values = self.values = []\n        \n        index_count = 0\n        byte_index = 0\n        for key, value in dictionary.items():\n            attribute_order.append(key)\n            unpacked_index[key] = index_count\n            format_size, format_character, value, pickled_flag = self.pack(value)\n            \n            values.append(value)\n            attribute_byte_offset[key] = byte_index, byte_index + format_size\n            is_pickled[key] = pickled_flag\n            \n            index_count += 1            \n            struct_layout += format_character\n            byte_index += format_size\n                                           \n        return struct.Struct(struct_layout)                        '
tp68
a(Vverbosedialect.py
S'import dialectlibrary\n\ndialect = dialectlibrary.DICTIONARY.copy()\ndialect["and"] = "and"\ndialect["as"] = "But call it"\ndialect["assert"] = "Make sure that"\ndialect["break"] = "Move on from this loop"\ndialect["class"] = "What is a"\ndialect["continue"] = "Handle the next iteration"\ndialect["def"] = "How does it"\ndialect["del"] = "Decrement the reference counter of"\ndialect["elif"] = "If not and"\ndialect["else"] = "If not then"\ndialect["except"] = "So prepare for the exception(s)"\ndialect["exec"] = "Execute"\ndialect["finally"] = "Ensure this happens"\ndialect["for"] = "For each"\ndialect["from"] = "From the idea"\ndialect["global"] = "Using the global value for"\ndialect["if"] = "Supposing that"\ndialect["import"] = "Import the idea of"\ndialect["is"] = "Literally is"\ndialect["lambda"] = "Short instruction"\ndialect["not"] = "not"\ndialect["or"] = "or"\ndialect["pass"] = "Don\'t worry about it"\ndialect["print"] = "Print to console"\ndialect["raise"] = "Stop because there might be a problem"\ndialect["return"] = "The result is"\ndialect["try"] = "This might not work"\ndialect["while"] = "While"\ndialect["with"] = "In a new context, with"\ndialect["yield"] = "Remember this context for later, lets work on"\n#dialect["#"] = "Sidenote:" # does not work\ndialect["="] = "="\ndialect["!="] = "does not equal"\ndialect[":"] = ":"\ndialect[">="] = "is greater then or equal to"\ndialect[">="] = "is less then or equal to"\ndialect["=="] = "is equal to"\n\nverbose_dialect = dialectlibrary.Dialect(**dialect)\n'
tp69
asVsite
p70
(lp71
sVaudio
p72
(lp73
(Valsaaudiodevices.py
S'import time\nimport wave\nimport contextlib\n\n# to install alsaaudio, use mpre.audio.utilities.install_pyalsaaudio\nimport alsaaudio\n\nimport mpre.base as base\nimport mpre.audio.audiolibrary as audiolibrary\nimport mpre.audio.defaults as defaults\n\nclass Audio_Device(audiolibrary.Audio_Reactor):\n\n    possible_options = ("rate", "channels", "format", "sample_size", \n                        "period", "type", "card")\n                        \n    def _get_options(self):\n        return dict((attribute, getattr(self, attribute)) for attribute in\n                     self.possible_options if \n                     getattr(self, attribute, None) is not None)\n    options = property(_get_options)\n\n    def _get_full_buffer_size(self):\n        return self.channels * self.period_size * (self.sample_size / 8)\n    full_buffer_size = property(_get_full_buffer_size)\n\n    defaults = defaults.AlsaAudio_Device\n\n    def __init__(self, **kwargs):\n        super(Audio_Device, self).__init__(**kwargs)\n        self.alert("{} {} initializing",\n                  (self.name, self.card),\n                  level=\'v\')\n                  \n        self.pcm = alsaaudio.PCM(type=self.type, mode=self.mode, card=self.card)\n        self.pcm.setchannels(self.channels)\n        self.pcm.setrate(self.rate)\n        self.pcm.setformat(self.format)\n        self.pcm.setperiodsize(self.period_size)\n\n    def get_data(self):\n        raise NotImplementedError\n\n    def mute(self):\n        if self.is_muted:\n            self.data_source = \'\\x00\' * self.full_buffer_size\n            self.is_muted = True\n        else:\n            self.is_muted = False\n\n\nclass Audio_Input(Audio_Device):\n\n    defaults = defaults.AlsaAudio_Input\n\n    def __init__(self, **kwargs):\n        super(Audio_Input, self).__init__(**kwargs)\n        if not self.data_source:\n            self.data_source = self.pcm            \n        self.byte_scalar = self.sample_size / 8\n    \n    @contextlib.contextmanager\n    def listeners_preserved(self):\n        old_listeners = self.listeners\n        try:\n            yield\n        finally:\n            self.listeners = old_listeners \n            \n    def get_data(self):\n        frame_count, data = self.pcm.read()\n        self.handle_audio_output(data)\n        \n        if self.playing_files:\n            byte_count = frame_count * self.byte_scalar\n            for _file in self.playing_files:\n                file_data = _file.read(byte_count)\n                for listener in self.playing_to[_file]:\n                    self.parallel_method(listener, "handle_audio_input",\n                                         _file.name, file_data)\n                                                 \n    def play_file(self, _file, listeners=("Audio_Output", )):\n        self.playing_files.append(_file)\n        self.playing_to[_file] = listeners\n        for listener in listeners:\n            self.parallel_method(listener, "set_input_device", self.instance_name)\n\n    def stop_file(self, _file):\n        self.playing_files.remove(_file)\n        \n        for listener in self.playing_to[_file]:\n            self.parallel_method(listener, "handle_end_of_stream")        \n        del self.playing_to[_file]\n        \n        \nclass Audio_Output(Audio_Device):\n\n    defaults = defaults.AlsaAudio_Output\n\n    def __init__(self, **kwargs):\n        super(Audio_Output, self).__init__(**kwargs)\n\n    def handle_audio_input(self, sender, audio_data):\n        if self.listeners:\n            super(Audio_Output, self).handle_audio_input(sender, audio_data)\n        self.pcm.write(audio_data)\n                \n    """def _new_thread(self):\n        data_source = getattr(self, "data_source", self.pcm)\n        read_data = self.data_source.read\n        period_size = self.period_size\n        full_buffer_size = self.full_buffer_size\n        silence = "\\x00" * period_size\n        pcm_write = self.pcm.write\n\n        if self.input_from == self.data_source.read:\n            read_data = partial(self.data_source.read, full_buffer_size)\n        else:\n            read_data = lambda: \'\'.join(self.read_messages())\n        \n        data = \'\'\n        while True:\n            data += read_data()            \n            buffer_size = len(data)\n            if buffer_size >= full_buffer_size:\n                if self.mute:\n                    data = silence\n                pcm_write(data[:full_buffer_size])\n                data = data[full_buffer_size:]\n            yield\n\n    def get_data(self):\n        return next(self.thread)"""\n'
tp74
a(Vaudiolibrary.py
S'import pickle\nimport wave\nimport sys\nimport os\nimport contextlib\n\nimport mpre\nimport mpre.base as base\nimport mpre.vmlibrary as vmlibrary\nimport mpre.fileio as fileio\nimport mpre.audio.defaults as defaults\nfrom mpre.utilities import Latency\nInstruction = mpre.Instruction\n\n# supports both pyalsaaudio (linux) and pyaudio (cross platform)\n       \nclass Audio_Reactor(base.Reactor):\n    \n    defaults = defaults.Audio_Reactor\n    \n    def __init__(self, **kwargs):\n        self.listeners = []\n        super(Audio_Reactor, self).__init__(**kwargs)\n        if self.source_name:\n            self.parallel_method(self.source_name, "add_listener", \n                                 self.instance_name)\n            \n    def set_input_device(self, target_instance_name):\n        self_name = self.instance_name\n        if self.source_name:\n            self.parallel_method(self.source_name, "remove_listener", self_name)\n            self.source_name = target_instance_name\n        \n        self.parallel_method(target_instance_name, "add_listener", self_name)\n        \n    def handle_audio_input(self, sender, audio_data):\n        self.handle_audio_output(audio_data)\n        \n    def handle_audio_output(self, audio_data):\n        for client in self.listeners:\n            self.parallel_method(client, "handle_audio_input", \n                                 self.instance_name, audio_data)\n    \n    def handle_end_of_stream(self):\n        self.alert("end of stream", level=0)\n        raise NotImplementedError\n        \n    def add_listener(self, instance_name):\n        self.listeners.append(instance_name)\n            \n    def remove_listener(self, instance_name):\n        self.listeners.remove(instance_name)    \n            \n            \nclass Audio_File(fileio.File):\n\n    def handle_audio_input(self, sender, audio_data):\n        self.handle_write(None, audio_data)\n        \n\nclass Wav_File(Audio_Reactor):\n\n    defaults = defaults.Wav_File\n\n    def _get_audiosize(self):\n        return self.channels * self.sample_width * self.file.getnframes()\n    audio_size = property(_get_audiosize)\n    \n    def __init__(self, **kwargs):\n        super(Wav_File, self).__init__(**kwargs)\n        self.name = os.path.split(self.filename)[-1].split(\'.\', 1)[0]\n        \n        _file = self.file = wave.open(self.filename, self.mode)\n        if \'r\' in self.mode:\n            channels, sample_width, rate, number_of_frames, comptype, compname = self.file.getparams()\n                \n            self.channels = channels\n            self.sample_width = sample_width\n            self.format = 2 # hardcoded to PCM_FORMAT_S16_LE for quick fix\n            self.rate = rate\n            self.number_of_frames = number_of_frames\n            self.comptype = comptype\n            self.compname = compname\n        else:\n            _file.setparams((self.channels, self.sample_width, self.rate, 0, \'NONE\', \'not compressed\'))\n            \n        message = "opened wav file with channels: {0}, format: {1}, rate: {2}"\n        self.alert(message, (self.channels, self.sample_width, self.rate), level="vv")\n    \n    def handle_audio_input(self, sender, audio_data):\n        self.write(audio_data)\n        \n    def read(self, size=None): # accepts size in bytes and converts to frame count   \n        size = (size / 4) if size is not None else (self.audio_size / 4)\n        \n        data = self.file.readframes(size)\n        if self.repeat and (self.file.tell() == self.number_of_frames):\n            self.file.rewind()\n\n        return data\n\n    def tell(self):\n        return self.file.tell()\n    \n    def write(self, data):\n        self.file.writeframes(data)\n\n    def close(self):\n        self.file.close()\n\n\nclass Config_Utility(vmlibrary.Process):\n\n    defaults = defaults.Config_Utility\n\n    def __init__(self, **kwargs):\n        self.selected_devices = []\n        super(Config_Utility, self).__init__(**kwargs)\n\n        if "default" in self.mode:\n            self.selected_devices.append(self.default_input)\n            self.selected_devices.append(self.default_output)\n            self.write_config_file(self.selected_devices)\n            Instruction(self.instance_name, "delete").execute()\n        else:\n            self.run()\n            \n    def write_config_file(self, device_list):\n        with open(self.config_file_name, "wb") as config_file:\n            for device in device_list:\n                print device\n            pickle.dump(device_list, config_file)\n            config_file.flush()\n            config_file.close()\n\n    def print_display_devices(self, device_dict):\n        for key, value in device_dict.items():\n            print "%s: %s" % (key, value)\n\n    def get_selections(self):\n        selection = ""\n        self.selected_devices = []\n        devices = self.devices\n        \n        while "done" not in selection:\n            print "\\n"*80\n            print "type \'done\' to finish selecting..."\n            print "**************************************"\n            self.print_display_devices(devices)\n            print "currently using: ", [str(item) for item in self.selected_devices]\n            selection = raw_input("Enter index of input device to use: ")\n            try:\n                index = int(selection)\n            except ValueError:\n                if selection == "done":\n                    break\n                else:\n                    raw_input("Invalid index. Press enter to continue...")\n            else:\n                try:\n                    device = devices[index]\n                except KeyError:\n                    selection = raw_input("Invalid index. press enter to continue to or \'done\' to finish")\n                    if \'done\' in selection:\n                        break\n                else:\n                    name = raw_input("Rename device or press enter for default name: ")\n                    if name:\n                        device["name"] = name\n                                   \n                    self.selected_devices.append(device)\n        print "finished selecting devices"\n                                    \n    def run(self):\n        self.get_selections()\n        self.write_config_file(self.selected_devices)\n        \n        if getattr(self, "exit_when_finished", None):\n            exit()\n        else:\n            Instruction(self.instance_name, "delete").execute()\n\n            \nclass Audio_Manager(base.Reactor):\n\n    defaults = defaults.Audio_Manager\n\n    def _get_devices(self):\n        return self.objects.get("Audio_Input", []) + self.objects.get("Audio_Output", [])\n\n    audio_devices = property(_get_devices)\n\n    def __init__(self, **kwargs):\n        device_names = self.device_names = {}\n        super(Audio_Manager, self).__init__(**kwargs)\n        self.objects.setdefault("Audio_Input", [])\n        \n        self.load_api()\n        \n        if self.configure:\n            self.run_configuration()\n            \n        if self.use_defaults:\n            self.load_default_devices()\n            \n        if self.config_file_name:\n            try:\n                self.load_config_file()\n            except IOError:\n                response = raw_input("No audio config file found\\nlaunch Audio_Config_Utility?: (y/n) ").lower()\n                if \'y\' in response:\n                    self.run_configuration()\n\n        self.alert("Finished loading", level=\'v\')\n        \n    def run_configuration(self, exit_when_finished=False):\n        self.create(Config_Utility,\n                    default_input=self.default_input,\n                    default_output=self.default_output,\n                    devices=self.devices)\n        \n        if exit_when_finished:\n            Instruction("Metapython", "exit").execute()\n        \n    def load_api(self):\n        if "linux" in sys.platform:\n            import alsaaudiodevices as audio_devices\n            self.api = \'alsaaudio\'\n            \n            default_input, default_output = "hw:0,0", "hw:0,0"\n            devices = dict((index, {"card" : "hw:{0},0".format(index), \n                                    "name" : device_name}) for \n                                    index,  device_name in \n                                    enumerate(audio_devices.alsaaudio.cards()))    \n            self.default_input = devices[0]\n            self.default_output = devices[0]\n            self.devices = devices\n        else:\n            import portaudiodevices as audio_devices\n            self.api = \'portaudio\'\n            self.pyaudio = audio_devices.pyaudio\n            PORTAUDIO = self.portaudio = audio_devices.PORTAUDIO\n            \n            host_api_info = PORTAUDIO.get_default_host_api_info()\n            input_index = host_api_info["defaultInputDevice"]\n            output_index = host_api_info["defaultOutputDevice"]\n            \n            default_input = PORTAUDIO.get_device_info_by_index(input_index)\n            default_output = PORTAUDIO.get_device_info_by_index(output_index)\n            \n            default_input["input_device_index"] = input_index\n            default_input["rate"] = int(default_input["defaultSampleRate"])\n            default_input["channels"] = default_input["maxInputChannels"]\n\n            default_output["output_device_index"] = output_index\n            default_output["rate"] = int(default_input["defaultSampleRate"])\n            default_output["channels"] = default_input["maxInputChannels"]\n            \n            self.devices = devices = {}\n            for device_number in xrange(PORTAUDIO.get_device_count()):\n                device_info = PORTAUDIO.get_device_info_by_index(device_number)\n                options = {"channels" : max(device_info["maxOutputChannels"], device_info["maxInputChannels"]),\n                        "rate" : int(device_info["defaultSampleRate"]),\n                        "name" : device_info["name"]}\n                devices[device_number] = options        \n        \n            self.default_input = default_input\n            self.default_output = default_output\n            \n        self.Audio_Device = audio_devices.Audio_Device\n        self.Audio_Input = audio_devices.Audio_Input\n        self.Audio_Output = audio_devices.Audio_Output\n    \n    def load_default_devices(self):\n        input = self.create(self.Audio_Input, **self.default_input)\n        output = self.create(self.Audio_Output, **self.default_output)\n        \n        device_names = self.device_names\n        device_names[input.instance_name] = input\n        device_names["Microphone"] = input\n        \n        device_names[output.instance_name] = output\n        device_names["Speakers"] = output\n        \n    def load_config_file(self):\n        with open(self.config_file_name, "rb") as config_file:\n            for device_info in pickle.load(config_file):\n                device = self.create(self.Audio_Input, **device_info)\n                self.device_names[device.instance_name] = device\n                self.device_names[device.name] = device\n                         \n    def get_devices(self, devices="Audio_Input"):\n        return [(instance.name, instance.instance_name) for \n                instance in self.objects[devices]]\n                        \n    def record(self, device_name, file, channels=2, rate=48000):  \n        device_name = self.device_names[device_name].instance_name\n               \n        reactor_file = self.create(Audio_File, file=file).instance_name\n        recording = self.create(self.Audio_Output, \n                                source_name=device_name,\n                                name="{}_recording".format(device_name),\n                                listeners=[reactor_file], \n                                channels=channels,\n                                rate=rate)'
tp75
a(Vaudio_config_utility.py
S'import mpre.base\n\nlaunch_utility = mpre.Instruction("Metapython", "create",            \n                             "mpre.audio.audiolibrary.Config_Utility", exit_when_finished=True)\nif __name__ == "__main__":\n    launch_utility.execute()'
tp76
a(Vcapture_live_audio.py
S'import mpre.audio.utilities as utilities\nif __name__ == "__main__":\n    utilities.ensure_audio_enabled()\n    utilities.record_wav_file(parse_args=True)'
tp77
a(Vdefaults.py
S'import mpre.defaults as defaults\nBase = defaults.Base\nProcess = defaults.Process\nReactor = defaults.Reactor\n\n# audiolibrary\n\nAudio_Reactor = Reactor.copy()\nAudio_Reactor.update({"source_name" : \'\'})\n\nWav_File = Audio_Reactor.copy()\nWav_File.update({"mode" : "rb",\n"filename" : "",\n"repeat" : False,\n"channels" : 2,\n"rate" : 48000,\n"sample_width" : 2})\n\nAlsaAudio_Device = Audio_Reactor.copy()\nAlsaAudio_Device.update({"channels" : 1,\n"rate" : 48000,\n"format" : 2, # alsaaudio.PCM_FORMAT_S16_LE\n"sample_size" : 16,\n"period_size" : 1024,\n"card" : "hw:0,0",\n"data" : \'\',\n"data_source" : None,\n"frame_count" : 0,\n"mute" : False})\n\nAlsaAudio_Input = AlsaAudio_Device.copy()\nAlsaAudio_Input.update({"type" : 1, # PCM_CAPTURE\n"mode" : 1, # PCM_NONBLOCK\n"_data" : \'\'})\n\nAlsaAudio_Output = AlsaAudio_Device.copy()\nAlsaAudio_Output.update({"type" : 0, # PCM_PLAYBACK\n"mode" : 1}) # PCM_NONBLOCK\n\nPyAudio_Device = Reactor.copy()\nPyAudio_Device.update({"format" : 8,\n"frames_per_buffer" : 1024,\n"data" : "",\n"record_to_disk" : False,\n"frame_count" : 0,\n"memory_size" : 16384,\n"source_name" : \'\',\n"data_source" : \'\',\n"mute" : False,\n"silence" : b"\\x00" * 65535})\n\nAudio_Input = PyAudio_Device.copy()\nAudio_Input.update({"input" : True,\n"data" : \'\',\n"priority" : .015})\n\nAudio_Output = PyAudio_Device.copy()\nAudio_Output.update({"output" : True})\n\nConfig_Utility = Process.copy()\nConfig_Utility.update({"config_file_name" : "audiocfg",\n"mode" : ("input",),\n"auto_start" : False})\n\nAudio_Manager = Reactor.copy()\nAudio_Manager.update({"config_file_name" : \'\',\n"use_defaults" : True,\n"configure" : False})\n\nAudio_Channel = Reactor.copy()\nAudio_Channel.update({"audio_data" : \'\',\n"memory_size" : 65535})\n\nAudio_Service = Reactor.copy()\nAudio_Service.update({"memory_size" : 65535})\n\nVoip_Messenger = Process.copy()\nVoip_Messenger.update({"microphone_name" : "microphone",\n"port" : 40100,\n"name" : "voip_messenger",\n"channels" : 2,\n"rate" : 48000,\n"format" : 2,\n"message_header" : "message",\n"call_header" : "call",\n"hangup_header" : "hangup",\n"audio_header" : "audio"})'
tp78
a(Vplay_wav_file.py
S'import sys\n\nimport mpre\nimport mpre.base as base\nimport mpre.audio.audiolibrary as audiolibrary\nInstruction = mpre.Instruction\n\nconstructor = base.Base()\n\nif __name__ == "__main__":\n    wav_file = constructor.create(audiolibrary.Wav_File, parse_args=True, mode=\'rb\')\n    enable_audio = Instruction("Metapython", "create", audiolibrary.Audio_Manager)\n    play_file = Instruction("Audio_Input", "play_file", wav_file)\n    enable_audio.execute()\n    play_file.execute()'
tp79
a(Vportaudiodevices.py
S'# pyaudio requires: libportaudio0, libportaudio2, libportaudiocpp0, and portaudio19-dev on linux\n# linux installation instructions:\n# if installation was already attempted, do: sudo apt-get remove python-pyaudio\n# wget http://people.csail.mit.edu/hubert/pyaudio/packages/python-pyaudio_0.2.8-1_i386.deb\n# sudo dpkg -i python-pyaudio_0.2.8-1_i386.deb\nimport wave\nimport sys\nimport mmap\nfrom contextlib import contextmanager\nfrom ctypes import *\n\nimport pyaudio\n\nimport mpre\nimport mpre.base as base\nimport mpre.vmlibrary as vmlibrary\nimport mpre.audio.audiolibrary as audiolibrary\nfrom mpre.utilities import Latency\n\nimport mpre.audio.defaults as defaults\nInstruction = mpre.Instruction\n\n@contextmanager\ndef _alsa_errors_suppressed():\n    prototype = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)\n    def do_nothing(filename, line, function, error, format):\n        return\n    c_suppression_function = prototype(do_nothing)\n    try:\n        alsa = cdll.LoadLibrary("libasound.so")\n    except OSError:\n        alsa = cdll.LoadLibrary("libasound.so.2")\n    alsa.snd_lib_error_set_handler(c_suppression_function)\n    yield\n    alsa.snd_lib_error_set_handler(None)\n\ndef _initialize_portaudio():\n    print "initializing PortAudio..."\n    if "linux" in sys.platform:\n        print "Trying to suppress ALSA configuration errors..."\n        with _alsa_errors_suppressed():\n            portaudio = pyaudio.PyAudio()\n        print "**Please ignore any warnings you may have received**"\n    else:\n        portaudio = pyaudio.PyAudio()\n    print "...done"\n    return portaudio\n\nPORTAUDIO = _initialize_portaudio()\n\nPORTAUDIO.format_mapping = {1 : "paInt8",\n                            2 : "paInt16",\n                            3 : "paInt24",\n                            4 : "paInt32"}\n                            \ndef _formats_to_indices():\n    format_lookup = {}\n    for device_index in range(PORTAUDIO.get_device_count()):\n        device_info = PORTAUDIO.get_device_info_by_index(device_index)\n        rate = device_info["defaultSampleRate"]\n        \n        channels = device_info["maxInputChannels"]\n        if channels:\n            in_or_out = "input"\n        else:\n            channels = device_info["maxOutputChannels"]\n            in_or_out = "output"\n        \n        try:\n            format_lookup[(rate, channels, in_or_out)].append(device_info["index"])\n        except KeyError:\n            format_lookup[(rate, channels, in_or_out)] = [device_info["index"]]\n    return format_lookup\n    \nformat_lookup = _formats_to_indices()\n           \nclass Audio_Device(audiolibrary.Audio_Reactor):\n\n    defaults = defaults.PyAudio_Device\n    possible_options = ("rate", "channels", "format", "input", "output",    \n                        "input_device_index", "output_device_index", \n                        "frames_per_buffer", "start", "stream_callback",\n                        "input_host_api_specific_stream_info",\n                        "output_host_api_specific_stream_info")\n                        \n    def _get_options(self):\n        options = {}\n        for option in self.possible_options:\n            value = getattr(self, option, None)\n            if value:\n                options[option] = value\n        \n        return options\n    options = property(_get_options)\n\n    def _get_full_buffer_size(self):\n        return self.channels * self.frames_per_buffer * self.sample_size\n    full_buffer_size = property(_get_full_buffer_size)\n        \n    def _get_bitrate(self):\n        return self.rate * self.channels * self.sample_size\n    bitrate = property(_get_bitrate)\n        \n    def __init__(self, **kwargs):        \n        self.available = 0\n        self._format_error = "{}hz {} channel {} not supported by any api"\n        self.sample_size = PORTAUDIO.get_sample_size(pyaudio.paInt16)\n        super(Audio_Device, self).__init__(**kwargs)\n        \n        import mpre.utilities\n        self.latency = mpre.utilities.Latency("audio input")\n        \n    def open_stream(self):\n        return PORTAUDIO.open(**self.options)\n           \n    def get_data(self):\n        raise NotImplementedError\n\n            \nclass Audio_Input(Audio_Device):\n\n    defaults = defaults.Audio_Input\n    \n    def __init__(self, **kwargs):\n        self.playing_files = []\n        self.playing_to = {}\n        self.frame_count = 0\n        super(Audio_Input, self).__init__(**kwargs)\n        refresh = self.refresh_instruction = Instruction(self.instance_name, "refresh")\n        refresh.execute(self.priority)\n        \n        if not hasattr(self, "input_device_index"):\n            try:\n                self.input_device_index = format_lookup[(self.rate, self.channels, "input")][0]\n            except KeyError:\n                raise FormatError(self._format_error.format(self.rate, self.channels, "input"))\n       \n        stream = self.stream = self.open_stream()\n        \n    def play_file(self, _file, listeners=("Audio_Output", )):\n        self.playing_files.append(_file)\n        self.playing_to[_file] = listeners\n        for listener in listeners:\n            self.parallel_method(listener, "set_input_device", self.instance_name)\n\n    def stop_file(self, _file):\n        self.playing_files.remove(_file)\n        \n        for listener in self.playing_to[_file]:\n            self.parallel_method(listener, "handle_end_of_stream")        \n        del self.playing_to[_file]\n\n    def refresh(self):\n  #      self.latency.update()\n   #     self.latency.display()\n        \n        stream = self.stream        \n        frame_count = stream.get_read_available()\n        \n        byte_count = min(self.frames_per_buffer, \n                         frame_count * self.channels * self.sample_width)\n        if self.mute:\n            data = self.data = self.silence\n        else:\n            data = self.data        \n            data += stream.read(frame_count) \n            \n        assert len(data) >= byte_count\n        self.handle_audio_output(data[:byte_count])\n        self.data = data[byte_count:]      \n        \n        if self.playing_files:\n            for _file in self.playing_files:\n                file_data = _file.read(byte_count)\n                for listener in self.playing_to[_file]:\n                    self.parallel_method(listener, "handle_audio_input", \n                                        _file.name, file_data)                            \n            \n        self.refresh_instruction.execute(self.priority)\n        \n\nclass Audio_Output(Audio_Device):\n\n    defaults = defaults.Audio_Output\n\n    def __init__(self, **kwargs):\n        super(Audio_Output, self).__init__(**kwargs)\n        \n        if not hasattr(self, "output_device_index"):\n            try:\n                self.output_device_index = format_lookup[(self.rate, self.channels, "output")][0]\n            except KeyError:\n                raise FormatError(self._format_error.format(self.rate, self.channels, "output"))        \n        \n        self.stream = self.open_stream()\n        \n    def handle_audio_input(self, sender, audio_data):\n     #   self.latency.update()\n    #    self.latency.display()\n        self.data_source += audio_data\n        available = self.available = len(self.data_source)\n                   \n        number_of_frames = self.stream.get_write_available()\n\n        byte_count = min(number_of_frames * self.channels * self.sample_size,\n                         available)\n                         \n        output_data = self.data_source[:byte_count]\n                \n        self.handle_audio_output(output_data)\n        self.stream.write(output_data)\n        \n        if not self.mute:\n            self.data_source = self.data_source[byte_count:]               \n            self.available -= byte_count'
tp80
a(Vutilities.py
S'import os\n\nimport mpre.base\nimport mpre.audio.audiolibrary as audiolibrary\n\nInstruction = mpre.Instruction\n\ndef install_pyalsaaudio():\n    os.system("sudo apt-get install python-dev")\n    os.system("sudo apt-get install libasound2")\n    os.system("sudo apt-get install libasound2-dev")\n    os.system("sudo pip install pyalsaaudio")\n    \ndef ensure_audio_enabled(**kwargs):\n    components = mpre.environment.Component_Resolve\n    if "Audio_Manager" not in components:\n        components["Metapython"].create("mpre.audio.audiolibrary.Audio_Manager", **kwargs)\n                    \n      \ndef enable_audio(parent="Metapython"):\n    """Executes the following instruction:\n    \n        Instruction("Metapython", "create", \n                    "mpre.audio.audiolibrary.Audio_Manager").execute()\n    """                         \n    Instruction(parent, "create", "mpre.audio.audiolibrary.Audio_Manager").execute()\n    \ndef disable_audio(name="Audio_Manager"):\n    Instruction(name, "delete").execute()\n    \ndef wav_file_info(parse_args=True, **kwargs):\n    wav_file = audiolibrary.Wav_File(parse_args=parse_args, **kwargs)\n    \n    print "{} information: ".format(wav_file.filename)\n    for attribute in ("rate", "channels", "format", \n                      "sample_width", "number_of_frames"):\n        print "{}: {}".format(attribute, getattr(wav_file, attribute))\n\ndef record_wav_file(parse_args=True, **kwargs):\n    wav_file = audiolibrary.Wav_File(parse_args=parse_args, mode=\'wb\', **kwargs)\n    mpre.Instruction("Audio_Manager", "record", \n                          "Microphone", file=wav_file).execute()    '
tp81
a(Vwav_file_info.py
S'import mpre.audio.utilities as utilities\n\nif __name__ == "__main__":\n    utilities.wav_file_info(parse_args=True)'
tp82
assS'file_source'
p83
(dp84
sS'memory_mode'
p85
I-1
sS'package_name'
p86
Vmpre
p87
sS'make_docs'
p88
I01
sS'deleted'
p89
I00
sS'verbosity'
p90
Vvvv
p91
sS'update_flag'
p92
I00
sS'instance_name'
p93
S'Package'
p94
sS'store_source'
p95
I01
sS'objects'
p96
(dp97
S'Documentation'
p98
(lp99
g1
(cmpre.package
Documentation
p100
g3
NtRp101
(dp102
S'subfolders'
p103
(tsS'site_name'
p104
g87
sg85
I-1
sS'package'
p105
g4
sg89
I00
sg90
S'vv'
p106
sS'ignore_directories'
p107
(S'docs'
tp108
sg96
(dp109
sS'memory_size'
p110
I4096
sS'ignore_files'
p111
(tsg92
I00
sS'directory'
p112
VC:\u005cusers\u005c_\u005cpythonbs\u005cmpre
p113
sS'index_page'
p114
(lp115
S'index.md'
p116
aS'Homepage'
p117
asg93
g98
sS'instance_number'
p118
I0
sbassg110
I4096
sg103
(lp119
Vprograms
p120
aVaudio
p121
aVgui
p122
aVmisc
p123
asg112
VC:\u005cusers\u005c_\u005cpythonbs
p124
sg118
I0
sb.