import sys
import os
import types
import pickle
import importlib
import sys
import time
import inspect
import subprocess
import collections
import contextlib
import importlib
import types
import pickle
import hashlib

if "win" in sys.platform:
    timer_function = time.clock
else:
    timer_function = time.time

def load(attributes=None, _file=None):
    """ usage: see mpre.Base.load.__doc__"""
    if _file:
        assert not attributes
        attributes = _file.read()
    mac = attributes[:128]
    attributes = attributes[128:]
    if mac != hashlib.sha512(attributes).hexdigest():
        raise CorruptPickleError("Message authentication code mismatch\n\n" + 
                                 attributes)
        
    attributes = pickle.loads(attributes) 
    saved_objects = attributes["objects"]
    objects = attributes["objects"] = {}
    for instance_type, saved_instances in saved_objects.items():            
        objects[instance_type] = [load(pickle.loads(instance)) for instance in
                                  saved_instances]

    if "_required_modules" in attributes:
        _required_modules = []
        incomplete_modules = attributes["_required_modules"]
        module_sources = dict((module_name, source) for module_name, source, none in 
                              incomplete_modules)

        for module_name, source, none in incomplete_modules[:-1]:
            module = create_module(module_name, source)
            _required_modules.append((module_name, source, module))
        
        class_name = attributes.pop("_class")
        self_class = getattr(module, class_name)
        attributes["_required_modules"] = _required_modules        
    else:
        module_name, class_name = attributes["_required_module"]
        module = importlib.import_module(module_name)
        self_class = getattr(module, class_name)            
    self = self_class.__new__(self_class)
    
    attribute_modifier = attributes.pop("_attribute_type")
    for key, value in attributes.items():
        modifier = attribute_modifier.get(key, '')
        if modifier == "reference":
            attributes[key] = self.environment.Component_Resolve[value]
        elif modifier == "save":
            attributes[key] = load(pickle.loads(value))
            
    self.on_load(attributes)
    return self  
        
def convert(old_value, old_base, new_base):
    old_base_size = len(old_base)
    new_base_size = len(new_base)
    old_base_mapping = dict((symbol, index) for index, symbol in enumerate(old_base))
    decimal_value = 0    
    new_value = []
    
    for power, value_representation in enumerate(reversed(old_value)):
        decimal_value += old_base_mapping[value_representation]*(old_base_size**power)
                            
    if decimal_value == 0:
        new_value = [new_base[0]]
    else:
        while decimal_value > 0: # divmod = divide and modulo in one action
            decimal_value, digit = divmod(decimal_value, new_base_size)
            new_value.append(new_base[digit])

    return ''.join(str(item) for item in reversed(new_value))
        
@contextlib.contextmanager
def file_contents_swapped(contents, filepath='', _file=None):
    """ Enters a context where the data of the supplied file/filepath are the 
        contents specified in the contents argument."""
    if not _file:
        _file = open(filepath, 'r+b')
    original_contents = _file.read()
    _file.truncate(0)
    _file.seek(0)
    _file.write(contents)
    _file.flush()
    try:
        yield
    finally:
        _file.truncate(0)
        _file.seek(0)
        _file.write(original_contents)
        _file.flush()
        _file.close()
        
def resolve_string(string):
    """Given an attribute string of ...x.y.z, import ...x.y and return z"""
    module_name = string.split(".")   
    class_name = module_name.pop(-1)
    module_name = '.'.join(module_name)
    if not module_name:
        module_name = "__main__"
        
    _from = sys.modules[module_name] if module_name in sys.modules\
            else importlib.import_module(module_name)

    return getattr(_from, class_name)
        
def create_module(module_name, source, attach_source=False):
    """ Creates a module with the supplied name and source"""
    module_code = compile(source, module_name, 'exec')
    new_module = types.ModuleType(module_name)
    exec module_code in new_module.__dict__
    if attach_source:
        assert not hasattr(new_module, "_source")
        new_module._source = source
    return new_module
  
def get_module_source(module_name):
    """ Retrieves the source code of a module specified by name"""
    with modules_preserved([module_name]):
        reload_module(module_name)
        source = inspect.getsource(sys.modules[module_name])
    return source
    
def reload_module(module_name):
    """ Reloads the module specified by module_name"""
    reload(sys.modules[module_name])
     
@contextlib.contextmanager
def modules_preserved(modules=tuple()):
    """ Enter a context where the modules specified will be backed up + restored upon exit"""
    backup = {}
    for module_name in modules:
        backup[module_name] = sys.modules.get(module_name, None)
        if backup[module_name] is None:
            print "Attempted to preserve non existent module: ", module_name
    try:
        yield
    finally:
        for name, module in backup.items():
            if module is not None:
                sys.modules[name] = module
        
@contextlib.contextmanager
def modules_switched(module_dict):
    """ Enters a context where the modules in module_dict.keys are replaced by the source
        specified in module_dict[key]. The original modules will be restored upon exit."""
    modules = {}
    with modules_preserved(module_dict.keys()):
        for module_name, source_code in module_dict.items():
            try:
                module = sys.modules.pop(module_name)
            except KeyError:
                module = importlib.import_module(module_name)                
            filepath = (module.__file__ if module.__file__[-1] != 'c' else
                        module.__file__[:-1])
            with file_contents_swapped(source_code, filepath):
                modules[module_name] = importlib.import_module(module_name)
        try:
            yield
        except:
            raise
            pass    
    
def shell(command, shell=False):
    """ usage: shell('command string --with args', 
                     [shell=False]) = > sys.stdout.output from executed command
                    
        Launches a process on the physical machine via the operating 
        system shell. The shell and available commands are OS dependent.
        
        Regarding the shell argument; from the python docs on subprocess.Popen:
            "The shell argument (which defaults to False) specifies whether to use the shell as the program to execute. If shell is True, it is recommended to pass args as a string rather than as a sequence."
            
        and also:        
            "Executing shell commands that incorporate unsanitized input from an untrusted source makes a program vulnerable to shell injection, a serious security flaw which can result in arbitrary command execution. For this reason, the use of shell=True is strongly discouraged in cases where the command string is constructed from external input" """        
    process = subprocess.Popen(command.split(), shell=shell)
    return process.communicate()[0]
    
def function_header(function, mode="signature"):
    """usage: function_header(function, 
                             [mode]) => "(arg1, default_arg=True, keyword=True...)"
    
    Given a function, return it's signature. mode can be specified as insertable
    to use string format insertions instead of argument names"""
    spec = args, varargs, keyword_args, default_args = inspect.getargspec(function)   
    
    header_size = ", ".join("{}" for x in range(len(args)))                
    header_args = [arg for arg in args]
    
    if default_args: 
        new_args = []
        for arg in default_args:
            if isinstance(arg, str):
                new_arg = repr(arg)
            else:
                new_arg = arg
            new_args.append(new_arg)
        default_args = new_args
        non_defaults = len(args) - len(default_args)
        len(default_args)
        header_args = header_args[:non_defaults] + ["{}={}".format(arg_name, default_args[index]) for index, arg_name in enumerate(header_args[non_defaults:])]
        
    if varargs:
        header_size += ", *{}"
        header_args.append(varargs)    
    
    if keyword_args: 
        insert = "**{}" if mode == "signature" else "**{}"
        header_size += ", " + insert
        header_args.append(keyword_args)
             
    answer = inserts = "({})".format(header_size)
    
    if mode == "signature":
        answer = inserts.format(*header_args)
    
    return answer    
    
def documentation(instance):
    """ usage: documentation(object) => augmented_documentation_string
    
        Given a python object, attempt to introspect any useful information
        and include it appended to the objects docstring."""
        
    if isinstance(instance, type):
        _class = instance
    else:
        _class = instance.__class__
    
    options_text = 'Default values for newly created instances:\n\n'
    try: # gather the default attribute names and values (base objects only)
        options = ""
        for key, value in _class.defaults.items():
            if value is None:
                value = "None"
            options += "- {0: <25}: {1}\n".format(key, value)
        if not options:
            options_text = "\nNo defaults are assigned to new instances\n"
        else:
            options_text += options
    except AttributeError: # does not have defaults
        options_text = "\n\n"
        
    docstring = ""
    class_docstring = getattr(_class, "__doc", '')
    if not class_docstring:
        class_docstring = getattr(_class, "__doc__", '')
    docstring += "\t" + class_docstring.replace("    ", '').replace("\n", "\n\t") + "\n\n" + options_text + "\n"
    beginning = docstring    
        
    docstring = "This object defines the following non-private methods:\n"
    found = False
    for attribute_name in _class.__dict__.keys():
        if "_" != attribute_name[0]:
            attribute = getattr(_class, attribute_name)
            if callable(attribute):
                attribute = getattr(attribute, "function", attribute)
                found = True

                docstring += "\n\n- **" + attribute_name + "**"
                                
                function_docstring = inspect.getdoc(attribute)
                function_docstring = function_docstring if function_docstring else "No documentation available"

                try:
                    method_header = function_header(attribute)
                except:
                    print "Could not find header for", attribute
                    raise SystemExit
                docstring += method_header + ":\n\n\t\t  " + function_docstring.replace("\n", "\n\t\t ") + "\n"
                docstring += "\n"          
                
    if found:
        docstring = beginning + docstring
    else:
        docstring = beginning + "No non-private methods are defined\n"
    try:
        mro = str(_class.__mro__).replace("<", "").replace(">", '')
        
    except AttributeError:
        docstring += "\n No method resolution order detected...\n"
    else:
        docstring += "\nThis objects method resolution order is:\n\n"
        docstring += mro + "\n"
    return docstring
    
class Latency(object):
    """ usage: Latency([name="component_name"], 
                       [average_size=20]) => latency_object
                       
        Latency objects possess a latency attribute that marks
        the average time between calls to latency.update()"""
                
    def __init__(self, name=None, size=20):
        super(Latency, self).__init__()
        self.name = name
        self.latency = 0.0
        self.now = timer_function()
        self.max = 0.0
        self.average = Average(size=size)
        self._position = 0

    def update(self):
        """ usage: latency.update()
        
            notes the current time and adds it to the average time."""
        self._position += 1
        time_before = self.time_before = self.now
        now = self.now = timer_function()
        latency = now - time_before
        self.average.add(latency)
        if (self._position == 20 or latency > self.max):
            self.max = latency
            self._position = 0
        self.latency = latency

    def display(self, mode="sys.stdin"):
        """ usage: latency.display([mode='sys.stdin'])
        
            Writes latency information via either sys.stdin.write or print.
            Information includes the latency average, meta average, and max value""" 
        if "print" in mode.lower():
            print "%s Latency: %0.6f, Average: %0.6f, Max: %0.6f" % \
            (self.name, self.latency, self.average.average, self.max)
        else:
            sys.stdout.write("\b"*120)
            sys.stdout.write("%s Latency: %0.6f, Average: %0.6f, Max: %0.6f" % \
            (self.name, self.latency, self.average.average, self.max))


class Average(object):
    """ usage: Average([name=''], [size=20], 
                       [values=tuple()], [meta_average=False]) => average_object
                       
        Average objects keep a running average via the add method.
        The size option specifies the maximum number of samples. When
        this limit is reached, additional samples will result in the
        oldest sample being removed.
        
        values may be used to seed the average.
        
        The meta_average boolean flag is used to determine whether or not
        to keep an average of the average - This is implemented by an
        additional Average object."""
        
    def _get_meta_average(self):
        average = self._meta_average.average
        if not average:
            average = self.average
        return average
    meta_average = property(_get_meta_average)

    def _get_range(self):
        values = self.values
        return (min(values), self.average, max(values))
    range = property(_get_range)
        
    def __init__(self, name='', size=20, values=tuple(), meta_average=True):
        value = meta_average
        if meta_average:
            value = Average("{0} meta-average".format(name), 30, meta_average=False)
        self._meta_average = value

        self.name = name
        self.values = collections.deque(values, size)
        self.max_size = size
        self.size = float(len(self.values))
        if self.size:
            self.average = sum(self.values) / self.size
        else:
            self.average = 0
        self.add = self.partial_add

    def partial_add(self, value):
        self.size += 1
        self.values.append(value)
        self.average = sum(self.values) / self.size
        if self.size == self.max_size:
            self.add = self.full_add

    def full_add(self, value):
        old_value = self.values[0]
        adjustment = (value - old_value) / self.size
        self.values.append(value)
        self.average += adjustment
        if self._meta_average:
            self._meta_average.add(self.average)

                   
class LRU_Cache(object):
    """A dictionary with a max size that keeps track of
       key usage and handles key eviction. 
       
       currently completely untested"""
    def __init__(self, size=50, seed=None):
        if seed:
            assert len(seed.keys()) <= size
        else:
            seed = dict()
        seed = seed if seed else dict()
        keys = seed.keys()
        assert len(keys) <= size
        
        deque = self.deque = collections.deque(maxlen=size)
        deque.extend(keys)
        
        # testing for x in ... is significantly faster with a set
        self.contains = set(keys)
        self.size = size
        
        # change implementations once cache is full
        self.add = self._add
        
        # when no entry has been evicted (cache is not full or entry was
        # already in it), return a non hashable object so all keys 
        # (None, False, etc) will remain valid for users.
        self.no_eviction = []
        
    def _add(self, item):
        deque = self.deque
        
        if item in self.contains:
            deque.remove(item)
        else:
            self.contains.add(item)
            
        deque.append(item)
        if len(deque) > self.size:
            # change to a slightly different implementation that
            # doesn't do this check when the cache becomes full
            self.add = self._full_add
        
        return self.no_eviction
        
    def _full_add(self, item):
        deque = self.deque
        contains = self.contains
        
        if item in contains:
            deque.remove(item)
            evicted = self.no_eviction
        else:
            contains.add(item)
            evicted = deque[0]
        deque.append(item)
        return evicted
              
    def __getitem__(self, key):
        evicted = self.tracker.add(key)
        dict = self.dict
        if evicted is not self.no_eviction:
            del dict[evicted]
            self.contains.remove(evicted)
        return dict[key]
        
    def __setitem__(self, key, value):
        self.dict[key] = value
        self.contains.add(key)    


import sys
import mpre.utilities as utilities
        
class String_Importer(object):
    
    sources = {}
    
    @classmethod
    def add_module(cls, module_name, source):
        cls.sources[module_name] = source
    
    @classmethod
    def remove_module(cls, module_name):
        del cls.sources[module_name]
        
    def find_module(self, module_name, path):    
        if module_name in self.sources:
            return self
        return None
        
    def load_module(self, module_name):        
        if module_name in sys.modules:
            return sys.modules[module_name]        
        module = utilities.create_module(module_name, self.sources[module_name], 
                                         attach_source=True)
        sys.modules[module_name] = module
        return module    
        
        
class Encrypted_String_Importer(String_Importer):

    sources = {}
                   
    def load_module(self, module_name):
        if module_name in sys.modules:
            return sys.modules[module_name]
        main = sys.modules["__main__"]
        print "------------------Retrieving module from virtual encrypted file", module_name
        saved_file_stream = self.sources[module_name]        
        saved_file = load(saved_file_stream)        
        sys.modules[module_name] = module = create_module(module_name, saved_file.read())
        
        print "Returning loaded module", module_name
        return module
               


mpre_defaults_source = r'''f0585a8fec60920565ef4bbd86dd4807da7edc41a8e93f8ab5e0b8b12291f249592deb9f03da5f5787f7c0be955dc56c7ffa6b1f565d47e993d718ef8a2d20f7(dp1
S'key'
p2
S'\x00\x83\x08\x8b\x10\x93\x18\x9b \xa3(\xab0\xb38\xbb@\xc3H\xcbP\xd3X\xdb`\xe3h\xebp\xf3x\xfb\x80\x03\x88\x0b\x90\x13\x98\x1b\xa0#\xa8+\xb03\xb8;\xc0C\xc8K\xd0S\xd8[\xe0c\xe8k\xf0s\xf8{\x81\x06\x89\x0e\x91\x16\x99\x1e\xa1&\xa9.\xb16\xb9>\xc1F\xc9N\xd1V\xd9^\xe1f\xe9n\xf1v\xf9~\x01\x86\t\x8e\x11\x96\x19\x9e!\xa6)\xae1\xb69\xbeA\xc6I\xceQ\xd6Y\xdea\xe6i\xeeq\xf6y\xfe\x04\x87\x0c\x8f\x14\x97\x1c\x9f$\xa7,\xaf4\xb7<\xbfD\xc7L\xcfT\xd7\\\xdfd\xe7l\xeft\xf7|\xff\x84\x07\x8c\x0f\x94\x17\x9c\x1f\xa4\'\xac/\xb47\xbc?\xc4G\xccO\xd4W\xdc_\xe4g\xeco\xf4w\xfc\x7f\x02\x85\n\x8d\x12\x95\x1a\x9d"\xa5*\xad2\xb5:\xbdB\xc5J\xcdR\xd5Z\xddb\xe5j\xedr\xf5z\xfd\x82\x05\x8a\r\x92\x15\x9a\x1d\xa2%\xaa-\xb25\xba=\xc2E\xcaM\xd2U\xda]\xe2e\xeam\xf2u\xfa}'
p3
sS'memory_mode'
p4
I-1
sS'deleted'
p5
I00
sS'_required_modules'
p6
(lp7
(S'mpre.base'
p8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p9
Ntp10
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p11
Ntp12
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p13
Ntp14
a(S'mpre.fileio'
p15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p16
Ntp17
a(g15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p18
Ntp19
aS'Encrypted_File'
p20
asS'objects'
p21
(dp22
sS'memory_size'
p23
I4096
sS'_file_data'
p24
S'#   mpf.defaults - config file - contains attributes:values for new instances\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\nimport struct\nimport socket\nimport os\n\nNO_ARGS = tuple()\nNO_KWARGS = dict()\n\nif "__file__" not in globals():\n    FILEPATH = os.getcwd()\nelse:\n    FILEPATH = os.path.split(__file__)[0]\n\n# Base\nMANUALLY_REQUEST_MEMORY = 0\nDEFAULT_MEMORY_SIZE = 4096\n\n# anonymous memory passes -1  as the file descriptor to pythons mmap.mmap.\n# persistent memory opens the file instance.instance_name and opens an\n# mmap.mmap with that files file descriptor\nANONYMOUS = -1\nPERSISTENT = 0\nBase = {"memory_size" : DEFAULT_MEMORY_SIZE,\n"memory_mode" : ANONYMOUS,\n"verbosity" : \'\',\n"deleted" : False}\n\nReactor = Base.copy()\n\nProcess = Base.copy()\nProcess.update({"auto_start" : True,\n"priority" : .04})\n\n# vmlibrary\n\nProcessor = Process.copy()\nProcessor.update({"running" : True,\n"auto_start" : False})\n\nUser_Input = Process.copy()\n\n# network\n\nSocket = Base.copy()\nSocket.update({"blocking" : 0,\n"timeout" : 0,\n"add_on_init" : True,\n"network_packet_size" : 32768,\n"memory_size" : 0,\n"network_buffer" : \'\',\n"interface" : "0.0.0.0",\n"port" : 0,\n"connection_attempts" : 10,\n"bind_on_init" : False,\n"closed" : False,\n"_connecting" : False,\n"added_to_network" : False})\n\nTcp_Socket = Socket.copy()\nTcp_Socket.update({"socket_family" : socket.AF_INET,\n"socket_type" : socket.SOCK_STREAM})\n\nServer = Tcp_Socket.copy()\nServer.update({"port" : 80,\n"backlog" : 50,\n"name" : "",\n"reuse_port" : 0,\n"Tcp_Socket_type" : "network.Tcp_Socket",\n"share_methods" : ("on_connect", "client_socket_recv", "client_socket_send")})\n\nTcp_Client = Tcp_Socket.copy()\nTcp_Client.update({"ip" : "",\n"port" : 80,\n"target" : tuple(),\n"as_port" : 0,\n"timeout_notify" : True,\n"auto_connect" : True,\n"bad_target_verbosity" : 0}) # alert verbosity when trying to connect to bad address\ndel Tcp_Client["interface"]\n\nUdp_Socket = Socket.copy()\nUdp_Socket.update({"bind_on_init" : True})\ndel Udp_Socket["connection_attempts"]\n\n# only addresses in the range of 224.0.0.0 to 230.255.255.255 are valid for IP multicast\nMulticast_Beacon = Udp_Socket.copy()\nMulticast_Beacon.update({"packet_ttl" : struct.pack("b", 127),\n"multicast_group" : "224.0.0.0",\n"multicast_port" : 1929})\n\nMulticast_Receiver = Udp_Socket.copy()\nMulticast_Receiver.update({"address" : "224.0.0.0"})\n\nConnection_Manager = Process.copy()\nConnection_Manager.update({"auto_start" : False})\n\nNetwork = Process.copy()\nNetwork.update({"handle_resends" : False,\n"number_of_sockets" : 0,\n"priority" : .01,\n"update_priority" : 5,\n"_updating" : False,\n"auto_start" : False})\n\n# network2\nNetwork_Service = Udp_Socket.copy()\n\nAuthenticated_Service = Base.copy()\nAuthenticated_Service.update({"database_filename" : ":memory:",\n"login_message" : \'login success\',\n"hash_rounds" : 100000})\n\nAuthenticated_Client = Base.copy()\nAuthenticated_Client.update({"email" : \'\',\n"username" : "",\n"password" : \'\',\n"target" : "Authenticated_Service"})\n\nFile_Service = Base.copy()\nFile_Service.update({"network_packet_size" : 16384,\n"mmap_threshold" : 16384,\n"timeout_after" : 15})\n\nDownload = Base.copy()\nDownload.update({"filesize" : 0,\n"filename" :\'\',\n"filename_prefix" : "Download",\n"download_in_progress" : False,\n"network_packet_size" : 16384,\n"timeout_after" : 15})\n\n # Metapython\nJYTHON = "java -jar jython.jar"\nPYPY = "pypy"\nCPYTHON = "python"\nDEFAULT_IMPLEMENTATION = CPYTHON\n\nShell = Authenticated_Client.copy()\nShell.update({"email" : \'\',\n"username" : "root",\n"password" : "password",\n"prompt" : ">>> ",\n"startup_definitions" : \'\',\n"target" : "Interpreter_Service"})\n\nInterpreter_Service = Authenticated_Service.copy()\nInterpreter_Service.update({"copyright" : \'Type "help", "copyright", "credits" or "license" for more information.\'})\n\nAlert_Handler = Reactor.copy()\nAlert_Handler.update({"log_level" : 0,\n                      "print_level" : 0,\n                      "log_name" : "Alerts.log"})\n                      \nMetapython = Reactor.copy()\nMetapython.update({"command" : os.path.join(FILEPATH, "shell_launcher.py"),\n"implementation" : DEFAULT_IMPLEMENTATION,\n"environment_setup" : ["PYSDL2_DLL_PATH = C:\\\\Python27\\\\DLLs"],\n"interface" : "0.0.0.0",\n"port" : 40022,\n"prompt" : ">>> ",\n"_suspended_file_name" : "suspended_interpreter.bin",\n"copyright" : \'Type "help", "copyright", "credits" or "license" for more information.\',\n"priority" : .04,\n"interpreter_enabled" : True,\n"startup_definitions" : \\\n"""Instruction(\'Metapython\', \'create\', \'userinput.User_Input\').execute()\nInstruction("Metapython", "create", "network.Network").execute()"""})\n#"help" : "Execute a python script or launch a live metapython session"})\n'
p25
sS'_attribute_type'
p26
(dp27
sS'instance_number'
p28
I0
sS'_respond_with'
p29
(lp30
sS'_added'
p31
I01
sS'verbosity'
p32
S''
sS'persistent'
p33
I01
sS'filename'
p34
S'mpre.defaults'
p35
sS'instance_name'
p36
g20
sS'file_system'
p37
S'virtual'
p38
sS'mode'
p39
S''
s.'''

Encrypted_String_Importer.add_module('mpre.defaults', mpre_defaults_source)

mpre_metaclass_source = r'''223aef24951e24d587460ef5a616b708640ce312be5975f3b3d3244ca3a4534c074d4fb243d6f0b6f692b1d95f2d7c737ee5daba8aedfe390eb723b071ecc844(dp1
S'key'
p2
S'\x00\x83\x08\x8b\x10\x93\x18\x9b \xa3(\xab0\xb38\xbb@\xc3H\xcbP\xd3X\xdb`\xe3h\xebp\xf3x\xfb\x80\x03\x88\x0b\x90\x13\x98\x1b\xa0#\xa8+\xb03\xb8;\xc0C\xc8K\xd0S\xd8[\xe0c\xe8k\xf0s\xf8{\x81\x06\x89\x0e\x91\x16\x99\x1e\xa1&\xa9.\xb16\xb9>\xc1F\xc9N\xd1V\xd9^\xe1f\xe9n\xf1v\xf9~\x01\x86\t\x8e\x11\x96\x19\x9e!\xa6)\xae1\xb69\xbeA\xc6I\xceQ\xd6Y\xdea\xe6i\xeeq\xf6y\xfe\x04\x87\x0c\x8f\x14\x97\x1c\x9f$\xa7,\xaf4\xb7<\xbfD\xc7L\xcfT\xd7\\\xdfd\xe7l\xeft\xf7|\xff\x84\x07\x8c\x0f\x94\x17\x9c\x1f\xa4\'\xac/\xb47\xbc?\xc4G\xccO\xd4W\xdc_\xe4g\xeco\xf4w\xfc\x7f\x02\x85\n\x8d\x12\x95\x1a\x9d"\xa5*\xad2\xb5:\xbdB\xc5J\xcdR\xd5Z\xddb\xe5j\xedr\xf5z\xfd\x82\x05\x8a\r\x92\x15\x9a\x1d\xa2%\xaa-\xb25\xba=\xc2E\xcaM\xd2U\xda]\xe2e\xeam\xf2u\xfa}'
p3
sS'memory_mode'
p4
I-1
sS'deleted'
p5
I00
sS'_required_modules'
p6
(lp7
(S'mpre.base'
p8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p9
Ntp10
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p11
Ntp12
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p13
Ntp14
a(S'mpre.fileio'
p15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p16
Ntp17
a(g15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p18
Ntp19
aS'Encrypted_File'
p20
asS'objects'
p21
(dp22
sS'memory_size'
p23
I4096
sS'_file_data'
p24
S'import sys\nimport argparse\nimport types\nimport functools\nimport ast\nimport inspect\nimport utilities\nfrom copy import copy\n\nclass Docstring(object):\n    """ A descriptor object used by the Documented metaclass. Augments\n        instance docstrings with introspected information"""\n    def __init__(self):\n        super(Docstring, self).__init__()\n\n    def __get__(self, instance, _class):\n        _object = instance if instance else _class\n        return utilities.documentation(_object)\n        \n        \nclass Documented(type):\n    """ A metaclass that uses the Docstring object to supply\n        abundant documentation for classes"""\n    def __new__(cls, name, bases, attributes):\n        cls.make_docstring(attributes)\n        return super(Documented, cls).__new__(cls, name, bases, attributes)\n        \n    @staticmethod\n    def make_docstring(attributes):\n        attributes["__doc"] = attributes.get("__doc__", "No docstring found")\n        attributes["__doc__"] = Docstring()\n        \n\nclass Method_Hook(type):\n    """ Provides a hook on all methods for the new class. This metaclass\n        uses this hook to wrap each method in a Runtime_Decorator."""\n        \n    def __new__(cls, name, bases, attributes):        \n        new_class = super(Method_Hook, cls).__new__(cls, name, bases, attributes)\n        Method_Hook.decorate(new_class)\n        return new_class\n        \n    @staticmethod\n    def decorate(new_class):\n        for key, value in new_class.__dict__.items():\n            if key[0] != "_" and callable(value):\n                bound_method = types.MethodType(Runtime_Decorator(value), \n                                                None, \n                                                new_class)\n                setattr(new_class, key, bound_method)\n        return new_class        \n        \n        \nclass Runtime_Decorator(object):\n    """ Provides the ability to call a method with a decorator, decorators,\n        or monkey patch specified via keyword argument. This decorator\n        inherits from object and utilizes the Documented metaclass.\n\n        usage: wrapped_method(my_argument, decorator="decorators.Tracer")"""\n    __metaclass__ = Documented\n    \n    def __init__(self, function):\n        self.function = function\n        functools.update_wrapper(self, function)\n        self.handler_map = {"monkey_patch" : self._handle_monkey_patch,\n                            "decorator" : self._handle_decorator,\n                            "decorators" : self._handle_decorators}\n            \n    def __call__(self, *args, **kwargs):\n        check_for = kwargs.pop\n        modifiers = ("monkey_patch", "decorator", "decorators")\n        \n        for modifier in modifiers:\n            found = check_for(modifier, None)\n            if found:\n                call = self.handler_map[modifier](found)\n                break\n        else:\n            call = self.function\n        return call(*args, **kwargs)  \n            \n    """def _handle_context_manager(self, context_manager):\n        raise NotImplementedError\n        if isinstance(context_manager, str):\n            context_manager = utilities.resolve_string(context_manager)\n        return context_manager   \n\n        with context_manager():\n            result = self.function(*args, **kwargs)\n        return result"""\n\n    def _handle_monkey_patch(self, monkey_patch):\n        if isinstance(monkey_patch, str):\n            monkey_patch = utilities.resolve_string(monkey_patch)\n        try:\n            monkey_patch = functools.partial(monkey_patch, self.function.im_self)\n        finally: # function has no attribute im_self (not a method)\n            return monkey_patch\n\n    def _handle_decorator(self, decorator_type):\n        if isinstance(decorator_type, unicode) or isinstance(decorator_type, str):\n            decorator_type = utilities.resolve_string(decorator_type)\n        return decorator_type(self.function)\n\n    def _handle_decorators(self, decorator_info):\n        decorators = []\n        for decorator in decorator_info:\n            if isinstance(decorator, str):\n                decorator = utilities.resolve_string(decorator)\n\n            decorators.append(decorator)\n\n        wrapped_function = self.function\n        for item in reversed(decorators):\n            wrapped_function = item(wrapped_function)\n        return wrapped_function\n\n\nclass Parser_Metaclass(type):\n    """ Provides a command line parser for a class based upon \n        the class.defaults dictionary"""\n\n    parser = argparse.ArgumentParser()\n    command_parser = parser.add_subparsers(help="filename")\n    run_parser = command_parser.add_parser("run", help="execute the specified script")\n    profile_parser = command_parser.add_parser("profile", help="profile the specified script")\n    \n    def __new__(cls, name, bases, attributes):\n        new_class = super(Parser_Metaclass, cls).__new__(cls, name, bases, attributes)\n        exit_on_help = attributes.get("exit_on_help", True)\n\n        base_class = bases[0]\n        modifiers = getattr(base_class, "parser_modifiers", {}).copy()\n\n        parser_ignore = set()\n        new_parser_ignore = attributes.get("parser_ignore", tuple())\n        old_parser_ignore = getattr(base_class, "parser_ignore", tuple())\n        for ignore in new_parser_ignore + old_parser_ignore:\n            parser_ignore.add(ignore)\n        new_class.parser_ignore = tuple(parser_ignore)\n        for attribute in parser_ignore:\n            modifiers[attribute] = "ignore"\n\n        new_modifiers = attributes.get("parser_modifiers", {})\n        modifiers.update(new_modifiers)\n        \n        new_class = Parser_Metaclass.make_parser(new_class, name, \n                                                 modifiers, exit_on_help)\n        return new_class\n        \n    @staticmethod\n    def make_parser(new_class, name, modifiers, exit_on_help):\n        parser = Parser_Metaclass.command_parser.add_parser(name)\n        new_class.parser = Parser(parser, modifiers, exit_on_help, name)\n        return new_class\n    \nclass Parser(object):\n    """ Faciltates automatically generated command line parsers. Parser\n        instances are class attributes assigned by the Parser_Metaclass"""\n    sys_argv_backup = copy(sys.argv)\n    __metaclass__ = Documented\n    \n    def __init__(self, parser, modifiers, exit_on_help, name):\n        super(Parser, self).__init__()\n        self.parser = parser\n        self.modifiers = modifiers\n        self.exit_on_help = exit_on_help\n        self.name = name\n\n    def get_arguments(self, argument_info):\n        arguments = {}\n        argument_names = argument_info.keys()\n        switch = {"short" : "-",\n                  "long" : "--",\n                  "positional" : ""}\n\n        default_modifiers = {"types" : ("long", )}\n        self_modifiers = self.modifiers\n        for name in argument_names:\n            modifiers = self_modifiers.get(name, default_modifiers)\n            if modifiers == "ignore":\n                continue\n            info = {}\n            for keyword_argument, value in modifiers.items():\n                info[keyword_argument] = value\n\n            temporary = {}\n            for arg_type in info.pop("types"):\n                if arg_type != "positional":\n                    temporary["dest"] = name\n\n                default_value = argument_info[name]\n                temporary["default"] = default_value\n                value_type = type(default_value)\n                if value_type == bool:\n                    value_type = ast.literal_eval\n                temporary["type"] = value_type\n\n                for key, value in temporary.items():\n                    info.setdefault(key, value)\n\n                arg_name = switch[arg_type] + name\n                arguments[arg_name] = info\n\n        parser = self.parser\n        exit_on_help = self.exit_on_help\n\n        for argument_name, options in arguments.items():\n            parser.add_argument(argument_name, **options)\n\n        new_argv = copy(Parser.sys_argv_backup)\n        sys.argv = new_argv\n\n        try:\n            arguments, unused = parser.parse_known_args()\n        except SystemExit:\n            if exit_on_help:\n                raise\n            try:\n                new_argv.pop(new_argv.index("-h"))\n            except ValueError:\n                new_argv.pop(new_argv.index("--help"))\n            arguments, unused = parser.parse_known_args()\n\n        if unused:\n          #  new_argv = copy(Parser.sys_argv_backup)\n            for unused_name in unused:\n                index = new_argv.index(unused_name)\n                new_argv.pop(index)\n\n                if "-" in unused_name: # pop whatever the value for the positional arg was too\n                    try:\n                        word = new_argv.pop(index)\n                    except IndexError: # no argument supplied to positional arg\n                        pass\n                    else:\n                        try:\n                            unused.remove(word)\n                        except ValueError:\n                            pass\n\n            arguments, unused = parser.parse_known_args()\n            sys.argv = copy(Parser.sys_argv_backup)\n        return arguments\n\n    def get_options(self, argument_info):\n        namespace = self.get_arguments(argument_info)\n        options = dict((key, getattr(namespace, key)) for key in namespace.__dict__.keys())\n        return options\n\n       \nclass Instance_Tracker(type):\n    """ Provides instance tracking and counting attributes.\n    \n        Note as of 3/3/2015: the class must implement these attributes,\n        it is not performed by this metaclass"""\n        \n    def __new__(cls, name, bases, attributes):\n        if "instance_tracker" not in attributes:\n            attributes["instance_tracker"] = {}\n        if "instance_count" not in attributes:\n            attributes["instance_count"] = 0\n\n        return super(Instance_Tracker, cls).__new__(cls, name, bases, attributes)\n\n       \nclass Metaclass(Documented, Instance_Tracker, Parser_Metaclass, Method_Hook):\n    """ A metaclass that applies other metaclasses. Each metaclass\n        in the list Metaclass.metaclasses will be chained into a \n        new single inheritance metaclass that utilizes each entry. \n        The methods insert_metaclass and remove_metaclass may be used\n        to alter the contents of this list.\n        \n        Implementation currently under examination due to compiling with\n        cython being broken"""\n        \n    #metaclasses = [Documented, Instance_Tracker, Parser_Metaclass, Method_Hook]\n   # _metaclass = type("Metaclass",\n     #                 tuple(metaclasses),\n      #                {})\n                      \n    def __new__(cls, name, bases, attributes):\n        # create a new metaclass that uses Metaclass.metaclasses as it\'s bases.\n        #new_metaclass = cls._metaclass\n       # print "\\nCreating new class: ", name, bases\n        new_class = super(Metaclass, cls).__new__(cls, name, bases, attributes)\n       # print "New class bases: ", new_class.__bases__\n        #print "new class mro: ", new_class.__mro__\n        return new_class\n    \n    @classmethod\n    def update_metaclass(cls):\n        cls._metaclass = type(cls.__name__,\n                              tuple(cls.metaclasses),\n                              {})\n               \n    @classmethod\n    def insert_metaclass(cls, metaclass, index=-1):\n        cls.metaclasses.insert(index, metaclass)\n        cls.update_metaclass()\n        \n    @classmethod\n    def remove_metaclass(cls, metaclass):\n        cls.metaclasses.remove(metaclass)\n        cls.update_metaclass()\n        \n        \nif __name__ == "__main__":\n    import unittest\n    import mpre.base as base\n    import mpre.defaults      \n    \n    class Test_Metaclass(unittest.TestCase):\n        \n        def testdocumentation(self):\n            print base.Base.__doc__[:256] + "..."\n            print "End documentation test"\n            \n        def testdecoration(self):\n            test_base = base.Base()\n            \n            def test_decorator1(function):\n                def wrapped_function(*args, **kwargs):\n                    print "inside local decorator1"\n                    return function(*args, **kwargs)\n                return wrapped_function\n               \n            def test_decorator2(function):\n                def wrapped_function(*args, **kwargs):\n                    print "inside local decorator2"\n                    return function(*args, **kwargs)\n                return wrapped_function\n                \n            sock = test_base.create("socket.socket", decorator=test_decorator1)\n            \n            other_base = test_base.create("mpre.base.Base", decorators=(test_decorator1, test_decorator2))\n            \n            def monkey_patch(*args, **kwargs):\n                print "inside monkey patch"\n                \n            another_sock = test_base.create("socket.socket", \n                                            monkey_patch=monkey_patch)\n            self.failIf(another_sock) # monkey_patch returns False\n            \n        def testparser(self):\n            import sys\n\n            \n            backup = sys.argv\n            arguments = ("--test_string", "test_value", "--test_int", \'8\',\n                         "--test_bool", "False", "--test_float", 3.14)\n            sys.argv = list(arguments)\n            print len(sys.argv)\n\n            class TestBase(base.Base):\n                defaults = mpre.defaults.Base.copy()\n                \n                arg_index = 1\n                for item in arguments[::2]:\n                    defaults[item] = arguments[arg_index]\n                    arg_index += 2\n                    \n            test_base = TestBase(parse_args=True, testattr=1, \n                                 test_string="ishouldn\'tbehere")\n            \n            print "Ensuring parser attribute assignment works"\n            \n            print "Testing keyword arg assignment..."\n            self.failUnless(test_base.testattr == 1)\n            \n            \n            # as above, iteratively for the pairs in sys.argv\n            arg_index = 1\n            for index, item in enumerate(arguments[::2]):\n                value = arguments[arg_index]\n                arg_index += 2\n                print "Testing {}: {} == {}".format(item, getattr(test_base, item), value)\n                self.failUnless(getattr(test_base, item) == value)            \n            \n            sys.argv = backup\n    unittest.main()\n'
p25
sS'_attribute_type'
p26
(dp27
sS'instance_number'
p28
I2
sS'_respond_with'
p29
(lp30
sS'_added'
p31
I01
sS'verbosity'
p32
S''
sS'persistent'
p33
I01
sS'filename'
p34
S'mpre.metaclass'
p35
sS'instance_name'
p36
S'Encrypted_File2'
p37
sS'file_system'
p38
S'virtual'
p39
sS'mode'
p40
S''
s.'''

Encrypted_String_Importer.add_module('mpre.metaclass', mpre_metaclass_source)

mpre_base_source = r'''bb8a49b785ea8d37603d75c6db2164ee880e0ac3b7974b16a2b48e6ad3a4772de57322654ce72b6a94c9c74873c47da78957e8ffd2e7aafc20cf2df9c68b2a26(dp1
S'key'
p2
S'\x00\x83\x08\x8b\x10\x93\x18\x9b \xa3(\xab0\xb38\xbb@\xc3H\xcbP\xd3X\xdb`\xe3h\xebp\xf3x\xfb\x80\x03\x88\x0b\x90\x13\x98\x1b\xa0#\xa8+\xb03\xb8;\xc0C\xc8K\xd0S\xd8[\xe0c\xe8k\xf0s\xf8{\x81\x06\x89\x0e\x91\x16\x99\x1e\xa1&\xa9.\xb16\xb9>\xc1F\xc9N\xd1V\xd9^\xe1f\xe9n\xf1v\xf9~\x01\x86\t\x8e\x11\x96\x19\x9e!\xa6)\xae1\xb69\xbeA\xc6I\xceQ\xd6Y\xdea\xe6i\xeeq\xf6y\xfe\x04\x87\x0c\x8f\x14\x97\x1c\x9f$\xa7,\xaf4\xb7<\xbfD\xc7L\xcfT\xd7\\\xdfd\xe7l\xeft\xf7|\xff\x84\x07\x8c\x0f\x94\x17\x9c\x1f\xa4\'\xac/\xb47\xbc?\xc4G\xccO\xd4W\xdc_\xe4g\xeco\xf4w\xfc\x7f\x02\x85\n\x8d\x12\x95\x1a\x9d"\xa5*\xad2\xb5:\xbdB\xc5J\xcdR\xd5Z\xddb\xe5j\xedr\xf5z\xfd\x82\x05\x8a\r\x92\x15\x9a\x1d\xa2%\xaa-\xb25\xba=\xc2E\xcaM\xd2U\xda]\xe2e\xeam\xf2u\xfa}'
p3
sS'memory_mode'
p4
I-1
sS'deleted'
p5
I00
sS'_required_modules'
p6
(lp7
(S'mpre.base'
p8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p9
Ntp10
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p11
Ntp12
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p13
Ntp14
a(S'mpre.fileio'
p15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p16
Ntp17
a(g15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p18
Ntp19
aS'Encrypted_File'
p20
asS'objects'
p21
(dp22
sS'memory_size'
p23
I4096
sS'_file_data'
p24
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p25
sS'_attribute_type'
p26
(dp27
sS'instance_number'
p28
I4
sS'_respond_with'
p29
(lp30
sS'_added'
p31
I01
sS'verbosity'
p32
S''
sS'persistent'
p33
I01
sS'filename'
p34
S'mpre.base'
p35
sS'instance_name'
p36
S'Encrypted_File4'
p37
sS'file_system'
p38
S'virtual'
p39
sS'mode'
p40
S''
s.'''

Encrypted_String_Importer.add_module('mpre.base', mpre_base_source)

mpre_network_source = r'''94da2c8fac073d99901a0a17cc3bae2a78b8359102953a463afbdb5d93da7c9f9ab2ef1ff2a112049ee1e3ca54b33ad329bef3d410096916e871f2b6e5c9ea44(dp1
S'key'
p2
S'\x00\x83\x08\x8b\x10\x93\x18\x9b \xa3(\xab0\xb38\xbb@\xc3H\xcbP\xd3X\xdb`\xe3h\xebp\xf3x\xfb\x80\x03\x88\x0b\x90\x13\x98\x1b\xa0#\xa8+\xb03\xb8;\xc0C\xc8K\xd0S\xd8[\xe0c\xe8k\xf0s\xf8{\x81\x06\x89\x0e\x91\x16\x99\x1e\xa1&\xa9.\xb16\xb9>\xc1F\xc9N\xd1V\xd9^\xe1f\xe9n\xf1v\xf9~\x01\x86\t\x8e\x11\x96\x19\x9e!\xa6)\xae1\xb69\xbeA\xc6I\xceQ\xd6Y\xdea\xe6i\xeeq\xf6y\xfe\x04\x87\x0c\x8f\x14\x97\x1c\x9f$\xa7,\xaf4\xb7<\xbfD\xc7L\xcfT\xd7\\\xdfd\xe7l\xeft\xf7|\xff\x84\x07\x8c\x0f\x94\x17\x9c\x1f\xa4\'\xac/\xb47\xbc?\xc4G\xccO\xd4W\xdc_\xe4g\xeco\xf4w\xfc\x7f\x02\x85\n\x8d\x12\x95\x1a\x9d"\xa5*\xad2\xb5:\xbdB\xc5J\xcdR\xd5Z\xddb\xe5j\xedr\xf5z\xfd\x82\x05\x8a\r\x92\x15\x9a\x1d\xa2%\xaa-\xb25\xba=\xc2E\xcaM\xd2U\xda]\xe2e\xeam\xf2u\xfa}'
p3
sS'memory_mode'
p4
I-1
sS'deleted'
p5
I00
sS'_required_modules'
p6
(lp7
(S'mpre.base'
p8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p9
Ntp10
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p11
Ntp12
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p13
Ntp14
a(S'mpre.fileio'
p15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p16
Ntp17
a(g15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p18
Ntp19
aS'Encrypted_File'
p20
asS'objects'
p21
(dp22
sS'memory_size'
p23
I4096
sS'_file_data'
p24
S'#   mpf.network_library - Asynchronous socket operations\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\nimport socket\nimport select\nimport struct\nimport errno\nimport traceback\n\nimport mpre\nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nfrom utilities import Latency, Average\nInstruction = mpre.Instruction\n\nNotWritableError = type("NotWritableError", (IOError, ), {"errno" : -1})\nERROR_CODES = {-1 : "NotWritableError"}\ntry:\n    CALL_WOULD_BLOCK = errno.WSAEWOULDBLOCK\n    BAD_TARGET = errno.WSAEINVAL\n    CONNECTION_IN_PROGRESS = errno.WSAEWOULDBLOCK\n    CONNECTION_IS_CONNECTED = errno.WSAEISCONN\n    CONNECTION_WAS_ABORTED = errno.WSAECONNABORTED\n    CONNECTION_RESET = errno.WSAECONNRESET    \n    ERROR_CODES[BAD_TARGET] = "BAD_TARGET"    \nexcept:\n    CALL_WOULD_BLOCK = errno.EWOULDBLOCK\n    CONNECTION_IN_PROGRESS = errno.EINPROGRESS\n    CONNECTION_IS_CONNECTED = errno.EISCONN\n    CONNECTION_WAS_ABORTED = errno.ECONNABORTED\n    CONNECTION_RESET = errno.ECONNRESET\n \nERROR_CODES.update({CALL_WOULD_BLOCK : "CALL_WOULD_BLOCK",\n                    CONNECTION_IN_PROGRESS : "CONNECTION_IN_PROGRESS",\n                    CONNECTION_IS_CONNECTED : "CONNECTION_IS_CONNECTED",\n                    CONNECTION_WAS_ABORTED : "CONNECTION_WAS_ABORTED",\n                    CONNECTION_RESET  : "CONNECTION_RESET"})\n               \nHOST = socket.gethostbyname(socket.gethostname())\n\nclass Error_Handler(object):\n            \n    def connection_reset(self, sock, error):\n        sock.alert("Connection reset\\n{}", [error], level=0)\n        sock.delete()\n        \n    def connection_was_aborted(self, sock, error):\n        sock.alert("Connection was aborted\\n{}", [error], level=0)\n        sock.delete()\n        \n    def eagain(self, sock, error):\n        sock.alert("{}", [error], level=0)\n    \n    def bad_target(self, sock, error):\n        sock.alert("Invalid target {}; {} {}", \n                   [getattr(sock, "target", \'\'), errno.errorcode[error.errno], error], \n                   level=0)\n        sock.delete()\n        \n    def unhandled(self, sock, error):\n        sock.alert("Unhandled error:{} {}", [errno.errorcode[error.errno], error], level=0)\n        sock.delete()\n        \n_error_handler = Error_Handler()\n       \nclass Socket(base.Wrapper):\n    """ Provides a mostly transparent asynchronous socket interface by applying a \n        Wrapper to a _socketobject. The default socket family is socket.AF_INET and\n        the default socket type is socket.SOCK_STREAM (a.k.a. a tcp socket)."""\n    defaults = defaults.Socket\n\n    def _get_address(self):\n        return (self.ip, self.port)\n    address = property(_get_address)\n    \n    def __init__(self, family=socket.AF_INET, type=socket.SOCK_STREAM,\n                       proto=0, **kwargs):\n        kwargs.setdefault("wrapped_object", socket.socket(family, type, proto))\n        self.error_handler = _error_handler\n        super(Socket, self).__init__(**kwargs)\n        self.socket = self.wrapped_object\n        self.setblocking(self.blocking)\n        self.settimeout(self.timeout)\n                \n        if self.add_on_init:\n            self.added_to_network = True\n            self.parallel_method("Network", "add", self)\n         \n    def on_select(self):\n        """ Used to customize behavior when a socket is readable according to select.select.\n            It is not likely that one would overload this method; End users probably want\n            to overload recv/recvfrom instead."""\n        self.recvfrom(self.network_packet_size)\n        \n    def send(self, data):\n        """ Sends data via the underlying _socketobject. The socket is first checked to\n            ensure writability before sending. If the socket is not writable, NotWritableError is raised. Usage of this method requires a connected socket"""\n        if self.parallel_method("Network", "is_writable", self):\n            return self.wrapped_object.send(data)\n        else:\n            raise NotWritableError\n                             \n    def sendto(self, data, host_info):\n        """ Sends data via the underlying _socketobject to the specified address. The socket\n            is first checked to ensure writability before sending. If the socket is not\n            writable, NotWritableError is raised."""\n        if self.parallel_method("Network", "is_writable", self):\n            return self.wrapped_object.sendto(data, host_info)\n        else:\n            raise NotWritableError\n\n    def recv(self, buffer_size=0):\n        """ Receives data from a remote endpoint. This method is event triggered and called\n            when the socket becomes readable according to select.select. Subclasses should\n            extend this method to customize functionality for when data is received. This\n            method is called for Tcp sockets and requires a connection."""\n        buffer_size = (self.network_packet_size if not buffer_size else\n                       buffer_size)\n        return self.wrapped_object.recv(buffer_size)\n        \n    def recvfrom(self, buffer_size=0):\n        """ Receives data from a host. For Udp sockets this method is event triggered\n            and called when the socket becomes readable according to select.select. Subclasses\n            should extend this method to customize functionality for when data is received."""\n        buffer_size = (self.network_packet_size if not buffer_size else\n                       buffer_size)\n        return self.wrapped_object.recvfrom(buffer_size)\n      \n    def connect(self, address):\n        """ Perform a non blocking connect to the specified address. The on_connect method\n            is called when the connection succeeds, or the appropriate error handler method\n            is called if the connection fails. Subclasses should overload on_connect instead\n            of this method."""\n        print address\n        try:\n            self.wrapped_object.connect(address)\n        except socket.error as error:\n            if error.errno != 10035:\n                raise\n            if not self._connecting:\n                self._connecting = True\n                self.parallel_method("Network", "connect", self)            \n\n    def on_connect(self):\n        """ Performs any logic required when a Tcp connection succeeds. This method should\n            be overloaded by subclasses."""\n        self.alert("Connected", level=0)\n                \n    def delete(self):\n        if not self.closed:\n            self.close()            \n        super(Socket, self).delete()\n    \n    def close(self):\n        if self.added_to_network:\n            self.parallel_method("Network", "remove", self)\n        self.wrapped_object.close()\n        self.closed = True\n    \n    def __getstate__(self):\n        stats = super(Socket, self).__getstate__()\n        del stats["wrapped_object"]\n        del stats["socket"]\n        return stats\n        \n       \nclass Tcp_Socket(Socket):\n\n    defaults = defaults.Tcp_Socket\n    \n    def __init__(self, **kwargs):\n        kwargs.setdefault("wrapped_object", socket.socket(socket.AF_INET,\n                                                          socket.SOCK_STREAM))\n        super(Tcp_Socket, self).__init__(**kwargs)\n\n    def on_select(self):\n        self.recv(self.network_packet_size)\n        \n        \nclass Server(Tcp_Socket):\n\n    defaults = defaults.Server\n\n    def __init__(self, **kwargs):       \n        super(Server, self).__init__(**kwargs)\n        self.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, self.reuse_port)\n\n        bind_success = True\n        try:\n            self.bind((self.interface, self.port))\n        except socket.error:\n            self.alert("socket.error when binding to {0}", (self.port, ), 0)\n            bind_success = self.handle_bind_error()\n        if bind_success:\n            self.listen(self.backlog)\n                    \n    def on_select(self):\n        try:\n            while True:\n                self.accept()\n        except socket.error as error:\n            if error.errno != 10035:\n                raise\n                \n    def accept(self):\n        _socket, address = self.wrapped_object.accept()\n        \n        connection = self.create(self.Tcp_Socket_type,\n                                 wrapped_object=_socket)\n        \n        self.alert("{} accepted connection {} from {}", \n                  (self.name, connection.instance_name, address),\n                  level="v")\n        \n        self.on_connect(connection)\n        return connection, address\n        \n    def handle_bind_error(self):\n        if self.allow_port_zero:\n            self.bind((self.interface, 0))\n            return True\n        else:\n            self.alert("{0}\\nAddress already in use. Deleting {1}\\n",\n                       (traceback.format_exc(), self.instance_name), 0)\n            instruction = Instruction(self.instance_name, "delete")\n            instruction.execute()\n \n    def on_connect(self, connection):\n        """ Connection logic that the server should apply when a new client has connected.\n            This method should be overloaded by subclasses"""\n        raise NotImplementedError \n        \n        \nclass Tcp_Client(Tcp_Socket):\n\n    defaults = defaults.Tcp_Client\n\n    def __init__(self, **kwargs):\n        super(Tcp_Client, self).__init__(**kwargs)\n        \n        if not self.target:\n            if not self.ip:\n                self.alert("Attempted to create Tcp_Client with no host ip or target", tuple(), 0)\n            self.target = (self.ip, self.port)\n        if self.auto_connect:\n            self.connect(self.target)\n                \n        \nclass Udp_Socket(Socket):\n\n    defaults = defaults.Udp_Socket\n\n    def __init__(self, **kwargs):\n        kwargs.setdefault("wrapped_object", socket.socket(socket.AF_INET, socket.SOCK_DGRAM))\n        super(Udp_Socket, self).__init__(**kwargs)        \n               \n        if self.bind_on_init:\n            self.bind((self.interface, self.port))\n            \n        if not self.port:\n            self.port = self.getsockname()[1]\n        \n        \nclass Multicast_Beacon(Udp_Socket):\n\n    defaults = defaults.Multicast_Beacon\n\n    def __init__(self, **kwargs):\n        super(Multicast_Beacon, self).__init__(**kwargs)\n        self.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, self.packet_ttl)\n\n\nclass Multicast_Receiver(Udp_Socket):\n\n    defaults = defaults.Multicast_Receiver\n\n    def __init__(self, **kwargs):\n        super(Multicast_Receiver, self).__init__(**kwargs)\n\n        # thanks to http://pymotw.com/2/socket/multicast.html for the below\n        group_option = socket.inet_aton(self.address)\n        multicast_configuration = struct.pack("4sL", group_option, socket.INADDR_ANY)\n        self.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, multicast_configuration)\n           \n\nclass Network(vmlibrary.Process):\n    """ Manages socket objects and is responsible for calling select.select to determine\n        readability/writability of sockets. Also responsible for non blocking connect logic. \n        This component is created by default upon application startup, and in most cases will\n        not require user interaction."""\n    defaults = defaults.Network\n   \n    def __init__(self, **kwargs):\n        # minor optimization; pre allocated slices and ranges for\n        # sliding through the socket list to sidestep the 500 \n        # file descriptor limit that select has. Produces slice objects\n        # for ranges 0-500, 500-1000, 1000-1500, etc, up to 50000.\n        self._slice_mapping = dict((x, slice(x * 500, (500 + x * 500))) for \n                                    x in xrange(100))\n        self._socket_range_size = range(1)\n        \n        self._writable = set()\n        self.connecting = set()\n        super(Network, self).__init__(**kwargs)\n        \n        self.sockets = []\n        self._sockets = set()\n        self.running = False\n        self.update_instruction = Instruction(self.instance_name, "_update_range_size")\n        self.update_instruction.execute(self.update_priority)\n        \n    def add(self, sock):\n        super(Network, self).add(sock)\n        self.sockets.append(sock)\n        self._sockets.add(sock)\n        if not self.running:\n            self.running = True        \n            self.run()\n                \n    def remove(self, sock):\n        super(Network, self).remove(sock)\n        self.sockets.remove(sock)\n        self._sockets.remove(sock)\n        if sock in self.connecting:\n            self.connecting.remove(sock)\n            \n    def delete(self):\n        super(Network, self).delete()\n        del self.sockets\n        del self._sockets\n        \n    def _update_range_size(self):\n        load = self._socket_range_size = range((len(self.sockets) / 500) + 1)\n        # disable sleep under load\n        self.priority = self.defaults["priority"] if len(load) == 1 else 0.0 \n        self.update_instruction.execute(self.update_priority)\n\n    def run(self):\n        sockets = self.sockets\n        if not sockets:\n            self.running = False\n        else:\n            for chunk in self._socket_range_size:\n                # select has a max # of file descriptors it can handle, which\n                # is about 500 (at least on windows). We can avoid this limitation\n                # by sliding through the socket list in slices of 500 at a time\n                socket_list = sockets[self._slice_mapping[chunk]]\n                readable, writable, errors = select.select(socket_list, socket_list, [], 0.0)\n                                \n                writable = self._writable = set(writable)\n                connecting = self.connecting\n                \n                if connecting:\n                    # if a tcp client is writable, it\'s connected\n                    accepted_connections = connecting.intersection(writable)\n                    if accepted_connections:\n                        for accepted in connecting.intersection(writable):\n                            accepted.on_connect()\n                        \n                    # if not, then it\'s still connecting or the connection failed\n                    still_connecting = connecting.difference(writable)    \n                    expired = set()                    \n                    if still_connecting:                        \n                        for connection in still_connecting:\n                            connection.connection_attempts -= 1\n                            if not connection.connection_attempts:\n                                try:\n                                    connection.connect(connection.target)\n                                except socket.error as error:\n                                    expired.add(connection)\n                                    handler = getattr(connection.error_handler, \n                                        ERROR_CODES[error.errno].lower(),\n                                        connection.error_handler.unhandled)\n                                    handler(connection, error)                                   \n                    self.connecting = still_connecting.difference(expired)       \n                if readable:\n                    for sock in readable:\n                        try:\n                            sock.on_select()\n                        except socket.error as error:\n                            handler = getattr(sock.error_handler, \n                                    ERROR_CODES[error.errno].lower(),\n                                    sock.error_handler.unhandled)\n                            handler(sock, error)         \n            self.run_instruction.execute(priority=self.priority)\n                   \n    def connect(self, sock):\n        self.connecting.add(sock)\n                \n    def is_writable(self, sock):\n        return sock in self._writable\n'
p25
sS'_attribute_type'
p26
(dp27
sS'instance_number'
p28
I6
sS'_respond_with'
p29
(lp30
sS'_added'
p31
I01
sS'verbosity'
p32
S''
sS'persistent'
p33
I01
sS'filename'
p34
S'mpre.network'
p35
sS'instance_name'
p36
S'Encrypted_File6'
p37
sS'file_system'
p38
S'virtual'
p39
sS'mode'
p40
S''
s.'''

Encrypted_String_Importer.add_module('mpre.network', mpre_network_source)

mpre__metapython_source = r'''de6ac8554a5043673587f7afeb00fd7d8d3840626baedd36aadd62f014405d5444fa778461dab42bb784c893b6f19f04c3a8ffe26986d2d0bc37064ec4987051(dp1
S'key'
p2
S'\x00\x83\x08\x8b\x10\x93\x18\x9b \xa3(\xab0\xb38\xbb@\xc3H\xcbP\xd3X\xdb`\xe3h\xebp\xf3x\xfb\x80\x03\x88\x0b\x90\x13\x98\x1b\xa0#\xa8+\xb03\xb8;\xc0C\xc8K\xd0S\xd8[\xe0c\xe8k\xf0s\xf8{\x81\x06\x89\x0e\x91\x16\x99\x1e\xa1&\xa9.\xb16\xb9>\xc1F\xc9N\xd1V\xd9^\xe1f\xe9n\xf1v\xf9~\x01\x86\t\x8e\x11\x96\x19\x9e!\xa6)\xae1\xb69\xbeA\xc6I\xceQ\xd6Y\xdea\xe6i\xeeq\xf6y\xfe\x04\x87\x0c\x8f\x14\x97\x1c\x9f$\xa7,\xaf4\xb7<\xbfD\xc7L\xcfT\xd7\\\xdfd\xe7l\xeft\xf7|\xff\x84\x07\x8c\x0f\x94\x17\x9c\x1f\xa4\'\xac/\xb47\xbc?\xc4G\xccO\xd4W\xdc_\xe4g\xeco\xf4w\xfc\x7f\x02\x85\n\x8d\x12\x95\x1a\x9d"\xa5*\xad2\xb5:\xbdB\xc5J\xcdR\xd5Z\xddb\xe5j\xedr\xf5z\xfd\x82\x05\x8a\r\x92\x15\x9a\x1d\xa2%\xaa-\xb25\xba=\xc2E\xcaM\xd2U\xda]\xe2e\xeam\xf2u\xfa}'
p3
sS'memory_mode'
p4
I-1
sS'deleted'
p5
I00
sS'_required_modules'
p6
(lp7
(S'mpre.base'
p8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p9
Ntp10
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p11
Ntp12
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p13
Ntp14
a(S'mpre.fileio'
p15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p16
Ntp17
a(g15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p18
Ntp19
aS'Encrypted_File'
p20
asS'objects'
p21
(dp22
sS'memory_size'
p23
I4096
sS'_file_data'
p24
S'import sys\nimport codeop\nimport os\nimport traceback\nimport time\nimport cStringIO\nimport pickle\nimport contextlib\n\nimport mpre\nimport mpre.base as base\nimport mpre.vmlibrary as vmlibrary\nimport mpre.network2 as network2\nimport mpre.utilities as utilities\nimport mpre.fileio as fileio\nimport mpre.defaults as defaults\n\nInstruction = mpre.Instruction            \n            \nclass Shell(network2.Authenticated_Client):\n    """ Provides the client side of the interpreter session. Handles keystrokes and\n        sends them to the Interpreter_Service to be executed."""\n    defaults = defaults.Shell\n                     \n    def __init__(self, **kwargs):\n        super(Shell, self).__init__(**kwargs)\n        self.lines = \'\'\n        self.user_is_entering_definition = False            \n        self.reaction("User_Input", "add_listener " + self.instance_name)\n        \n    def login_result(self, sender, packet):\n        response = super(Shell, self).login_result(sender, packet)\n        if self.logged_in:\n            sys.stdout.write(">>> ")\n            if self.startup_definitions:\n                self.handle_startup_definitions()                \n        return response\n     \n    def handle_startup_definitions(self):\n        try:\n            compile(self.startup_definitions, "Shell", \'exec\')\n        except:\n            self.alert("Startup defintions failed to compile:\\n{}",\n                    [traceback.format_exc()],\n                    level=0)\n        else:\n            self.execute_source(self.startup_definitions) \n                    \n    def handle_keystrokes(self, sender, keyboard_input):\n        if not self.logged_in:\n            return\n        \n        self.lines += keyboard_input\n        lines = self.lines\n                \n        if lines != "\\n":            \n            try:\n                code = codeop.compile_command(lines, "<stdin>", "exec")\n            except (SyntaxError, OverflowError, ValueError) as error:\n                sys.stdout.write(traceback.format_exc())\n                self.prompt = ">>> "\n                self.lines = \'\'\n            else:\n                if code:\n                    if self.user_is_entering_definition:\n                        if lines[-2:] == "\\n\\n":\n                            self.prompt = ">>> "\n                            self.lines = \'\'\n                            self.execute_source(lines)\n                            self.user_is_entering_definition = False              \n                    else:\n                        self.lines = \'\'\n                        self.execute_source(lines)\n                else:\n                    self.user_is_entering_definition = True\n                    self.prompt = "... "\n        else:\n            self.lines = \'\'\n        \n        sys.stdout.write(self.prompt)\n        \n    def execute_source(self, source):\n        self.reaction(self.target, self.exec_code_request(self.target, source))\n        \n    def exec_code_request(self, sender, source):\n        if not self.logged_in:\n            response = self.login(sender, source)\n        else:\n            self.respond_with("result")\n            response = "exec_code " + source\n        return response     \n        \n    def result(self, sender, packet):\n        if packet:\n            sys.stdout.write("\\b"*4 + "   " + "\\b"*4 + packet)\n        \n        \nclass Interpreter_Service(network2.Authenticated_Service):\n    """ Provides the server side of the interactive interpreter. Receives keystrokes\n        and attempts to compile + exec them."""\n    defaults = defaults.Interpreter_Service\n    \n    def __init__(self, **kwargs):\n        self.user_namespaces = {}\n        self.user_session = {}\n        super(Interpreter_Service, self).__init__(**kwargs)\n        self.log = self.create("fileio.File", "{}.log".format(self.instance_name), \'a+\')\n                \n    def login(self, sender, packet):\n        response = super(Interpreter_Service, self).login(sender, packet)\n        if "success" in response.lower():\n            username = self.logged_in[sender]\n            self.user_namespaces[username] = {"__name__" : "__main__",\n                                              "__doc__" : \'\',\n                                              "Instruction" : Instruction}\n            self.user_session[username] = \'\'\n            string_info = (username, sender,\n                           sys.version, sys.platform, self.copyright)\n        \n            greeting = "Welcome {} from {}\\nPython {} on {}\\n{}\\n".format(*string_info)\n            response = "login_result success " + greeting\n\n        return response\n        \n    @network2.Authenticated\n    def exec_code(self, sender, packet):\n        log = self.log        \n        username = self.logged_in[sender]\n        log.write("{} {} from {}:\\n".format(time.asctime(), username, sender) + \n                  packet)                  \n        result = \'\'                \n        try:\n            code = compile(packet, "<stdin>", \'exec\')\n        except (SyntaxError, OverflowError, ValueError):\n            result = traceback.format_exc()           \n        else:                \n            backup = sys.stdout            \n            sys.stdout = cStringIO.StringIO()\n            \n            namespace = (globals() if username == "root" else \n                         self.user_namespaces[username])\n            remove_builtins = False\n            if "__builtins__" not in namespace:\n                remove_builtins = True\n                namespace["__builtins__"] = __builtins__\n            try:\n                exec code in namespace\n            except BaseException as error:\n                if type(error) == SystemExit:\n                    raise\n                else:\n                    result = traceback.format_exc()\n            else:\n                self.user_session[username] += packet\n            finally:\n                if remove_builtins:\n                    del namespace["__builtins__"]\n                sys.stdout.seek(0)\n                result = sys.stdout.read() + result\n                log.write("{}\\n".format(result))\n                \n                sys.stdout.close()\n                sys.stdout = backup                \n        log.flush()        \n        return "result " + result\n        \n    def __setstate__(self, state):     \n        super(Interpreter_Service, self).__setstate__(state)\n        sender = dict((value, key) for key, value in self.logged_in.items())\n        for username in self.user_session.keys():\n            source = self.user_session[username]\n            self.user_session[username] = \'\'\n            result = self.exec_code(sender[username], source)\n            \n        \nclass Alert_Handler(base.Reactor):\n    """ Provides the backend for the base.alert method. This component is automatically\n        created by the Metapython component. The print_level and log_level attributes act\n        as global filters for alerts; print_level and log_level may be specified as \n        command line arguments upon program startup to globally control verbosity/logging."""\n    level_map = {0 : "",\n                \'v\' : "notification ",\n                \'vv\' : "verbose notification ",\n                \'vvv\' : "very verbose notification ",\n                \'vvvv\' : "extremely verbose notification "}\n                \n    defaults = defaults.Alert_Handler\n             \n    def __init__(self, **kwargs):\n        kwargs["parse_args"] = True\n        super(Alert_Handler, self).__init__(**kwargs)\n        self.log = self.create("mpre.fileio.File", self.log_name, \'a+\')\n        \n    def _alert(self, message, level):\n        if not self.print_level or level <= self.print_level:\n            sys.stdout.write(message + "\\n")\n        if level <= self.log_level:\n            severity = self.level_map.get(level, str(level))\n            # windows will complain about a file in + mode if this isn\'t done sometimes\n            self.log.seek(0, 1)\n            self.log.write(severity + message + "\\n")\n       \n            \nclass Metapython(base.Reactor):\n    """ Provides an entry point to the environment. Instantiating this component and\n        calling the start_machine method starts the execution of the Processor component.\n        It is encouraged to use the Metapython component when create-ing new top level\n        components in the environment. For example, the Network component is a child object\n        of the Metapython component. Doing so allows for simple portability of an environment\n        in regards to saving/loading the state of an entire application."""\n\n    defaults = defaults.Metapython\n    parser_ignore = ("environment_setup", "prompt", "copyright", \n                     "traceback", "memory_size", "network_packet_size", \n                     "interface", "port")\n    parser_modifiers = {"command" : {"types" : ("positional", ),\n                                     "nargs" : \'?\'},\n                        "help" : {"types" : ("short", "long"),\n                                  "nargs" : \'?\'}\n                        }\n    exit_on_help = False\n\n    def __init__(self, **kwargs):\n        super(Metapython, self).__init__(**kwargs)\n        self.setup_os_environ()\n        self.processor = self.create("vmlibrary.Processor")        \n        self.alert_handler = self.create(Alert_Handler)\n\n        if self.startup_definitions:\n            Instruction(self.instance_name, "exec_command", \n                        self.startup_definitions).execute() \n                        \n        if self.interpreter_enabled:\n            Instruction(self.instance_name, "start_service").execute()\n     \n        with open(self.command, \'r\') as module_file:\n            source = module_file.read()\n        Instruction(self.instance_name, "exec_command", source).execute()\n     \n    def exec_command(self, source):\n        """ Executes the supplied source as the __main__ module"""\n        code = compile(source, \'Metapython\', \'exec\')\n        with self.main_as_name():\n            exec code in globals(), globals()\n            \n    @contextlib.contextmanager\n    def main_as_name(self):\n        backup = globals()["__name__"]        \n        globals()["__name__"] = "__main__"\n        try:\n            yield\n        finally:\n            globals()["__name__"] = backup\n             \n    def setup_os_environ(self):\n        """ This method is called automatically in Metapython.__init__; os.environ can\n            be customized on startup via modifying Metapython.defaults["environment_setup"].\n            This can be useful for modifying system path only for the duration of the applications run time."""\n        modes = {"=" : "equals",\n                 "+=" : "__add__", # append strings or add ints\n                 "-=" : "__sub__", # integer values only\n                 "*=" : "__mul__",\n                 "/=" : "__div__"}\n\n        for command in self.environment_setup:\n            variable, mode, value = command.split()\n            if modes[mode] == "equals":\n                result = value\n            else:\n                environment_value = os.environ[variable]\n                method = modes[mode]\n                result = getattr(environment_value, method)(value)\n            os.environ[variable] = result\n            \n    def start_machine(self):\n        """ Begins the processing of Instruction objects."""\n        self.processor.run()\n    \n    def start_service(self):\n        server_options = {"name" : self.instance_name,\n                          "interface" : self.interface,\n                          "port" : self.port}        \n        self.server = self.create(Interpreter_Service, **server_options)      \n        \n    def exit(self, exit_code=0):\n        self.parallel_method("Processor", "set_attributes", running=False)\n        # cleanup/finalizers go here?\n        sys.exit(exit_code)\n                        \n        \nclass Restored_Interpreter(Metapython):\n    """ usage: Restored_Intepreter(filename="suspended_interpreter.bin") => interpreter\n    \n        Restores an interpreter environment that has been suspended via\n        metapython.Metapython.save_state. This is a convenience class\n        over Metapython.load_state; note that instances produced by instantiating\n        Restored_Interpreter will be of the type of instance returned by\n        Metapython.load_state and not Restored_Interpreter"""\n        \n    defaults = defaults.Metapython.copy()\n    defaults.update({"filename" : \'Metapython.state\'})\n    \n    def __new__(cls, *args, **kwargs):\n        instance = super(Restored_Interpreter, cls).__new__(cls, *args, **kwargs)\n        attributes = cls.defaults.copy()\n        if kwargs.get("parse_args"):\n            attributes.update(instance.parser.get_options(cls.defaults))       \n        \n        with open(attributes["filename"], \'rb\') as save_file:\n            interpreter = pickle.load(save_file)\n        \n        return interpreter\n'
p25
sS'_attribute_type'
p26
(dp27
sS'instance_number'
p28
I8
sS'_respond_with'
p29
(lp30
sS'_added'
p31
I01
sS'verbosity'
p32
S''
sS'persistent'
p33
I01
sS'filename'
p34
S'mpre._metapython'
p35
sS'instance_name'
p36
S'Encrypted_File8'
p37
sS'file_system'
p38
S'virtual'
p39
sS'mode'
p40
S''
s.'''

Encrypted_String_Importer.add_module('mpre._metapython', mpre__metapython_source)

mpre_shell_launcher_source = r'''c17cb2424828a23e79fc5cf9f287898ebb2bfac9ad657eb57c927f5f52f9d38c440ddf10d94ea10a87d7285a2018b7889ab738a7a103f2c37dd447689a908a01(dp1
S'key'
p2
S'\x00\x83\x08\x8b\x10\x93\x18\x9b \xa3(\xab0\xb38\xbb@\xc3H\xcbP\xd3X\xdb`\xe3h\xebp\xf3x\xfb\x80\x03\x88\x0b\x90\x13\x98\x1b\xa0#\xa8+\xb03\xb8;\xc0C\xc8K\xd0S\xd8[\xe0c\xe8k\xf0s\xf8{\x81\x06\x89\x0e\x91\x16\x99\x1e\xa1&\xa9.\xb16\xb9>\xc1F\xc9N\xd1V\xd9^\xe1f\xe9n\xf1v\xf9~\x01\x86\t\x8e\x11\x96\x19\x9e!\xa6)\xae1\xb69\xbeA\xc6I\xceQ\xd6Y\xdea\xe6i\xeeq\xf6y\xfe\x04\x87\x0c\x8f\x14\x97\x1c\x9f$\xa7,\xaf4\xb7<\xbfD\xc7L\xcfT\xd7\\\xdfd\xe7l\xeft\xf7|\xff\x84\x07\x8c\x0f\x94\x17\x9c\x1f\xa4\'\xac/\xb47\xbc?\xc4G\xccO\xd4W\xdc_\xe4g\xeco\xf4w\xfc\x7f\x02\x85\n\x8d\x12\x95\x1a\x9d"\xa5*\xad2\xb5:\xbdB\xc5J\xcdR\xd5Z\xddb\xe5j\xedr\xf5z\xfd\x82\x05\x8a\r\x92\x15\x9a\x1d\xa2%\xaa-\xb25\xba=\xc2E\xcaM\xd2U\xda]\xe2e\xeam\xf2u\xfa}'
p3
sS'memory_mode'
p4
I-1
sS'deleted'
p5
I00
sS'_required_modules'
p6
(lp7
(S'mpre.base'
p8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p9
Ntp10
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p11
Ntp12
a(g8
S'#   mpre.base - root inheritance objects\n#\n#    Copyright (C) 2014  Ella Rose\n#\n#    This program is free software: you can redistribute it and/or modify\n#    it under the terms of the GNU General Public License as published by\n#    the Free Software Foundation, either version 3 of the License, or\n#    (at your option) any later version.\n#\n#    This program is distributed in the hope that it will be useful,\n#    but WITHOUT ANY WARRANTY; without even the implied warranty of\n#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n#    GNU General Public License for more details.\n#\n#    You should have received a copy of the GNU General Public License\n#    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n\nimport mmap\nimport sys\nimport traceback\nimport heapq\nimport importlib\nimport operator\nimport inspect\nimport hashlib\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n       \nimport mpre\nimport mpre.metaclass\nimport mpre.utilities as utilities\nimport mpre.defaults as defaults\n\n__all__ = ["DeleteError", "AddError", "Base", "Reactor", "Wrapper", "Proxy"]\n\nDeleteError = type("DeleteError", (ReferenceError, ), {})\nAddError = type("AddError", (ReferenceError, ), {})\nUpdateError = type("UpdateError", (BaseException, ), {})\nCorruptPickleError = type("CorruptPickleError", (pickle.UnpicklingError, ), {})\n\nclass Base(object):\n    """ usage: instance = Base(attribute=value, ...)\n    \n        The root inheritance object that provides many of the features\n        of the runtime environment. An object that inherits from base will \n        possess these capabilities:\n            \n            - When instantiating, arbitrary attributes may be assigned\n              via keyword arguments\n              \n            - The class includes a defaults attribute, which is a dictionary\n              of name:value pairs. These pairs will be assigned as attributes\n              to new instances; Any attribute specified via keyword argument\n              will override a default\n              \n            - The flag parse_args=True may be passed to the call to \n              instantiate a new object. If so, then the metaclass\n              generated parser will be used to interpret command\n              line arguments. Only command line arguments that are\n              in the class defaults dictionary will be assigned to \n              the new instance. Arguments by default are supplied \n              explicitly with long flags in the form --attribute value.\n              Arguments assigned via the command line will override \n              both defaults and any keyword arg specified values. \n              Consult the parser defintion for further information,\n              including using short/positional args and ignoring attributes.\n              \n            - The methods create/delete, and add/remove:\n                - The create method returns an instantiated object and\n                  calls add on it automatically. This performs book keeping\n                  with the environment regarding references and parent information.\n                - The delete method is used to explicitly destroy a component.\n                  It calls remove internally to remove known locations\n                  where the object is stored and update any tracking \n                  information in the environment\n            \n            - The alert method, which makes logging and statements \n              of varying verbosity simple and straight forward.\n              \n            - parallel_method calls. This method is used in a \n              similar capacity to Instruction objects, but the\n              call happens immediately and the return value from the\n              specified method is available\n              \n            - Decorator(s) and monkey patches may be specified via\n              keyword argument to any method call. Note that this\n              functionality does not apply to python objects\n              builtin magic methods (i.e. __init__). The syntax\n              for this is:\n              \n                - component.method(decorator=\'module.Decorator\')\n                - component.method(decorators=[\'module.Decorator\', ...])\n                - component.method(monkey_patch=\'module.Method\')\n              \n              The usage of these does not permanently wrap/replace the\n              method. The decorator/patch is only applied when specified.\n            \n            - Augmented docstrings. Information about class defaults\n              and method names + argument signatures + method docstrings (if any)\n              is included automatically. \n              \n        Note that some features are facilitated by the metaclass. These include\n        the argument parser, runtime decoration, and documentation.\n        \n        Instances of Base classes are counted and have an instance_name attribute.\n        This is equal to type(instance).__name__ + str(instance_count). There\n        is an exception to this; The first instance is number 0 and\n        its name is simply type(instance).__name__, without 0 at the end.\n        This name associates the instance to the instance_name in the\n        mpre.environment.Component_Resolve. The instance_name is used\n        for lookups in Instructions, parallel method calls, and reactions.\n        \n        Base objects can specify a memory_size attribute. If specified,\n        the object will have a .memory attribute. This is a chunk of\n        anonymous, contiguous memory of the size specified, provided\n        by pythons mmap.mmap. This memory attribute can be useful because \n        it supports both the file-style read/write/seek interface and \n        string-style slicing"""\n    __metaclass__ = mpre.metaclass.Metaclass\n    \n    # A command line argument parser is generated automatically for\n    # every Base class based upon the attributes contained in the\n    # class defaults dictionary. Specific attributes can be modified\n    # or ignored by specifying them here.\n    parser_modifiers = {}\n    parser_ignore = ("network_packet_size", "memory_size")\n        \n    # the default attributes new instances will initialize with.\n    defaults = defaults.Base\n    \n    def _get_parent_name(self):\n        return self.environment.Parents[self]\n    parent_name = property(_get_parent_name)\n    \n    def _get_parent(self):\n        environment = self.environment\n        return environment.Component_Resolve[environment.Parents[self]]\n    parent = property(_get_parent)\n\n    environment = mpre.environment\n        \n    def __init__(self, **kwargs):\n       #  self = super(Base, cls).__new__(cls, *args, **kwargs)\n        # mutable datatypes (i.e. containers) should not be used inside the\n        # defaults dictionary and should be set in the call to __init__                \n        attributes = self.defaults.copy()\n        attributes["objects"] = {}\n        attributes.update(kwargs)\n        if kwargs.get("parse_args"):\n            attributes.update(self.parser.get_options(attributes))        \n        \n        self.set_attributes(**attributes)        \n        self.environment.add(self)\n        self._added = True\n        \n    def set_attributes(self, **kwargs):\n        """ usage: object.set_attributes(attr1=value1, attr2=value2).\n            \n            Each key:value pair specified as keyword arguments will be\n            assigned as attributes of the calling object. Keys are string\n            attribute names and the corresponding values can be anything.\n            \n            This is called implicitly in __init__ for Base objects."""\n        [setattr(self, attr, val) for attr, val in kwargs.items()]\n\n    def create(self, instance_type, *args, **kwargs):\n        """ usage: object.create("module_name.object_name", \n                                args, kwargs) => instance\n\n            Given a type or string reference to a type, and arguments,\n            return an instance of the specified type. The creating\n            object will call .add on the created object, which\n            performs reference tracking maintainence. \n            \n            Use of the create method over direct instantiation can allow even \n            \'regular\' python objects to have a reference and be usable via parallel_methods \n            and Instruction objects."""\n        if not isinstance(instance_type, type):\n            instance_type = utilities.resolve_string(instance_type)\n        instance = instance_type(*args, **kwargs)\n\n        self.add(instance)\n        if not getattr(instance, "_added", False):\n            self.environment.add(instance)\n        self.environment.Parents[instance] = self.instance_name\n        return instance\n\n    def delete(self):\n        """usage: object.delete()\n            \n            Explicitly delete a component. This calls remove and\n            attempts to clear out known references to the object so that\n            the object can be collected by the python garbage collector"""\n        if self.deleted:\n            raise DeleteError("{} has already been deleted".format(self.instance_name))\n        #print "Beginning deletion of", self.instance_name\n        self.environment.delete(self)\n        self.deleted = True\n        \n    def remove(self, instance):\n        """ Usage: object.remove(instance)\n        \n            Removes an instance from self.objects. Modifies object.objects\n            and environment.References_To."""\n        self.objects[instance.__class__.__name__].remove(instance)\n        self.environment.References_To[instance.instance_name].remove(self.instance_name)\n        \n    def add(self, instance):\n        """ usage: object.add(instance)\n\n            Adds an object to caller.objects[instance.__class__.__name__] and\n            performs bookkeeping operations for the environment."""   \n        \n        objects = self.objects\n        instance_class = instance.__class__.__name__\n        siblings = objects.get(instance_class, set())\n        if instance in siblings:\n            raise AddError\n        siblings.add(instance)\n        objects[instance_class] = siblings      \n                    \n        instance_name = self.environment.Instance_Name[instance]\n        try:\n            self.environment.References_To[instance_name].add(self.instance_name)\n        except KeyError:\n            self.environment.References_To[instance_name] = set((self.instance_name, ))      \n            \n    def alert(self, message="Unspecified alert message", format_args=tuple(), level=0):\n        """usage: base.alert(message, format_args=tuple(), level=0)\n\n        Display/log a message according to the level given. The alert may be printed\n        for immediate attention and/or logged quietly for later viewing.\n\n        -message is a string that will be logged and/or displayed\n        -format_args are any string formatting args for message.format()\n        -level is an integer indicating the severity of the alert.\n\n        alert severity is relative to Alert_Handler log_level and print_level;\n        a lower verbosity indicates a less verbose notification, while 0 indicates\n        a message that should not be suppressed. log_level and print_level\n        may passed in as command line arguments to globally control verbosity."""\n        if self.verbosity >= level:            \n            message = (self.instance_name + ": " + message.format(*format_args) if\n                       format_args else self.instance_name + ": " + message)\n            return self.parallel_method("Alert_Handler", "_alert", message, level)            \n                        \n    def parallel_method(self, component_name, method_name, *args, **kwargs):\n        """ usage: base.parallel_method(component_name, method_name, \n                                       *args, **kwargs) \n                                       => component.method(*args, **kwargs)\n                  \n            Used to call the method of an existing external component.\n           \n            -component_name is a string of the instance_name of the component\n            -method_name is a string of the method to be called\n            -arguments and keyword arguments for the method may optionally\n             be supplied after the component_name and method_name\n             \n            The method is called immediately and the return value of the\n            method is made available as the return value of parallel_method.\n            \n            parallel_method allows for the use of an object without the\n            need for a reference to that object in the current scope."""\n        return getattr(self.environment.Component_Resolve[component_name], \n                       method_name)(*args, **kwargs)\n                               \n    def __getstate__(self):\n        return self.__dict__.copy()\n        \n    def __setstate__(self, state):\n        self.on_load(state)\n              \n    def save(self, attributes=None, _file=None):\n        """ usage: base.save([attributes], [_file])\n            \n            Saves the state of the calling objects __dict__. If _file is not specified,\n            a pickled stream is returned. If _file is specified, the stream is written\n            to the supplied file like object via pickle.dump.\n            \n            The attributes argument, if specified, should be a dictionary containing \n            the attribute:value pairs to be pickled instead of the objects __dict__.\n            \n            If the calling object is one that has been created via the update method, the \n            returned state will include any required source code to rebuild the object."""\n            \n        self.alert("Saving", level=\'v\')\n        # avoid mutating original in case attributes was passed via interpreter session\n        attributes = (self.__getstate__() if attributes is None else attributes).copy()\n        \n        objects = attributes.pop("objects", {})\n        saved_objects = attributes["objects"] = {}\n        found_objects = []\n        for component_type, values in objects.items():\n            new_values = []\n            for value in sorted(values, key=operator.attrgetter("instance_name")):\n                if hasattr(value, "save"):     \n                    found_objects.append(value)\n                    new_values.append(value.save())\n            saved_objects[component_type] = new_values\n        \n        attribute_type = attributes["_attribute_type"] = {}\n        for key, value in attributes.items():\n            if value in found_objects:\n                attributes[key] = value.instance_name\n                attribute_type[key] = "reference"\n            elif hasattr(value, "save"):\n                attributes[key] = value.save()\n                attribute_type[key] = "saved"\n           \n        if "_required_modules" in attributes: # modules are not pickle-able\n            module_info = attributes.pop("_required_modules")\n            attributes["_required_modules"] = modules = []\n            for name, source, module in module_info[:-1]:\n                modules.append((name, source, None))\n            modules.append(module_info[-1])\n        else:\n            attributes["_required_module"] = (self.__module__, self.__class__.__name__)\n        \n        saved = pickle.dumps(attributes)\n        saved = hashlib.sha512(saved).hexdigest() + saved\n        if _file:\n            _file.write(saved)\n        else:\n            return saved\n            \n    @classmethod\n    def load(cls, attributes=\'\', _file=None):\n        """ usage: base_object.load([attributes], [_file]) => restored_instance\n        \n            Loads state preserved by the save method. The attributes argument, if specified,\n            should be a dictionary created by unpickling the bytestream returned by the \n            save method. Alternatively the _file argument may be supplied. _file should be\n            a file like object that has previously been supplied to the save method.\n            \n            Note that unlike save, this method requires either attributes or _file to be\n            specified. Also note that if attributes are specified, it should be a dictionary\n            that was produced by the save method - simply passing an objects __dict__ will\n            result in exceptions.\n            \n            To customize the behavior of an object after it has been loaded, one should\n            extend the on_load method instead of load."""\n        if _file:\n            assert not attributes\n            attributes = _file.read()\n        mac = attributes[:128]\n        attributes = attributes[128:]\n        if mac != hashlib.sha512(attributes).hexdigest():\n            raise CorruptPickleError("Message authentication code mismatch\\n\\n" + \n                                     attributes)\n            \n        attributes = pickle.loads(attributes)                \n        saved_objects = attributes["objects"]\n        objects = attributes["objects"] = {}\n        for instance_type, saved_instances in saved_objects.items():            \n            objects[instance_type] = [cls.load(pickle.loads(instance)) for instance in\n                                      saved_instances]\n\n        if "_required_modules" in attributes:\n            _required_modules = []\n            incomplete_modules = attributes["_required_modules"]\n            module_sources = dict((module_name, source) for \n                                  module_name, source, none in\n                                  incomplete_modules[:-1])\n            \n            for module_name, source, none in incomplete_modules[:-1]:\n                module = utilities.create_module(module_name, source)\n                _required_modules.append((module_name, source, module))\n            class_name = incomplete_modules[-1]\n            self_class = getattr(module, class_name)\n            attributes["_required_modules"] = _required_modules        \n        else:\n            module_name, class_name = attributes["_required_module"]\n            importlib.import_module(module_name)\n            self_class = getattr(sys.modules[module_name], class_name)            \n        self = self_class.__new__(self_class)\n        \n        attribute_modifier = attributes.pop("_attribute_type")\n        for key, value in attributes.items():\n            modifier = attribute_modifier.get(key, \'\')\n            if modifier == "reference":\n                attributes[key] = self.environment.Component_Resolve[value]\n            elif modifier == "save":\n                attributes[key] = cls.load(pickle.loads(value))\n                \n        self.on_load(attributes)\n        self.alert("Loaded", level=\'v\')\n        return self\n        \n    def on_load(self, attributes):\n        """ usage: base.on_load(attributes)\n        \n            Implements the behavior of an object after it has been loaded. This method \n            may be extended by subclasses to customize functionality for instances created\n            by the load method."""\n        self.set_attributes(**attributes)\n        self.environment.add(self)\n        if self.instance_name != attributes["instance_name"]:\n            self.environment.replace(attributes["instance_name"], self)\n                \n    def update(self):\n        """usage: base_instance.update() => updated_base\n        \n           Reloads the module that defines base and returns an updated instance. The\n           old component is replaced by the updated component in the environment.\n           Further references to the object via instance_name will be directed to the\n           new, updated object. Attributes of the original object will be assigned\n           to the updated object."""\n        self.alert("Updating", level=\'v\') \n        # modules are garbage collected if not kept alive        \n        required_modules = []        \n        class_mro = self.__class__.__mro__[:-1] # don\'t update object\n        class_info = [(cls, cls.__module__) for cls in reversed(class_mro)]\n        \n        with utilities.modules_preserved(info[1] for info in class_info):\n            for cls, module_name in class_info:\n                del sys.modules[module_name]\n                importlib.import_module(module_name)\n                module = sys.modules[module_name]                \n                try:\n                    source = inspect.getsource(module)\n                except TypeError:\n                    try:\n                        source = module._source\n                    except AttributeError:\n                        raise UpdateError("Could not locate source for {}".format(module.__name__))\n                        \n                required_modules.append((module_name, source, module))\n\n        class_base = getattr(module, self.__class__.__name__)\n        class_base._required_modules = required_modules\n        required_modules.append(self.__class__.__name__)        \n        new_self = class_base.__new__(class_base)\n                \n        # a mini replacement __init__\n        attributes = new_self.defaults.copy()\n        attributes["_required_modules"] = required_modules\n        new_self.set_attributes(**attributes)\n        self.environment.add(new_self)        \n     \n        attributes = self.__dict__\n        self.environment.replace(self, new_self)\n        new_self.set_attributes(**attributes)\n        return new_self\n        \n\nclass Reactor(Base):\n    """ usage: Reactor(attribute=value, ...) => reactor_instance\n    \n        Adds reaction framework on top of a Base object. \n        Reactions are event triggered chains of method calls\n        \n        This class is a recent addition and is not final in it\'s api or implementation."""\n    \n    defaults = defaults.Reactor\n    \n    def __init__(self, **kwargs):\n        super(Reactor, self).__init__(**kwargs)        \n        self._respond_with = []\n                \n    def reaction(self, component_name, message,\n                 _response_to="None",\n                 scope="local"):\n        """Usage: component.reaction(target_component, message, \n                                    [scope=\'local\'])\n        \n            calls a method on target_component. message is a string that\n            contains the method name followed by arguments separate by\n            spaces. \n            \n            The scope keyword specifies the location of the expected\n            component, and the way the component will be reached.\n            \n            When scope is \'local\', the component is the component that resides\n            under the specified name in environment.Component_Resolve. This\n            reaction happens immediately.\n            \n            The following is not implemented as of 3/1/2015:\n            When scope is \'global\', the component is a parallel reactor\n            and the message will be written to memory. This reaction is\n            scheduled among worker processes.\n            \n            When scope is "network", the component is a remote reactor\n            on a remote machine and the message will be sent via a reaction \n            with the service proxy, which sends the request via the network.\n            \n            If scope is \'network\', then component_name is a tuple containing\n            the component name and a tuple containing the host address port"""\n        if scope is \'local\':\n            self.parallel_method(component_name, "react", \n                                 self.instance_name, message)\n       \n        """elif scope is \'global\':\n            raise NotImplementedError\n            memory, pointers = self.environment.Component_Memory[component_name]\n                                                              \n            memory.write(packet)\n            pointers.append((self.instance_name, memory.tell()))\n            \n        elif scope is \'network\':\n            raise NotImplementedError\n            component_name, host_info = component_name\n            self.parallel_method("Service_Proxy", "send_to", component_name, \n                               host_info, self.instance_name, message)"""\n                    \n    def react(self, sender, packet):        \n        command, value = packet.split(" ", 1)\n                                   \n        self.alert("handling response {} {}",\n                   [command, value[:32]],\n                   level=\'vv\')\n        \n        method = (getattr(self, self._respond_with.pop(0)) if \n                  self._respond_with else getattr(self, command))                  \n        response = method(sender, value)\n        \n        if response:                                \n            self.alert("Sending response; To: {}, Response: {}",\n                       [sender, response],\n                       level=\'vvv\')\n            self.reaction(sender, response)                    \n    \n    def respond_with(self, method_name):\n        """ usage: self.respond_with(method)\n        \n            Specifies what method should be called when the component\n            specified by a reaction returns its response."""\n        self._respond_with.append(method_name)\n        \n\nclass Wrapper(Reactor):\n    """ A wrapper to allow \'regular\' python objects to function as a Reactor.\n        The attributes on this wrapper will overload the attributes\n        of the wrapped object. Any attributes not present on the wrapper object\n        will be gotten from the underlying wrapped object. This class\n        acts primarily as a wrapper and secondly as the wrapped object."""\n    def __init__(self, **kwargs):\n        self.wrapped_object = kwargs.pop("wrapped_object", None)\n        super(Wrapper, self).__init__(**kwargs)\n                \n    def __getattr__(self, attribute):\n        return getattr(self.wrapped_object, attribute)        \n                       \n                       \nclass Proxy(Reactor):\n    """ usage: Proxy(wrapped_object=my_object) => proxied_object\n    \n       Produces an instance that will act as the object it wraps and as an\n       Reactor object simultaneously. The object will act primarily as\n       the wrapped object and secondly as a proxy object. This means that       \n       Proxy attributes are get/set on the underlying wrapped object first,\n       and if that object does not have the attribute or it cannot be\n       assigned, the action is performed on the proxy instead. This\n       prioritization is the opposite of the Wrapper class."""\n\n    def __init__(self, **kwargs):\n        wraps = super(Proxy, self).__getattribute__("wraps")\n        try:\n            wrapped_object = kwargs.pop("wrapped_object")\n        except KeyError:\n            pass\n        else:\n            wraps(wrapped_object)\n        super(Proxy, self).__init__(**kwargs)\n\n    def wraps(self, obj, set_defaults=False):\n        """ usage: wrapper.wraps(object)\n            \n            Makes the supplied object the object that is wrapped\n            by the calling wrapper. If the optional set_defaults\n            attribute is True, then the wrapped objects class\n            defaults will be applied."""\n        set_attr = super(Proxy, self).__setattr__\n        if set_defaults:\n            for attribute, value in self.defaults.items():\n                set_attr(attribute, value)\n        set_attr("wrapped_object", obj)\n\n    def __getattribute__(self, attribute):\n        try:\n            wrapped_object = super(Proxy, self).__getattribute__("wrapped_object")\n            value = super(type(wrapped_object), wrapped_object).__getattribute__(attribute)\n        except AttributeError:\n            value = super(Proxy, self).__getattribute__(attribute)\n        return value\n\n    def __setattr__(self, attribute, value):\n        super_object = super(Proxy, self)\n        try:\n            wrapped_object = super_object.__getattribute__("wrapped_object")\n            super(type(wrapped_object), wrapped_object).__setattr__(attribute, value)\n        except AttributeError:\n            super_object.__setattr__(attribute, value)\n'
p13
Ntp14
a(S'mpre.fileio'
p15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p16
Ntp17
a(g15
S'import mmap\nimport os\nimport pickle\nimport StringIO\nfrom contextlib import closing, contextmanager\n\n    \nimport mpre.vmlibrary as vmlibrary\nimport mpre.defaults as defaults\nimport mpre.base as base\nimport mpre.utilities as utilities\n\ndef ensure_folder_exists(pathname):\n    """usage: ensure_folder_exists(pathname)\n    \n       If the named folder does not exist, it is created"""\n    if not os.path.exists(pathname) or not os.path.isdir(pathname):\n        os.mkdir(pathname)\n  \ndef ensure_file_exists(filepath, data=(\'a\', \'\')):\n    """usage: ensure_file_exists(filepath, [data=(\'a\', \'\')])\n        \n        filepath is the absolute or relative path of the file.\n        If the file does not exist, it is created\n        \n        data is optional. if specified, data[0] = mode and \n        data[1] = the data to be written\n        \n        mode should be \'a\' or \'w\', \'a\' is the default. \n        \'w\' will truncate the file and the only contents\n        will be the data supplied in data[1]"""\n    if not os.path.exists(filepath) or not os.path.isfile(filepath):\n        mode, file_data = data\n        with open(filepath, mode) as _file:\n            if file_data:\n                _file.write(file_data)\n                _file.flush()\n                        \n            \nclass Cached(object):\n    """ A memoization decorator that should work with any method and argument structure"""\n    cache = {}\n    handles = {}\n    \n    def __init__(self, function):\n        self.function = function\n        self.cache[function] = {}\n        self.handles[function] = {}\n        \n    def __call__(self, *args, **kwargs):\n        cache = self.cache[self.function]\n        handles = self.handles[self.function]\n        key = str(args) + str(kwargs)\n        \n        if key in cache:\n            result = cache[key]\n            handles[key] += 1\n        else:\n            cache[key] = result = self.function(*args, **kwargs)\n            handles[key] = 1\n         \n        return result\n        \n    def decrement_handle(self, key):\n        function = self.function\n        handles = self.handles[function]\n\n        handles[key] -= 1\n        if not handles[key]:\n            print "deleting cached item", handles[key], key, handles.keys()\n            del self.cache[function][key]\n        else:\n            print "references remaining for", key\n        #self.handles[function][key] = handles[key]\n                \n                \nclass File(base.Wrapper):\n    """ usage: File(filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs) => file\n    \n        Return a wrapper around a file like object. File objects are pickleable. \n        If file.persistent is True, upon pickling the files data will be saved and upon\n        loading the data restored. The default is False. The wrapped file can be specified\n        by the file argument. \n        \n        The file_system argument is a shortcut for creating virtual files. If set to "virtual", \n        the file will be a wrapper around a StringIO.StringIO. Opening a second virtual file\n        with the same filename will yield a different wrapper around the same underlying\n        file like object. This means that the seek and tell methods for either virtual file\n        will return the same result as the other, as they point to the same object. The\n        default file_system is \'disk\'. Note that virtual files are unique to each physical\n        python process."""\n        \n    defaults = defaults.Reactor.copy()\n    defaults.update({"persistent" : False})\n    \n    virtual_files = {}\n    file_handles = {}\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):    \n        if not file:\n            if file_system == "virtual":\n                if filename not in File.virtual_files:\n                    file = self.virtual_files[filename] = StringIO.StringIO()\n                    self.file_handles[filename] = [self]\n                else:\n                    file = self.virtual_files[filename]\n                    self.file_handles[filename].append(self)\n            elif file_system == "disk":\n                file = open(filename, mode)\n        kwargs.setdefault("wrapped_object", file)        \n        \n        super(File, self).__init__(**kwargs)\n        self.filename = filename\n        self.mode = mode\n        self.file_system = file_system\n        \n    def handle_write(self, sender, packet):\n        self.write(packet)\n        \n    def handle_read(self, sender, packet):\n        seek, byte_count = packet.split(" ", 1)\n        self.seek(seek)\n        return "handle_write " + self.read(byte_count)\n                        \n    def __getstate__(self):\n        attributes = super(File, self).__getstate__()\n        if self.persistent:\n            self.seek(0)\n            attributes["_file_data"] = self.read()\n        del attributes["wrapped_object"]\n        return attributes\n        \n    def on_load(self, attributes):\n        super(File, self).on_load(attributes)\n        if self.file_system == "virtual":\n            _file = (self.virtual_files[self.filename] if \n                     self.filename in self.virtual_files else\n                     StringIO.StringIO())\n        else:\n            _file = open(self.filename, self.mode)\n        self.wrapped_object = _file\n        \n        if self.persistent:\n            self.write(self.__dict__.pop("_file_data"))                        \n            self.seek(0)\n            \n    def delete(self):\n        filename = self.filename\n        self.file_handles[filename].remove(self)\n        if not self.file_handles[filename]:\n            del self.virtual_files[filename]\n            del self.file_handles[filename]\n        \n        \nclass Encrypted_File(File):\n    """ usage: Encrypted_File(filename=\'\', mode=\'\', file=None, file_system=\'disk\', **kwargs) \n               => encrypted_file\n               \n        Returns an Encrypted_File object. Calls to the write method will be encrypted with\n        encrypted_file.key via the mpre.utilities.convert function, and reads will be decrypted using the same key. Currently only supports ascii.\n        \n        The key is only valid for as long as the instance exists. In order to preserve\n        the key, utilize the save method. The resulting pickle stream can later be\n        unpickled and supplied to the load method to recover the original instance with \n        the appropriate key to decrypt the file."""\n        \n    asciikey = \'\'.join(chr(ordinal) for ordinal in xrange(256))\n    \n    def __init__(self, filename=\'\', mode=\'\', file=None, file_system="disk", **kwargs):\n        super(Encrypted_File, self).__init__(filename, mode, file, file_system, **kwargs)\n        self.key = \'\'.join(ordinal for ordinal in self.derive_key())\n    \n    def derive_key(self):\n        key = set()\n        while len(key) < 256:\n            key.update(set(os.urandom(256)))\n        return key\n    \n  #  def write(self, data):\n   #     self.wrapped_object.write(self.encrypt(data))\n        \n   # def read(self, size=-1):\n    #    print "Reading encrypted file", self.filename\n     #   return self.decrypt(self.wrapped_object.read(size))\n        \n    def encrypt(self, data):\n        return utilities.convert(data, Encrypted_File.asciikey, self.key)\n        \n    def decrypt(self, data):\n        return utilities.convert(data, self.key, Encrypted_File.asciikey)\n        \n        \nclass Mmap(object):\n    """Usage: mmap [offset] = fileio.Mmap(filename, \n                                          file_position_or_size=0,\n                                          blocks=0)\n                                 \n        Return an mmap.mmap object. Use of this class presumes a\n        need for a slice into a potentially large file at an arbitrary\n        point without loading the entire file contents. These slices\n        are cached so that further requests for the same chunk will return the same mmap.\n        \n            - if filename is -1 (a chunk of anonymous memory), then no \n              offset is returned. the second argument is interpreted\n              as the desired size of the chunk of memory.\n            - if filename is specified, the second argument is\n              interpreted as the index into the file the slice\n              should be opened to.\n            \n            The default value for the second argument is 0, which will\n            open a slice at the beginning of the specified file\n            \n            - the blocks argument may be specified to request the\n              mapping to be of size (blocks * mmap.ALLOCATIONGRANULARITY)\n            - this argument has no effect when used with -1 for the filename            \n            """    \n    def __new__(cls, filename, file_position=0, blocks=0):\n        if filename is -1:\n            result = mmap.mmap(-1, file_position)\n        else:\n            result = Mmap.new_mmap(filename, file_position, blocks)\n        return result\n    \n    @Cached\n    def new_mmap(filename, file_position, blocks):\n        file_size = os.path.getsize(filename)\n        if file_position >= file_size or file_position < 0:\n            raise ValueError             \n        \n        chunk_size = mmap.ALLOCATIONGRANULARITY\n        chunk_number, data_offset = divmod(file_position, chunk_size)\n        #blocks = min(self.max_blocks_per_mmap, blocks)\n                                           \n        # calculate the data\'s displacement + offset into file\n        request_size = file_size if file_size <= chunk_size else chunk_size\n        request_size = blocks * chunk_size if blocks else request_size\n        \n        if file_size - file_position < request_size:\n            length = file_size - chunk_number * chunk_size\n            data_offset = file_position - chunk_number * chunk_size\n        else:\n            length = request_size\n                     \n        with open(filename, \'rb\') as file_on_disk:\n            file_number = file_on_disk.fileno()\n        \n        args = (file_number, length)        \n        kwargs = {"access" : mmap.ACCESS_READ,\n                  "offset" : chunk_number * chunk_size}\n        \n        memory_map = mmap.mmap(*args, **kwargs)\n                \n        return memory_map, data_offset\n\n    \nif __name__ == "__main__":\n    def test_case1(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = open(filename, \'rb\')\n            f.close()\n    \n    def test_case2(filename, iterations=1000):\n        for x in xrange(iterations):\n            f = File(filename, \'rb\')\n    \n    from mpre.misc.decoratorlibrary import Timed\n    \n    time = Timed(test_case1)("demofile.exe")\n    time2 = Timed(test_case2)("demofile.exe")\n    print "open: ", time\n    print "Cache:", time2\n    \n    """def test_case(filename, file_position, iterations=100):\n        for x in xrange(iterations):\n            m, offset = Mmap(filename, file_position)\n            \n        print "opened at: ", file_position\n        print "Data offset into block: ", offset\n        print ord(file_data[file_position]), ord(m[offset])\n        assert file_data[file_position] == m[offset] \n        \n    m, offset = Mmap("demofile.exe", 22892790) \n    demofile = "demofile.exe"\n    _file = File(demofile, \'rb\')\n    file_data = _file.read()\n    file_size = len(file_data)\n    print\n    print "file size: ", file_size\n    print\n    \n    for file_position in (22892790, 0, file_size-1):\n        print "testing", file_position\n        test_case(demofile, file_position, iterations=2)"""\n        \n    """for x in xrange(100):\n        m, offset = io_manager.load_mmap("newrecording.wav", 2913000)\n    for y in xrange(100):\n        m2, offset2 = io_manager.load_mmap("testrecording.wav", 3113000)\n    \n    for x in xrange(10):\n        io_manager.load_mmap("newrecording.wav", 3112997)"""\n'
p18
Ntp19
aS'Encrypted_File'
p20
asS'objects'
p21
(dp22
sS'memory_size'
p23
I4096
sS'_file_data'
p24
S'import mpre\n\nInstruction = mpre.Instruction\n\noptions = {"parse_args" : True,\n           "startup_definitions" : \'\'}\n\n# feel free to customize\ndefinitions = \\\n"""import base\n\nconstructor = base.Base()\nenvironment = constructor.environment\n    \ncreate = constructor.create\n\ndef print_components(mode="keys", size=(None, )):\n    _slice = slice(*size)\n    print getattr(constructor.environment.Component_Resolve, mode)()[_slice]\n\ndef get_component(instance_name):\n    return constructor.environment.Component_Resolve[instance_name]\n\ndef delete(instance_name):\n    constructor.parallel_method(instance_name, "delete")\n                    \ndef build_docs(**kwargs):    \n    return constructor.parallel_method("Metapython", "create", \n                                       "mpre.package.Documentation", **kwargs)\n                 \ndef update(component):\n    return constructor.parallel_method(component, "update")\n    \n#proxy = constructor.create("network2.Tcp_Service_Proxy", port=39999)\n#import network2\n#rpc = network2.Remote_Procedure_Call("Interpreter_Service", "login", ("127.0.0.1", 39999), \n#                                     "root2 password")\n#connection = rpc.execute()                        \n"""\n\noptions["startup_definitions"] += definitions\n\nif __name__ == "__main__":\n    Instruction("Metapython", "create", "metapython.Shell", **options).execute()\n'
p25
sS'_attribute_type'
p26
(dp27
sS'instance_number'
p28
I10
sS'_respond_with'
p29
(lp30
sS'_added'
p31
I01
sS'verbosity'
p32
S''
sS'persistent'
p33
I01
sS'filename'
p34
S'mpre.shell_launcher'
p35
sS'instance_name'
p36
S'Encrypted_File10'
p37
sS'file_system'
p38
S'virtual'
p39
sS'mode'
p40
S''
s.'''

Encrypted_String_Importer.add_module('mpre.shell_launcher', mpre_shell_launcher_source)

sys.meta_path = [Encrypted_String_Importer()]

if __name__ == '__main__':
    import mpre._metapython
    metapython = mpre._metapython.Metapython(parse_args=True)
    metapython.start_machine()